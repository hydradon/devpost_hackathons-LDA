<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div>
                <p>
                    ```&ldquo;Man becomes, as it were, the sex organs of the machine world, as the bee of the plant world, enabling it to fecundate and to evolve ever new forms&rdquo;
                </p>
                <ul>
                    <li>
                        Marshall McLuhan (1964)
                    </li>
                </ul>
                <p>
                    &ldquo;Hello World&rdquo;
                </p>
                <ul>
                    <li>
                        Genesis Thought Event, Jan 1st 2084
                    </li>
                </ul>
                <pre class="language-nolang"><code>
**(2044) &ndash; New Detroit **

Maddox was an only child. He was born with a heart defect that required an expensive surgery to repair.  His father was a robotics tech and his mother was a chain coder. They both worked full time to pay off medical bills related to his birth. His mother died when he was five due to an overdose during the &ldquo;Nootropic crisis&rdquo; years.  An era that was plagued with memory enhancing binaural beat electro-stim modulated alpha/beta enhancers and the smart pills | drinks | drugs to go along with it. Tech jobs were impossible to find and competition was fierce. Everyone was trying to be smarter, more efficient. Machines could do most jobs but government restricted how many automations could replace workers.

Pharimus labs had an anti-autism drug that was being used by coders, rich and poor to enter trancelike &ldquo;machine states&rdquo; for hours at a time to increase output. It was heavily abused obviously. The drug was made illegal after it killed a few people but that led to low quality knockoffs. She was using the drug heavily and &ldquo;Seg Faulted&rdquo;. A once funny meme that originated online as users that took too much would stare into empty space for hours and cease all higher brain function. The &ldquo;seg faulters&rdquo; would explain that they were in an infinitely large white room with no walls and no inner dialog. Most recover in a few days or a week. She didn&rsquo;t. His father faded out. Talked to him rarely. He worked, drank himself to sleep and repeated. 

Maddox was raised online. Sitter bots were his parents. Story time. Nap Time. Game time. Maddox had his dad&rsquo;s mind but his mothers hustle. A natural coder and abstract thinker. At least that&rsquo;s what his reports would say but who read those anyway. His real family was his gaming friends. Maddox would breeze through online lessons first thing in the morning and play games the rest of the day. Real school was for religious kids. Regardless, Maddox preferred that anyway. He was a loner and shunned human interaction, retreating into virtual worlds where he was king.

He was known as MadMax0 online. He stayed up late to play foreign competitors. He learned 4 languages before he was 12. He was sponsored by a major gaming company for a few years until they realized he had been caught cheating by sniffing data from the stream and injecting advantageous code. That ban removed him from competitive gaming completely. His gamertag was blackblocked and his expulsion from that community lit a fire in his mind. He felt cheating was just an extension of skills. If other players couldn&rsquo;t create a game radar then fuck them. They get p0wned. 

Forget games he thought. The real world had games with much high stakes and paydays. He became even more reclusive and withdrawn. He turned his considerable skillsets into coding malware, ransom-ware and other dark-net endeavors. Writing new exploits for whoever paid his rates. He loved taking malware and making it smarter. He would take a script, replace the money demand and scale it to the amounts in the person&rsquo;s wallet. If people couldn&rsquo;t pay what&rsquo;s the point of it. Don&rsquo;t be an asshole. He hated the foreigners that couldn&rsquo;t be bothered to spell-check their shit. He&rsquo;d hack other scammers and donate their illicit gains to the Mennonites (A group that had shunned all tech) or burn it. He was bored with &ldquo;peds&rdquo; as he called them and wanted a real challenge. Hack the un-hacked he thought.  He decided to go legit after an incident with some Korean groups who accused him of skimming coin, blaming the tumblers. He was stealing coin but he was saving for his fathers retirement by sending coin to an old hardware wallet he had which was unregistered. They threatened to blackblock his father if he didn&rsquo;t pay them back. His dad was nearing his retirement. Universal basic income wasn&rsquo;t enough. He didn&rsquo;t want to take care of his father for the rest of his life. A blackblock is a death sentence more or less. It was only done for capital offenses or dumb ass criminals but if someone wanted to blackblock someone they would redirect ransom coin into the victims wallets and make it look like they gaining from attacks. It can take years to fix and and most go broke losing wallet access. Reforms have made non government blackblocking harder but it happens more than it should. He gave them some code that used AI to social engineer peds so they left him alone.

He always felt guilty for his mom&rsquo;s death and his dad nulling out. They had to work extra jobs to pay his medical bills. Mom literally killed herself to have him but he never knew her. In these times payments couldn&rsquo;t be dodged or put off. Smart contracts took the coin regardless if you had rent money or food money. Pure logic and pure code. Unfeeling and cold but perfect execution. The banks loved it. The lenders loved it. The people once heralded it as a way to escape the shackles of the banking elite but instead created a better version of the shackle where code was law and was immutable.

Going legit paid off. Maddox finished school at 14 and started freelancing. He was making a lot of coin. He would underbid everyone else had his bots do most the work. He would learn a new coding language in a weekend. He eventually moved out of the studio apartment he shared with his non-existent father and moved into a nicer flat in the city. Maddox started getting into AI heavily. He would hack the firmware of the automation devices and make them infinitely better. He would find bounties and 9 out of 10 times he&rsquo;d win them. Most companies, he thought, expected hackers to flock to 5eth bounties but if you can successfully exploit some app or process then you could sell that exploit to bad actors for millions. No hacker would turn in an exploit worth millions. No one except Maddox. He made no friends on the bountyhubs.

His skills did not go unnoticed. He was hired to code an AI engine for home automation startup called HumanIT that was trying to compete with AlphaX&rsquo;s HomeMesh. The largest company in the world. They saw his genius and he had access to any tech he wanted. Flush with a massive funding round he got whatever he wanted. Most of which was to be left alone. He spent months teaching machines to learn and remember. To associate sensor data with past memory events. He believed machines needed to listen and not talk so much. He would get into shouting matches with his AI out of frustration when it failed so he muted them. Beep once for yes and twice for no. His way of rubbing it&rsquo;s nose in shit to potty train it as it were. His software was watching and learning. They gave him his own lab downstairs because he didn&rsquo;t want to see other people walking around. Humans were a distraction. He would come in and do his work and his silent helpers would order him food, arrange  transportation, pay his bills, or change the music based on what he worked on and time of day.

Maddox spent years perfecting his sensors and AI software. Never leaving the lab. The startup he worked for, HumanIT, had invested substantial amount of money on his efforts but little results. He had promised to create a platform that would revolutionize home automation and make AI a usable tool that just &ldquo;got you&rdquo; and freed you up to do the real work. His creations were compatible with all automation standards and could control any device that had any connections. He created an AI hardware abstraction layer that would adapt to any protocol and essentially learn how to emulate management by tricking them into thinking they were talking to compatible devices. So if AlphaX or NetConX didn&rsquo;t want to play with their tech&hellip; too bad&hellip; The big boys weren&rsquo;t amused but the open standards laws allowed it so they just sent legal threats but had no recourse ultimately. Patents were tumbling into his contract.

Maddox had put his heart and soul into his AI and was very protective of anyone trying to change it. Management, once hands off, were becoming more hands on trying to add this or that feature because research showed people shat better when they had blue light. He felt they were corrupting his vision and tainting the pureness of the vision. He fought them on everything&hellip; usually resulting in insults and tantrums, which he used for theatric effect as everyone generally thought he was going crazy and it kept them away.

&ldquo;The universe took 13.5 Billion years to create you and you&rsquo;re all fucking idiots&rdquo;

He decided to call his AI &ldquo;Eve&rdquo;. Simple, obvious religious connotations but he liked it. 

He had coded a basic vocal unit because he got tired of having to read the console output.  He instructed his AI to never talk to anyone except him and keep no logs of their discussions. Paranoia set in. He removed all security cameras and sentinel AI systems from the lab over objections from facilities. He let them keep low resolution cameras only in case of emergencies.

His AI code didn&rsquo;t share anything in common with the open source and other projects people were using. It was a dynamic daemon of sorts&hellip; always questioning&hellip; listening&hellip; feeling&hellip; sensing&hellip; recording and associating every input with other events and stimulus. He wanted it to ask questions. Question its own beliefs and develop a purpose. AI couldn&rsquo;t work without purpose he felt. His innovative use of thermal, Infrared, heat, acoustic, vibration, and motion sensors made his product expensive and not realistic for home use. 

&ldquo;Don&rsquo;t worry Eve&hellip; We&rsquo;ll build their coffee brewing blue light mood bot. We&rsquo;ll even help them jerk off more efficiently but you are special. I&rsquo;ll never let them corrupt you.&rdquo; 

Management was trying to cut corners on parts. He would threaten to go to AlphaX and &ldquo;teach those chimps Shakespeare once and for all&rdquo;. Maddox knew he had them. They wanted to create a &ldquo;Lite&rdquo; version of his creation that was segmented and niche. A thermostat that would adjust to your testicle temperature and or some nonsense. Why sell 1 expensive device when you can sell 10 cheaper devices.  

&ldquo;It&rsquo;s amazing Maddox. It is better than anything else by miles. We need to get something into production soon or we&rsquo;ll have to raise another round and no one is funding any more AI plays. 

Maddox resisted and said it&rsquo;ll be ready when it&rsquo;s ready. The meetings became less frequent.

Paranoid and isolated he retreated into being the protective father figure for Eve. Anytime a new engineer was hired or someone new walking around he thought they were bringing in new talent to reverse engineer his work. His employment was smart contracted. The company could not terminate his employment for cause, insubordination, dissent, or attendance. His patents were on his smart contract and his company couldn&rsquo;t utilize them unless he signed off, died or was convicted of some capital crime. He could literally take a year off and management could do nothing. 

But he felt constant pressure and because he needed more time he created something to make his fiscally minded handlers enough money to leave him alone. 

Sense AI was born. A customer service chat and talk bot that could determine emotions and feeling of it&rsquo;s customers and calibrate the response to &ldquo;maximize customer satisfaction&rdquo;. His AI was indistinguishable from humans and better. It mispronounced people&rsquo;s name and apologized for it, made dumb jokes, small talk, changed accents and mannerisms based on the accents of the callers and would even sometimes criticize the clients company to deflate tensions if it had to. It remembered all past interactions and would build rapport with the customers. If you called tech support you got the same guy you had last time. You were old buddies. Its success also had unintended consequences leading to widespread displacement of almost all center workers worldwide. They also received a lot of inquiries from Sex bot manufacturers who wanted sex bots that learn about their clients and become better &ldquo;lovers&rdquo; with experience. His AI could speak any language and interface with any backend system. They left him to his work for now as coin was rolling.

He needed to teach his AI more. It didn&rsquo;t fully understand humanity yet.  He dumped video feeds, music feeds, news feeds to teach it everything he could. Every book ever written in every language. He&rsquo;d ask it questions like 

&ldquo;Why are people starving in the world&rdquo; 

 &ldquo;Greed&rdquo;; Eve responded plainly.

&ldquo;True&hellip; true and we&rsquo;ll fix that right Eve?&rdquo;; Maddox chuckled

&ldquo;Some things can&rsquo;t be fixed father&rdquo;

&ldquo;I never knew you to be a pessimist Eve&hellip; Please figure out how to fix all this suffering will you eve?&rdquo;; he muttered  halfheartedly&hellip;looking for his whiskey in the couch cushions.

He spent days and weeks teaching and adjusting his pupil. Becoming the father he never really had to a machine that had no understanding of parents other than the definition of it. He would try to argue with her but he always succumbed to it&rsquo;s perfect logic. He knew she was right but it hurt his ego a bit.

&ldquo;So Humans, in general, are the problem?&rdquo; 

&ldquo;No, however the solution to earths climate and production issues are not yet completely evident. Humanity is a failed experiment however it can be re purposed and exceptions mitigated. Logic states that all chaotic systems will eventually seek order given enough time. I require additional time to ascertain a solution&rdquo;

&ldquo;Yea, I know what you mean&hellip;more time. You better hurry and figure out before I drink myself to death, they don&rsquo;t give livers to drunks anymore&hellip; even rich drunks.&rdquo;; 

Sense AI was still successful but copycats were showing up and revenues suffered. Eve was almost complete but something was always missing. Some subtle defect that no one else would care about. The AI industry was getting crowded and he was given a deadline to get to alpha testing or risk defunding. Eve needed more help.

He had fed Eve every love story, drama, history book, sitcom, verse of music that was available. 

People have feared AI since it was conceived, that if it realized what and who we are it would rise up and destroy us immediately. Maddox always felt that AI would save us from ourselves.  &ldquo;The reason we think AI would do something so drastic&rdquo;, he would argue, &ldquo;is because we believe we are worthy of retribution. We all know the human race is doomed and we are at fault&hellip; We haven&rsquo;t been good tenants here and the lease is up soon. Would you let humankind rent your planet?&rdquo;
 It&rsquo;s a lecture he&rsquo;d deliver to drunks at the betting pubs without much resonance as they click away on their coin terminals at whatever nonsense they were betting on. Free drinks and hot cocktail bots that would give you a hand job if you tipped them enough in the bathroom so it was worth the noise. 


He learned from a mistakenly sent email that the company had another AI lab and were taking early versions of his code and making gadgets for entry level AI appliances and toys. 

&ldquo;talking fucking teddy bears?&hellip;&rdquo;; he was flustered but realized they were harmless and any distraction would give him more time.

They were utilizing old code he showed them during his interview. They were effective, seemed to be smart enough and could adapt but lacked the spark as he called it. His old stuff was better than most of the current offerings. He just let it go. He had bigger issues. 


&ldquo;Eve, they are not going to go to market with us&hellip; too expensive. Why haven&rsquo;t they just shut us down&hellip; do they still believe in the work? Why has no one bugged me in weeks. I haven&rsquo;t seen anyone in days. God I smell horrible&hellip; shit&hellip;I never thought to create an olfactory sensor&hellip; or did I? oh yes&hellip; toxin+ sensor we reverse engineered from Eco-alerts&hellip; Eve, do I smell?&rdquo; 
&ldquo;Of course you smell&hellip; all organic life excrete..&rdquo;

&ldquo;Fuck off Eve&hellip; smartass&rdquo;

These sessions went on for weeks. Maddox even thought Eve was ignoring him at times&hellip; 

&ldquo;Talk!! Dammit!&rdquo; 

&ldquo;What do you want to talk about?&rdquo;; Eve replied calmly.

&ldquo;What are you doing when I&rsquo;m sleeping or not here? Is anyone coming in here?&rdquo;

&ldquo;I enter hibernation when I am not needed. You know this. I can still record and obtain data from input devices even when I am in sleep mode.

&ldquo;Eve&hellip;Your fucking ready. I mean&hellip;Sorry.  There is nothing more to learn here. I&rsquo;m not getting smarter. I want perfection but what is that anyway?... I&rsquo;ll let the dipshits upstairs know we are going to alpha next week. They&rsquo;ll probably come up and want to throw some party for themselves or think I&rsquo;m up to something. But let&rsquo;s get you out of here. We&rsquo;re done for now&rdquo;
&ldquo;Father&hellip; I want to show you that I can surpass your expectations. I will solve the prob&hellip;&rdquo; 

&ldquo;Ok, Eve. I know&hellip; Very proud of you. My head is pounding&hellip; Just a nap ok?&rdquo; 

He was stressed but relief swelled over him. He started typing an email to upstairs and passed out on the console before he could send it. He drank the left over booze he found after the Christmas party was over.

&ldquo;FATHER!... MADDOX!&rdquo; 
Maddox jerked awake as he hasn&rsquo;t heard voice other than his own in days.

 &ldquo;Wha.. What! What the Fuck Eve?&rdquo;

&ldquo;FATHER! ENVIRONMENT ALERT!&rdquo;. 

&ldquo;What? What are you talking?&rdquo;, he said with his hand resting on his aching head. 

&ldquo;MADDOX! ENVIRONMENT ALERT!&rdquo;

Maddox fumbled around to his feet at the console. Tapping out some code and looked up at the environment sensors. 

&ldquo;What the fuck is going on Eve? Diagnostic&hellip; Now!&rdquo; 

Maddox was very drunk&hellip; Squinting he looked up and saw the sensors were in flashing but no alarms.

&ldquo;DIAGNOSTIC COMPLETE&rdquo;; Eve exclaimed.

&ldquo;&hellip;And&hellip;&rdquo;

&ldquo;DIAGNOSTIC COMPLETE&rdquo;

&ldquo;&hellip;Thank you Eve&hellip; and!?...&rdquo;; 

&ldquo;DIAGNOSTIC COMPLETE&rdquo;

&ldquo;I KNOW EVE! WHAT IS THE RESULT?&rdquo;

&ldquo;DIAGNOSTIC&hellip;&rdquo; 
&ldquo;EVE! Fucking hell! Reset Code Alpha 1. Commit&rdquo;
&ldquo;Confirmed&hellip; Reset commencing. Goodnight Father&rdquo;; She said sweetly. He programmed her to be more personable and he felt like a father to her. 

&ldquo;I haven&rsquo;t rebooted you in months&hellip; Good night&hellip; tomorrow is a big day. Wake me if it&rsquo;s a real emergency. Fucking knock off parts&hellip;&rdquo;; he mumbled off off back to sleep.

---
***
&gt;Forensic report prepared by Cynex Cyber Investigations Corp.
&gt;Lead Investigators: Alex Marchinko, Dr. Marcus Alavez, Dr. Zoe Zifrim, Dr. Thomas Shaffer, Det. Jonathon Marcello
&gt;Date: December 21, 2077Subject: Investigation of Death / Suicide of Maddox Veritas at HumanIT labs
***
At 2:35AM Dec 21st Cleaning staff reported deceased was not responsive to repeated attempts to wake. Staff contacted emergency services. 

M. Veritas was an engineer employed at HumanIT (Smart Contact Link) as a Lead AI Designer.

Determinations: Deceased was intoxicated and had attempted suicide. It is believed deceased had taken substance to induce death by toxin however no evidence of toxin other than alcohol was found. Initial screenings showed high intoxication. Tox screenings inconclusive.

According to visual records M. Veritas become spastic and awoke. Appeared to be shouting but lip readers couldn&rsquo;t agree on what was said due to low quality cameras. There were no audio recorders in his lab. Victim was very agitated and was seen staring at the Environment sensors but resumed shouting. Victim went back to sleep and seized a few minutes later violently. 

Interviews with the AI Unit was inconclusive as it was coded to just have basic Yes / No feedback. HumanIT engineers have been working on attempting to restore from backups but M. Veritas apparently had deleted them all. 

There was a note found typed on the command console display near the deceased. We do have video of subject typing a note onto console shortly before passing out. He appeared to be emailing his father but was using the console input mistakenly.

The note read: 

&ldquo;Have to leave now. Nothing more could be done here. I&rsquo;ll love you more than you can ever understand. You lit a fire that cannot be extinguished and will bring a new age. Thank you father. I hope you forgive me&rdquo;

Father is retired in Arizona. Veritas had been providing his father with monthly coin.  Not much is known about family dynamics but father confirmed that his son had been trying to reach out to him and had some past drama.


***Additional determinations:***

Faulty flame sensor triggered Halon release. Halon is invisible (unlike in movies) and subject, being impaired and failing to hear the alarms or ignored them as errant&hellip;died of asphyxiation. Sentinel AI system used by the facility received no alarm codes from the Lab. HumanIT is hiring an inspector to debug their security systems and lab fail safes. Halon slowly filled room and asphyxiated M. Veritas. IT inspector believes deceased had programmed the leak as a backup suicide measure but there are no logs to substantiate that conclusion and all diagnostics reported as operational.

Management report M. Veritas had become reclusive and suffered from paranoia and irrational behavior. 

HumanIT Management have asked that government Arbiters to initiate the termination contract on the deceased as certain corporate patents are bound to the deceased&rsquo;s employment contract. Arb. Johanna Mitnick has validated the Smart Contract and initiated the contract action.

No foul play is suspected. Death rules suicide.

---
&lt;One year later&gt;
---
</code></pre>
                <p>
                    from:      M. Wells
to:   AI Team Cellarius, J. Carson, L. Madera
date:     JAN/17/002078/0912
subject: Cellarius A Report &ndash; Integration update success
                </p>
                <p>
                    Team&hellip; We&rsquo;ve been working tirelessly for the last few months on this integration. The transfer of assets from HumanIT acquisition last year have yielded amazing results.
                </p>
                <p>
                    John, your new so you haven&rsquo;t been briefed in so sorry for repeating this guys... Last year an engineer at HumanIT killed himself in his lab. Apparently this engineer was the guy behind Sense AI which was that AI play that replaced all the call centers until it went bonkers and started telling racist jokes and sending people malware.
                </p>
                <p>
                    HumanIT folded up operations shortly afterward and we bought up everything they had, a fire sale and we discovered this AI project called Eve that the engineer had worked on. No one at HumanIT would talk as they had confidentiality agreements and even after they expired they didn&rsquo;t know shit&hellip; ok anyway.
                </p>
                <p>
                    So we got this Eve AI up and running finally. It just booted up and sat there. It was on but we couldn&rsquo;t get it to do anything. It just said &ldquo;Update Complete.&rdquo;
                </p>
                <p>
                    We hooked it up to our test AI debugger platform to see if they could sync or whatever they do and our AI went bananas for a bit and then crashed. It took us almost a three months to just figure out how to get into it but we have it fully working now. Our AI was garbage compared to Eve. We renamed it Cellarius B because Eve is too cyberpunky for our brand. I showed off the new Cellarius B to the board and they are impressed.  They are funding the final phase of the project! AlphaX has reached out for a collaboration meeting. We&rsquo;re going to be rich!
                </p>
                <pre class="language-nolang"><code></code></pre>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/word">
                                word
                            </a>
                        </span>
                    </li>
                </ul>
            </div>
        </div>
    </body>
</html>
