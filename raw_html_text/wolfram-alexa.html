<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li class="text-center">
                        <a data-lightbox="368576" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/368/576/datas/original.png">
                            <img alt="Wolfram Alexa &ndash; screenshot 1" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/368/576/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                            </i>
                        </p>
                    </li>
                </ul>
            </div>
            <div>
                <h2>
                    Inspiration
                </h2>
                <p>
                    We were originally going to do a handwriting recognition hack to convert handwriting into Wolfram Alpha queries. When we learned that Amazon was providing hardware to hack with (Amazon Echo), we decided that dictating a query made more sense for a student trying to write homework.
                </p>
                <h2>
                    What it does
                </h2>
                <p>
                    This hack allows your spoken query to be sent to Wolfram Alpha for solving. While it was optimized for math queries (such as "integrate x squared from zero to three"), it can also answer some general questions that Wolfram Alpha is known for (such as "Facebook stock price").
                </p>
                <h2>
                    How I built it
                </h2>
                <p>
                    The code is hosted on the Amazon Lambda compute service and is written in Python. It relies on Amazon Echo's built-in voice recognition and Wolfram Alpha's natural language recognition. The challenging part was converting everyday speech into a format that Wolfram Alpha is most likely to understand without throwing errors. Due to the fluid nature of language and the white noise that can affect Echo's understanding of queries, this can be a challenge.
                </p>
                <h2>
                    Challenges I ran into
                </h2>
                <p>
                    The biggest challenge for us was properly parsing human speech to begin with. While Amazon Echo does an excellent job of identifying the words that are spoken, how it passes those words into our function can vary significantly. Making sure we covered as many cases as possible - and ensuring we could convert those cases into Wolfram Alpha queries - was the backbone of our coding.
                </p>
                <h2>
                    Accomplishments that I'm proud of
                </h2>
                <p>
                    Our group split into two parts - one working on parsing Amazon Echo speech and one working on getting results from Wolfram Alpha. For each of us, the accomplishment we're most proud of was simply getting our side of the code to work.
                </p>
                <h2>
                    What I learned
                </h2>
                <p>
                    All of us learned the importance of robust code, as this is one of the biggest drawbacks currently affecting voice recognition. The wide range of possible variable combinations necessitated a great deal of testing to ensure that Wolfram Alexa sent the right queries and returned the correct results.
                </p>
                <h2>
                    What's next for Wolfram Alexa
                </h2>
                <p>
                    If we get a chance to work with Alexa again, we hope to be able to expand the range of queries it can interpret and pass to Wolfram Alpha - for now, it is limited to relatively basic math equations.
                </p>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/amazon-alexa">
                                amazon-alexa
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/python">
                                python
                            </a>
                        </span>
                    </li>
                </ul>
            </div>
            <nav class="app-links section">
                <h2>
                    Try it out
                </h2>
                <ul class="no-bullet" data-role="software-urls">
                    <li>
                        <a href="https://github.com/pchow101/AlexaHackCU" rel="nofollow" target="_blank" title="https://github.com/pchow101/AlexaHackCU">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                github.com
                            </span>
                        </a>
                    </li>
                </ul>
            </nav>
        </div>
    </body>
</html>
