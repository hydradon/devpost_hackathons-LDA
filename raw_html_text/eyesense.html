<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li class="text-center">
                        <a data-lightbox="299024" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/299/024/datas/original.PNG">
                            <img alt="EyeSense &ndash; screenshot 1" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/299/024/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                            </i>
                        </p>
                    </li>
                </ul>
            </div>
            <div>
                <h2>
                    Inspiration
                </h2>
                <p>
                    Communication is essential to the human experience. But individuals who suffer motor paralysis from ALS (amyotrophic lateral sclerosis), GBS (Guillain-Barre Syndrome), spinal cord injury (SCI) or brain-stem infarction have difficulty conveying their intentions because the motor neurons influencing their voluntary muscles have been compromised. The Christopher and Dana Reeves Foundation reports that some 5.6 million people in the US suffer from some form of paralysis, with about 700,000 of them reporting that they were "completely unable to move". Of the 5.6 million people, about 250,000 are under the age of 20. The eyes are directly connected to the brain; if we should suffer through trauma that causes paralysis, they are the last parts of the body on which we can lose control.
                </p>
                <h2>
                    What it does
                </h2>
                <p>
                    EyeSense is a messaging app that lets users send messages by blinking. The Muse EEG wearable device can detect blinking patterns. The app analyzes those patterns and triggers an event. In this version of the product, we have set it to send an SMS saying "I need a doctor" to a "doctor" when the user blinks twice; and to send an SMS saying "I need you here" to a "parent" when the user blinks thrice.
                </p>
                <h2>
                    How we built it
                </h2>
                <p>
                    We have developed a Java application that reads Open Sound Control or OSD data from the Muse device. Our application isolates and analyzes the blinking patterns of the user and once a pattern is established, it triggers the appropriate event - that is, when the user blinks twice or thrice, a specific message is sent to a designated mobile number. The Java application communicates through a PHP web service that leverages the Twilio API deployed in the Linode server.
                </p>
                <h2>
                    Challenges we ran into
                </h2>
                <p>
                    We ran into several challenges:
                </p>
                <ol>
                    <li>
                        We had initially hoped to take advantage of Muse's EEG capabilities. Unfortunately, no one on our team had experience reading raw EEG data. We could not interpret EEG data and so could not use it to trigger controlled, predictable events. We felt we did not have enough time for a crash course into EEG interpretation and decided to take advantage of Muse's simpler eye blink sensing capabilities.
                    </li>
                    <li>
                        Lack of documentation on the Muse developer website; so we did trial by inspection.
                    </li>
                    <li>
                        Formulating an algorithm to identify the blink sequence.
                    </li>
                    <li>
                        Configuration of the Linode server - there were some missing libraries that we had to install.
                    </li>
                </ol>
                <h2>
                    Accomplishments that we're proud of
                </h2>
                <p>
                    We are proud that we accomplished the following:
                </p>
                <ol>
                    <li>
                        We were able to interface the Muse device with the Java application
                    </li>
                    <li>
                        We were able to figure out how to take the data Muse collects when it detects blinking, and make it useful.
                    </li>
                    <li>
                        The thing works!
                    </li>
                </ol>
                <h2>
                    What we learned
                </h2>
                <p>
                    No one on the team had experience developing with hardware. This was a great learning opportunity for all of us. We learned the value of teamwork - we each had a different set of skills (one of us doesn't even have coding experience); we come from different cultures; we have different perspectives, but we were able to come up with what we believe is a promising product.
                </p>
                <h2>
                    What's next for EyeSense
                </h2>
                <p>
                    The Muse wearable device is currently marketed as a meditation aid. It can do so much more. EEG is currently being studied as a noninvasive brain-computer interface. With further development, we can use EEG data to help users perform more sophisticated actions. It also has a lot of potential applications in epilepsy research and stress management research.  Our short term goal is to accomplish our initial idea - using Muse to monitor how a hospital patient is feeling (e.g. anxious, stressed, calm), and sending that information at specific events (e.g. very high anxiety levels) to someone outside the hospital (e.g. an emergency contact, a parent).
                </p>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/java">
                                java
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/linode">
                                linode
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/muse">
                                muse
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/php">
                                php
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/twilio">
                                twilio
                            </a>
                        </span>
                    </li>
                </ul>
            </div>
        </div>
    </body>
</html>
