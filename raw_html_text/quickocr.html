<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li class="text-center">
                        <a data-lightbox="815672" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/815/672/datas/original.png">
                            <img alt="QuickOCR &ndash; screenshot 1" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/815/672/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="815650" data-title="Online user interface, in an easy to access Colab notebook format" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/815/650/datas/original.png">
                            <img alt="QuickOCR &ndash; screenshot 2" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/815/650/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Online user interface, in an easy to access Colab notebook format
                            </i>
                        </p>
                    </li>
                </ul>
            </div>
            <div>
                <h2>
                    Inspiration
                </h2>
                <p>
                    QuickOCR was built to help
                    <a href="https://www.charitableanalytics.org/" rel="nofollow">
                        Charitable Analytics International
                    </a>
                    leverage recent
                    <strong>
                        advances in deep learning
                    </strong>
                    and
                    <strong>
                        optical character recognition
                    </strong>
                    in order to digitize health records, quicker.
                </p>
                <p>
                    Charitable Analytics International takes images of clinical logbooks sent from the field and is developing
                    <a href="http://mezademo.charitableanalytics.org:8080/" rel="nofollow">
                        Meza
                    </a>
                    , a platform to digitize the logbooks in order to help NGOs streamline the delivery of much-needed supplies to health clinics, as well as schools and refugee camps. Meza's accuracy for optical character recognition is currently around 35%. QuickOCR is an
                    <strong>
                        easy to customize model
                    </strong>
                    to help increase Meza's accuracy. Ultimately, we hope to help Meza decrease operational costs as well as ensure judicious resource allocation to those who need it the most!
                </p>
                <h2>
                    What it does
                </h2>
                <p>
                    QuickOCR's online user interface is an
                    <a href="https://colab.research.google.com/drive/1Hu5wQG71078-lvuQtg_pGlVpxaD9fpnR#scrollTo=8K2VG70W3ZI_" rel="nofollow">
                        easy to access Colab notebook
                    </a>
                    that:
                </p>
                <ul>
                    <li>
                        <strong>
                            Walks a user through all steps of digitizing input health records
                        </strong>
                        , from
                        <em>
                            importing data
                        </em>
                        to
                        <em>
                            training and validating the model
                        </em>
                        to
                        <em>
                            obtaining predictions
                        </em>
                        on image sets of interest.
                    </li>
                    <li>
                        <strong>
                            Allows users to upload their own training data
                        </strong>
                        . QuickOCR's model was trained on four datasets: (1)
                        <a href="http://yann.lecun.com/exdb/mnist/" rel="nofollow">
                            MNIST
                        </a>
                        (70,000 labelled handwritten digits), (2)
                        <a href="http://ufldl.stanford.edu/housenumbers/" rel="nofollow">
                            SVHN
                        </a>
                        (600,000 house numbers from Google's Street View), (3)
                        <a href="http://www.image-net.org/" rel="nofollow">
                            ImageNet
                        </a>
                        (14 million images with bounding boxes), and (4) around 5,000 labelled images provided by Meza. As Meza grows and collects more labelled health records, these can be uploaded as additional training data, which will improve QuickOCR's accuracy.
                    </li>
                    <li>
                        <strong>
                            Allows users to customize their model architecture
                        </strong>
                        .
                    </li>
                </ul>
                <p>
                    <img alt="picture" data-canonical-url="https://drive.google.com/uc?id=1x-8wh1AZyB0nZDmTKfvsj0guoZwfpVxi" src="https://res.cloudinary.com/devpost/image/fetch/s--QA0pDi1Q--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://drive.google.com/uc%3Fid%3D1x-8wh1AZyB0nZDmTKfvsj0guoZwfpVxi">
                    <em>
                        QuickOCR's user interface
                    </em>
                </p>
                <h2>
                    How we built it
                </h2>
                <p>
                    QuickOCR's model is a custom 32-layer CNN developed using transfer learning on a ResNet CNN. We used Colab's free GPU compute to train the model. The QuickOCR user application was written in Python using various libraries (Pytorch, Numpy, Pandas, scikit-learn, and fastai). We chose to use Pytorch, a flexible deep learning library, over TensorFlow to leverage the dynamic computation which restricts the freedom of the compiler to optimize, but allows our users to debug and experiment with greater ease, and hopefully will make Meza integration easier for Charitable Analytics International.
                </p>
                <h2>
                    What we learned
                </h2>
                <p>
                    We learned a lot about
                    <strong>
                        convolutional neural networks
                    </strong>
                    ,
                    <strong>
                        optical character recognition
                    </strong>
                    , and
                    <strong>
                        challenges in digitizing handwritten text
                    </strong>
                    . Conversations with Charitable Analytic's mentors also helped us learn a lot about Meza's pain points, which we've summarized
                    <a href="https://docs.google.com/document/d/18mzBu3p58GSw5aTE3pBz6GXtuTBrK5Gu0sqUD_pKvPE/edit" rel="nofollow">
                        here
                    </a>
                    !
                </p>
                <h2>
                    What's next for QuickOCR
                </h2>
                <p>
                    We'd love to work together with Charitable Analytics to help them implement QuickOCR to improve Meza's accuracy. We'd also love to work together with other NGOs to guide them through the process of building, training, and deploying their own models!
                </p>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag">
                            fastai
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/numpy">
                                numpy
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/pandas">
                                pandas
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/python">
                                python
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/pytorch">
                                pytorch
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/scikit-learn">
                                scikit-learn
                            </a>
                        </span>
                    </li>
                </ul>
            </div>
            <nav class="app-links section">
                <h2>
                    Try it out
                </h2>
                <ul class="no-bullet" data-role="software-urls">
                    <li>
                        <a href="https://colab.research.google.com/drive/150EO7x_lWZLnKUO6LSZjuH9p1EEYse0o" rel="nofollow" target="_blank" title="https://colab.research.google.com/drive/150EO7x_lWZLnKUO6LSZjuH9p1EEYse0o">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                colab.research.google.com
                            </span>
                        </a>
                    </li>
                </ul>
            </nav>
        </div>
    </body>
</html>
