<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li>
                        <div class="flex-video">
                            <iframe allowfullscreen="allowfullscreen" allowscriptaccess="always" class="video-embed" frameborder="0" height="371" mode="transparent" src="https://www.youtube.com/embed/lgbhKgSiJyM?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;start=&amp;version=3&amp;wmode=transparent" type="text/html" webkitallowfullscreen="true" width="660" wmode="transparent">
                            </iframe>
                        </div>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="841004" data-title='2-D image rendered by Cartesian plane coordinates of LEAP Motion Sensor, generating "hello" letters from finger-motion gestures above sensor' href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/841/004/datas/original.png">
                            <img alt="Mid Air &ndash; screenshot 1" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/841/004/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                2-D image rendered by Cartesian plane coordinates of LEAP Motion Sensor, generating "hello" letters from finger-motion gestures above sensor
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="841005" data-title='Microsoft Azure Cognitive Services API parses the 2-D image for handwritten text and outputs recognized text as a result. Here: "hello"' href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/841/005/datas/original.png">
                            <img alt="Mid Air &ndash; screenshot 2" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/841/005/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Microsoft Azure Cognitive Services API parses the 2-D image for handwritten text and outputs recognized text as a result. Here: "hello"
                            </i>
                        </p>
                    </li>
                </ul>
            </div>
            <div>
                <h2>
                    Inspiration
                </h2>
                <p>
                    This project acts as the first step to an entirely gesture based computer experience. When paired with a mouse, 
using Mid Air means there is no need to ever touch a keyboard. It's not hard to imagine how a mouse could be replaced by a second Leap Motion, or even an extended version of Mid Air on a single device. This could be built upon even further for more benefits, such as using the movement mapping capabilities of Mid Air for security in the form of in-air signatures. Finally, the simple hand gestures involved make this product a good alternative for people with limited digit mobility, and means those with few fingers don't have to rely on a 'hunt-and-peck' method.
                </p>
                <h2>
                    What it does
                </h2>
                <p>
                    Mid Air uses the Leap Motion's precise hand tracking and Azure Cognitive Services' text recognition to enable in-air handwriting as a text input to a computer. Simply write a word with your finger over the sensor, and watch as it is analyzed and extracted to your copy clipboard.
                </p>
                <h2>
                    How we built it
                </h2>
                <p>
                    The Leap Motion tracks the tip of the index finger of a hand held above it, the up, down, left, and right movements of this tracking point are used like the movements of a pen on paper to generate an image of what was written. This image goes through some pre-processing before being submitted to Azure Cognitive Services for text extraction. Finally, any text which is found is pushed into the copy clipboard.
                </p>
                <h2>
                    Challenges we ran into
                </h2>
                <p>
                    There was quite a bit of challenge in setting up the pre-processing so that Azure could (relatively) reliably understand that it was being shown some form of text.
                </p>
                <h2>
                    Accomplishments that we're proud of
                </h2>
                <p>
                    The product produces semi-reliable results despite how difficult it can be to be accurate when drawing in the air.
                </p>
                <h2>
                    What we learned
                </h2>
                <p>
                    A lot more about python data and image manipulation. Also how to make a GUI in Python.
                </p>
                <h2>
                    What's next for mid air
                </h2>
                <p>
                    Ideally it wouldn't need any GUI controls whatsoever. Through Leap Motion's gesture recognition, we would like to enable starting/stopping recording, as well as adding spaces and periods, and pasting the generated text.
                </p>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/python">
                                python
                            </a>
                        </span>
                    </li>
                </ul>
            </div>
            <nav class="app-links section">
                <h2>
                    Try it out
                </h2>
                <ul class="no-bullet" data-role="software-urls">
                    <li>
                        <a href="https://github.com/gapope/Mid-Air" rel="nofollow" target="_blank" title="https://github.com/gapope/Mid-Air">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                github.com
                            </span>
                        </a>
                    </li>
                </ul>
            </nav>
        </div>
    </body>
</html>
