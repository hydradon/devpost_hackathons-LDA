<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li>
                        <div class="flex-video">
                            <iframe allowfullscreen="allowfullscreen" allowscriptaccess="always" class="video-embed" frameborder="0" height="371" mode="transparent" src="https://www.youtube.com/embed/uxhcuM7AFL0?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;start=&amp;version=3&amp;wmode=transparent" type="text/html" webkitallowfullscreen="true" width="660" wmode="transparent">
                            </iframe>
                        </div>
                    </li>
                </ul>
            </div>
            <div>
                <h2>
                    Inspiration
                </h2>
                <p>
                    One day one of our members asked if he could get the computer to scroll using his face. At the time he was joking, but we realized that we could expand on the idea and bring it to reality.
                </p>
                <h2>
                    What it does
                </h2>
                <p>
                    FaceIt! tracks the movement and various properties of facial features to recognize a wide array of hands free gestures. Our program was built with ease of use in mind for a wide audience. FaceIt! can be used as an accessibility feature for the handicapped, or just for convenience.
                </p>
                <h2>
                    How we built it
                </h2>
                <p>
                    We decided to use Python as our language of choice for its simplicity and because all our members are familiar with it. We had heard of OpenCV and its capabilities before, so we immediately gravitated toward it for our vision processing workload. We used Haar-feature based cascade classifiers to recognize several different facial features such as eyes, the mouth, and the outline of the face as a whole. We then used other OpenCV capabilities to track those facial features and recognize different gestures such as face tilting, turning, and winking. We used the pyautogui library to translate gestures into actions executed on the computer and used Google's speech-to-text API for translating user speech.
                </p>
                <h2>
                    Challenges we ran into
                </h2>
                <p>
                    We ran into struggles along multiple steps of the process, but the major ones we encountered were difficulty installing OpenCV and obtaining satisfactory
                </p>
                <h2>
                    Accomplishments that we're proud of
                </h2>
                <p>
                    We are proud that we were able to complete a project which we considered ambitious - almost too much so - when we began this event.
                </p>
                <h2>
                    What we learned
                </h2>
                <p>
                    We all gained experience with OpenCV and working on a full project from conception to delivery in such a restricted time frame, which none of us have ever done before. Some members of the team also learned to use Git for version control for the first time and we all gained experience using Python in an environment we had never encountered before.
                </p>
                <h2>
                    What's next for FaceIt!
                </h2>
                <p>
                    We plan to improve the accuracy of face tilt and turn recognition using the user's eyes as additional reference points. We also plan to change the way different gestures interact to prevent the possibility of multiple gestures being inadvertently recognized at once and refine the algorithm we use to implement the auto-lock and auto-unlock features to eliminate false negatives on face recognition.
                </p>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag">
                            google-speech-to-text
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/opencv">
                                opencv
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag">
                            pyautogui
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/python">
                                python
                            </a>
                        </span>
                    </li>
                </ul>
            </div>
            <nav class="app-links section">
                <h2>
                    Try it out
                </h2>
                <ul class="no-bullet" data-role="software-urls">
                    <li>
                        <a href="https://github.com/tkadur/HackCMU2016" rel="nofollow" target="_blank" title="https://github.com/tkadur/HackCMU2016">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                github.com
                            </span>
                        </a>
                    </li>
                </ul>
            </nav>
        </div>
    </body>
</html>
