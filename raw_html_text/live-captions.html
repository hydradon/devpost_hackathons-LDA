<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li>
                        <div class="flex-video">
                            <iframe allowfullscreen="allowfullscreen" allowscriptaccess="always" class="video-embed" frameborder="0" height="371" mode="transparent" src="https://www.youtube.com/embed/aPhK6EtLEPw?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;start=&amp;version=3&amp;wmode=transparent" type="text/html" webkitallowfullscreen="true" width="660" wmode="transparent">
                            </iframe>
                        </div>
                    </li>
                </ul>
            </div>
            <div>
                <h2>
                    Inspiration
                </h2>
                <p>
                    Our inspiration is my brother who is a big fan of Apple products and who wanted to watch Apple Keynote Livestreams badly but couldn't understand a thing because of his poor English skills. My brother and our family members who are non-native English speakers, people who are hearing impaired and differently abled face this problem day-in and day-out when they try to consume content whose audio doesn't make much sense for them.
                </p>
                <h2>
                    What it does
                </h2>
                <p>
                    Our hack generates closed captions in real-time in the speakers' language (and live "translations" in other languages - planned extension: WIP). This is helpful for hearing impaired and also lifts language barrier for a worldwide audience of any useful media they can benefit from.
                </p>
                <h2>
                    How we built it
                </h2>
                <p>
                    We source our captions from multiple systems (some of our own) and stitch them together with an intelligent algorithm that can come up with most accurate transcriptions.
                </p>
                <h2>
                    Challenges we ran into
                </h2>
                <p>
                    Streaming video, integrating and normalizing multiple third-party Speech-to-Text APIs, the accurate stitching with limited metadata about the stream etc.,
                </p>
                <h2>
                    Accomplishments that we're proud of
                </h2>
                <p>
                    The accuracy of the stitching algorithm that we came up in a very short time, our benchmarking utility to measure the accuracy of any stream, the end-to-end solution we built, and our creative presentation "with captions instead of usual audio"
                </p>
                <h2>
                    What we learned
                </h2>
                <p>
                    Learned a bunch of latest technologies/frameworks. To build fast, fail fast and iterate. The accuracy levels that we were able to come up are far higher than we imagined.
                </p>
                <h2>
                    What's next for Live Captions
                </h2>
                <p>
                    YC W2018
                </p>
                <p>
                    <strong>
                        NOTE:
                    </strong>
                    Please turn on the CAPTIONS on the demo video. It is intentionally lacking audio, to demonstrate the power of captions.
                </p>
            </div>
        </div>
    </body>
</html>
