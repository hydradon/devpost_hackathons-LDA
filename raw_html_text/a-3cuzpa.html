<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li>
                        <div class="flex-video">
                            <iframe allowfullscreen="allowfullscreen" allowscriptaccess="always" class="video-embed" frameborder="0" height="371" mode="transparent" src="https://www.youtube.com/embed/DQDYsJXLqlo?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;start=&amp;version=3&amp;wmode=transparent" type="text/html" webkitallowfullscreen="true" width="660" wmode="transparent">
                            </iframe>
                        </div>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="906201" data-title="WGAN-GP algorithm" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/906/201/datas/original.png">
                            <img alt="MusicGAN &ndash; screenshot 1" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/906/201/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                WGAN-GP algorithm
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="906213" data-title="Fake waveform, spectrogram and F0 contour" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/906/213/datas/original.png">
                            <img alt="MusicGAN &ndash; screenshot 2" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/906/213/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Fake waveform, spectrogram and F0 contour
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="906215" data-title="Real waveform, spectrogram and F0 contour (notice the more distinct horizontal regions)" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/906/215/datas/original.png">
                            <img alt="MusicGAN &ndash; screenshot 3" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/906/215/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Real waveform, spectrogram and F0 contour (notice the more distinct horizontal regions)
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="906257" data-title="Critic loss" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/906/257/datas/original.png">
                            <img alt="MusicGAN &ndash; screenshot 4" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/906/257/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Critic loss
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="906258" data-title="Generator loss" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/906/258/datas/original.png">
                            <img alt="MusicGAN &ndash; screenshot 5" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/906/258/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Generator loss
                            </i>
                        </p>
                    </li>
                </ul>
            </div>
            <div>
                <h1>
                    tfworldhackathon
                </h1>
                <p>
                    GitHub repo for my Tensorflow World hackathon submission
                </p>
                <h2>
                    Inspiration
                </h2>
                <p>
                    Since the inception of generative adversarial networks, I have been fascinated by their capacity to perform tasks of unprecedented complexity. They are a prime example of how machines can learn in a similar manner to humans - akin to reinforcement learning. I am also a huge fan of music and love to play the piano. So I thought, why not conflate my love for machine learning and my passion for music!?
                </p>
                <p>
                    Music generation has many different and exciting potential applications such as:
                </p>
                <ul>
                    <li>
                        Providing melody inspiration to artists
                    </li>
                    <li>
                        Creating infinite, unique and free music without the need for audio file storage (for retail shops, restaurants, cafes, video games, radio stations etc.)
                    </li>
                </ul>
                <p>
                    GANs are already well-established in the image-processing domain, but not so much in NLP or audio-processing due to their sequential structure. After some investigaton, I learned about
                    <a href="https://arxiv.org/abs/1802.04208" rel="nofollow">
                        WaveGAN
                    </a>
                    . So, I set out to adapt WaveGAN for piano in Tensorflow 2.0 using WGAN-GP as my training mechanism (as recommended by the paper).
                </p>
                <h2>
                    What it does
                </h2>
                <p>
                    MusicGAN generates approximately one second of music (from a particular instrument i.e. piano) given a random noise vector. The majority of existing technologies generate
                    <a href="https://en.wikipedia.org/wiki/MIDI" rel="nofollow">
                        MIDI
                    </a>
                    files, which contains information such as the notes and tempo of a song, but do not contain any audio data. This approach loses the character and personality of music that can't simply be transcribed.
                </p>
                <p>
                    I have also created a JavaScript model for implementation in webpages down the track.
                </p>
                <h2>
                    How I built it
                </h2>
                <p>
                    I adapted code for
                    <a href="https://github.com/LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2/blob/master/train.py" rel="nofollow">
                        WGAN-GP
                    </a>
                    and created my own
                    <a href="https://github.com/chrisdonahue/wavegan" rel="nofollow">
                        WaveGAN
                    </a>
                    using Tensorflow-GPU 2.0. I tried developing my script to be as transparent as possible so that someone can look at it, change some parameters, and get going.
                </p>
                <p>
                    I took a highly systematic and methodical approach, since a lot of my work was writing code based off of research papers, or needing conversion from Tensorflow 1.x.
                </p>
                <p>
                    Firstly, I trained a regular GAN on the MNIST dataset using WGAN-GP to ensure that I had implemented the training algorithm correctly. Next, I used an old Tensorflow 1.x WaveGAN implementation with my architecture to be certain that my generator and critic models were correct. Then I inserted my generator and critic models into my WGAN-GP infrastructure, replacing the MNIST GAN. Lastly, I tested the script on the same audio datasets used in the WaveGAN paper to make sure everything was ready to go. Finally, I started running my script on piano audio, adjusting hyperparameters and optimizing my models' architecture (trying to avoid mode collapse and failure to converge).
                </p>
                <h2>
                    Challenges I ran into
                </h2>
                <p>
                    I spent quite a bit of time getting used to
                    <code>
                        tensorflow.GradientTape
                    </code>
                    and watching tensors etc. This was new to me since this project was my first shot at using Tensorflow 2.0. The majority of errors I faced were due to implementation/import mistakes, which I scoured GitHub to solve. In particular, finding elegant workarounds for functions contained in
                    <code>
                        tensorflow.contrib
                    </code>
                    proved to be challenging. Annoyingly, many solutions made use of
                    <code>
                        tf.compat.v1
                    </code>
                    , so I had to circumvent the problem some other way.
                </p>
                <p>
                    Additionally, I had to maintain constant consideration with regards to my computation capacity. My PC has a Nvidia RTX 2060, but training still took many many hours, and I had to use small batch sizes.
                </p>
                <h2>
                    Accomplishments that I'm proud of
                </h2>
                <p>
                    In light of the fact that I wasn't familiar with the new API, had never heard of WaveGAN or WGAN-GP and had hardware limitations, I am proud to say that I gave the project my best shot.
                </p>
                <h2>
                    What I learned
                </h2>
                <p>
                    I can now say that I can train a GAN in Tensorflow 2.0, and I have also improved a lot of accessory skills involving numpy, matplotlib, tensorboard. Also, my understanding of CNNs, ReLU, transposed convolutions and general training monitoring techniques has deepened.
                </p>
                <h2>
                    What's next for this project
                </h2>
                <p>
                    I am currently exploring the generation of other musical instrument sounds, such as the violin and saxaphone. My next goal is to create a recurrent version of WaveGAN by using LSTM's and minature WaveGAN's to produce short segments of audio in a sequentially. This would allow for any duration of audio to be created.
                </p>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag">
                            cuda
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag">
                            cudnn
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag">
                            keras
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag">
                            librosa
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/pandas">
                                pandas
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/python">
                                python
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag">
                            tensorflow
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag">
                            tensorflow-2
                        </span>
                    </li>
                </ul>
            </div>
            <nav class="app-links section">
                <h2>
                    Try it out
                </h2>
                <ul class="no-bullet" data-role="software-urls">
                    <li>
                        <a href="https://github.com/HStuart18/tfworldhackathon" rel="nofollow" target="_blank" title="https://github.com/HStuart18/tfworldhackathon">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                github.com
                            </span>
                        </a>
                    </li>
                </ul>
            </nav>
        </div>
    </body>
</html>
