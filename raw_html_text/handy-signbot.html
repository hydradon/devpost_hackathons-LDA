<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li class="text-center">
                        <a data-lightbox="466664" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/466/664/datas/original.jpg">
                            <img alt="Signbot &ndash; screenshot 1" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/466/664/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                            </i>
                        </p>
                    </li>
                </ul>
            </div>
            <div>
                <h2>
                    Inspiration
                </h2>
                <p>
                    Sign language is already difficult to learn; adding on the difficulty of learning movements from static online pictures makes it next to impossible to do without help. We came up with an elegant robotic solution to remedy this problem.
                </p>
                <h2>
                    What it does
                </h2>
                <p>
                    Handy Signbot is a tool that translates voice to sign language, displayed using a set of prosthetic arms. It is a multipurpose sign language device including uses such as: a teaching model for new students, a voice to sign translator for live events, or simply a communication device between voice and sign.
                </p>
                <h2>
                    How we built it
                </h2>
                <p>
                    <strong>
                        Physical
                    </strong>
                    : The hand is built from 3D printed parts and is controlled by several servos and pulleys. Those are in turn controlled by Arduinos, housing all the calculations that allow for finger control and semi-spherical XYZ movement in the arm. The entire setup is enclosed and protected by a wooden frame.
                </p>
                <p>
                    <strong>
                        Software
                    </strong>
                    : The bulk of the movement control is written in NodeJS, using the Johnny-Five library for servo control. Voice to text is process using the Nuance API, and text to sign is created with our own database of sign movements.
                </p>
                <h2>
                    Challenges we ran into
                </h2>
                <p>
                    The Nuance library was not something we have worked with before, and took plenty of trial and error before we could eventually implement it. Other difficulties included successfully developing a database, and learning to recycle movements to create more with higher efficiency.
                </p>
                <h2>
                    Accomplishments that we're proud of
                </h2>
                <p>
                    From calculating inverse trigonometry to processing audio, several areas had to work together for anything to work at all. We are proud that we were able successfully combine so many different parts together for one big project.
                </p>
                <h2>
                    What we learned
                </h2>
                <p>
                    We learned about the importance of teamwork and friendship :)
                </p>
                <h2>
                    What's next for Handy Signbot
                </h2>
                <p>
                    -Creating a smaller scale model that is more realistic for a home environment, and significantly reducing cost at the same time.
                </p>
                <p>
                    -Reimplement the LeapMotion to train the model for an increased vocabulary, and different accents (did you know you can have an accent in sign language too?).
                </p>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/arduino">
                                arduino
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/nuance">
                                nuance
                            </a>
                        </span>
                    </li>
                </ul>
            </div>
            <nav class="app-links section">
                <h2>
                    Try it out
                </h2>
                <ul class="no-bullet" data-role="software-urls">
                    <li>
                        <a href="https://github.com/toastify/signbot-talk" rel="nofollow" target="_blank" title="https://github.com/toastify/signbot-talk">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                github.com
                            </span>
                        </a>
                    </li>
                </ul>
            </nav>
        </div>
    </body>
</html>
