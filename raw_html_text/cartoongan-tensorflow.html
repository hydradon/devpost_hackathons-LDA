<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li class="text-center">
                        <a data-lightbox="808245" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/808/245/datas/original.jpg">
                            <img alt="CartoonGan-tensorflow &ndash; screenshot 1" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/808/245/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-gif-player="true" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/808/246/datas/original.gif">
                            <img alt="CartoonGan-tensorflow &ndash; screenshot 2" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/808/246/datas/gallery.jpg">
                        </a>
                        <span class="gif-tag">
                            GIF
                        </span>
                        <a class="gif-play">
                            <i class="fas fa-play">
                            </i>
                        </a>
                        <p>
                            <i>
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="808247" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/808/247/datas/original.jpg">
                            <img alt="CartoonGan-tensorflow &ndash; screenshot 3" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/808/247/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="808248" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/808/248/datas/original.jpg">
                            <img alt="CartoonGan-tensorflow &ndash; screenshot 4" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/808/248/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                            </i>
                        </p>
                    </li>
                </ul>
            </div>
            <div>
                <h1>
                    CartoonGAN-TensorFlow2
                </h1>
                <p>
                    Generate your own cartoon-style images with
                    <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.pdf" rel="nofollow">
                        CartoonGAN (CVPR 2018)
                    </a>
                    , powered by
                    <a href="https://www.tensorflow.org/alpha" rel="nofollow">
                        TensorFlow 2.0 Alpha
                    </a>
                    .
                </p>
                <p>
                    Check our blog posts with project overview, online demo and gallery of generated anime:
                </p>
                <table class="responsive">
                    <thead>
                        <tr>
                            <th>
                                Blog post
                            </th>
                            <th>
                                Language
                            </th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>
                                <a href="https://leemeng.tw/generate-anime-using-cartoongan-and-tensorflow2-en.html" rel="nofollow">
                                    Generate Anime using CartoonGAN and TensorFlow 2.0
                                </a>
                            </td>
                            <td>
                                English
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <a href="https://leemeng.tw/generate-anime-using-cartoongan-and-tensorflow2.html" rel="nofollow">
                                    用 CartoonGAN 及 TensorFlow 2 生成新海誠與宮崎駿動畫
                                </a>
                            </td>
                            <td>
                                繁體中文（Traditional Chinese）
                            </td>
                        </tr>
                    </tbody>
                </table>
                <p>
                    <img alt="cat" data-canonical-url="https://github.com/mnicnc404/CartoonGan-tensorflow/raw/master/images/cover.gif" src="https://res.cloudinary.com/devpost/image/fetch/s--C6uTFOry--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://github.com/mnicnc404/CartoonGan-tensorflow/raw/master/images/cover.gif">
                </p>
                <p>
                    Top-left corner is real world image, and the other 3 images are generated by CartoonGAN using different anime styles.
                </p>
                <p>
                    This repo demonstrates how to:
                </p>
                <ul>
                    <li>
                        <a href="#Train-your-own-CartoonGAN" rel="nofollow">
                            Train your own CartoonGAN
                        </a>
                    </li>
                    <li>
                        <a href="#generate-anime-using-trained-cartoongan" rel="nofollow">
                            Generate anime using trained CartoonGAN
                        </a>
                    </li>
                </ul>
                <h2>
                    Train your own CartoonGAN
                </h2>
                <p>
                    In this section, we will explain how to train a CartoonGAN using the script we provide.
                </p>
                <h3>
                    Setup Environment
                </h3>
                <p>
                    First clone this repo:
                </p>
                <pre class="language-bash"><code>git clone https://github.com/mnicnc404/CartoonGan-tensorflow.git
</code></pre>
                <p>
                    To run code in this repo properly, you will need:
                </p>
                <ul>
                    <li>
                        <a href="https://www.python.org/downloads/release/python-360/" rel="nofollow">
                            Python 3.6
                        </a>
                    </li>
                    <li>
                        <a href="https://www.tensorflow.org/alpha" rel="nofollow">
                            TensorFlow 2.0 Alpha
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/tqdm/tqdm" rel="nofollow">
                            tqdm
                        </a>
                    </li>
                    <li>
                        <a href="https://pypi.org/project/imageio/" rel="nofollow">
                            imageio
                        </a>
                    </li>
                    <li>
                        <a href="https://pypi.org/project/tb-nightly/" rel="nofollow">
                            tb-nightly
                        </a>
                    </li>
                </ul>
                <p>
                    For environment management, we recommend
                    <a href="https://www.anaconda.com/" rel="nofollow">
                        Anaconda
                    </a>
                    . If GPU is available, you can install all the packages simply using:
                </p>
                <pre class="language-bash"><code>conda env create -n cartoongan -f environment_gpu.yml
conda activate cartoongan
# to deactivate this env, run "conda deactivate"
</code></pre>
                <p>
                    Although it is not recommended to train CartoonGANs without a GPU, you can still set up environment by running:
                </p>
                <pre class="language-bash"><code>conda env create -n cartoongan -f environment_cpu.yml
conda activate cartoongan
# to deactivate this env, run "conda deactivate"
</code></pre>
                <p>
                    If Anaconda is not available, you can also run:
                </p>
                <pre class="language-bash"><code>pip install -r requirements_gpu.txt
# use `requirements_cpu` if GPU is not available
</code></pre>
                <p>
                    You will also need TensorFlow version of
                    <a href="https://github.com/keras-team/keras-contrib" rel="nofollow">
                        keras-contrib
                    </a>
                    for some custom Keras layers used in our CartoonGAN implementation:
                </p>
                <pre class="language-bash"><code>git clone https://www.github.com/keras-team/keras-contrib.git \
                &amp;&amp; cd keras-contrib \
    &amp;&amp; python convert_to_tf_keras.py \
    &amp;&amp; USE_TF_KERAS=1 python setup.py install
</code></pre>
                <p>
                    If all above complete successfully, you're good to go.
                </p>
                <h3>
                    Prepare Dataset
                </h3>
                <p>
                    You also need to prepare your own dataset and arrange the images under
                    <code>
                        datasets
                    </code>
                    folder as below:
                </p>
                <pre class="language-text"><code>datasets
└── YourDataset [your dataset name]
├── testA [(must) 8 real-world images for evaluation]
├── trainA [(must) (source) real-world images]
├── trainB [(must) (target) cartoon images]
└── trainB_smooth [(must, but can be generated by running scripts/smooth.py) cartoon images with smooth edges]
</code></pre>
                <p>
                    <code>
                        trainA
                    </code>
                    and
                    <code>
                        testA
                    </code>
                    folders contain real-world images, while
                    <code>
                        trainB
                    </code>
                    contain images with desired cartoon style. Notice that 8 images in
                    <code>
                        testA
                    </code>
                    folder will be evaluated after each epoch, so they should not appear in
                    <code>
                        trainA
                    </code>
                    .
                </p>
                <p>
                    In order to generate
                    <code>
                        trainB_smooth
                    </code>
                    , you can run
                    <code>
                        scripts/smooth.py
                    </code>
                    :
                </p>
                <pre class="language-nolang"><code>python path/to/smooth.py --path path/to/datasets/YourDataset  # YourDataset should contain trainB for executing this script

</code></pre>
                <p>
                    <a href="https://github.com/taki0112/CartoonGAN-Tensorflow/blob/master/edge_smooth.py" rel="nofollow">
                        smooth.py credit to taki0112 https://github.com/taki0112/CartoonGAN-Tensorflow/blob/master/edge_smooth.py
                    </a>
                </p>
                <h3>
                    Start training
                </h3>
                <p>
                    Although you may have to tune hyperparameters to generate best result for your own datasets, train following settings that we found effective can be your starting point.
                </p>
                <p>
                    If you get more than 16GB memory in your GPU, you can try these settings (Note that
                    <code>
                        --light
                    </code>
                    indicates that we are training GAN with a light-weight generator):
                </p>
                <pre class="language-bash"><code>python train.py \
                --batch_size 8 \
    --pretrain_epochs 1 \
    --content_lambda .4 \
    --pretrain_learning_rate 2e-4 \
    --g_adv_lambda 8. \
    --generator_lr 8e-5 \
    --discriminator_lr 3e-5 \
    --style_lambda 25. \
    --light \
    --dataset_name {your dataset name}
</code></pre>
                <p>
                    Note that
                    <code>
                        style_lambda
                    </code>
                    is for
                    <code>
                        style loss
                    </code>
                    <a href="https://arxiv.org/abs/1508.06576" rel="nofollow">
                        (source)
                    </a>
                    .
If your GPU does not have 16GB memory, you can use a smaller
                    <code>
                        batch_size
                    </code>
                    and use lower learning rates accordingly. For example, for
                    <code>
                        batch_size = 4
                    </code>
                    , you can try:
                </p>
                <pre class="language-bash"><code>python train.py \
                --batch_size 4 \
    --pretrain_epochs 1 \
    --content_lambda .4 \
    --pretrain_learning_rate 1e-4 \
    --g_adv_lambda 8. \
    --generator_lr 4e-5 \
    --discriminator_lr 1.5e-5 \
    --style_lambda 25. \
    --light \
    --dataset_name {your dataset name}
</code></pre>
                <p>
                    <img alt="train-demo" data-canonical-url="images/train-demo.gif" src="https://res.cloudinary.com/devpost/image/fetch/s--Ro5B54lh--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/v1/images/train-demo.gif">
                </p>
                <p>
                    Detailed log messages, model architecture and progress bar are all provided. This enable you to gain a better understanding of what is happening when training a CartoonGAN.
                </p>
                <h3>
                    Choose model architecture
                </h3>
                <p>
                    Notice that we specified
                    <code>
                        --light
                    </code>
                    in our previous example:
                </p>
                <pre class="language-bash"><code>python train.py \
                ...
    --light \
    ...
</code></pre>
                <p>
                    When specified,
                    <a href="train.py" rel="nofollow">
                        train.py
                    </a>
                    will initialize a light-weight
                    <a href="generator.py" rel="nofollow">
                        generator
                    </a>
                    for training a CartoonGAN.
                </p>
                <p>
                    When we design the light-weight generator,
                    <a href="https://arxiv.org/abs/1807.11164" rel="nofollow">
                        ShuffleNet V2
                    </a>
                    is taken as our reference. This generator is designed to minimalize inference time while achieving similar effect. We will make some minor adjustments to
                    <a href="discriminator.py" rel="nofollow">
                        discriminator
                    </a>
                    as well when
                    <code>
                        --light
                    </code>
                    is specified.
                </p>
                <p>
                    <img alt="generator" data-canonical-url="https://github.com/mnicnc404/CartoonGan-tensorflow/raw/master/images/generator.png" src="https://res.cloudinary.com/devpost/image/fetch/s--HPgswYKG--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://github.com/mnicnc404/CartoonGan-tensorflow/raw/master/images/generator.png">
                </p>
                <p>
                    Generator proposed by the original CartoonGAN authors
                </p>
                <p>
                    To train a CartoonGAN with the original generator/discriminator architecture proposed by the
                    <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.pdf" rel="nofollow">
                        CartoonGAN
                    </a>
                    authors, simply remove
                    <code>
                        --light
                    </code>
                    option:
                </p>
                <pre class="language-bash"><code>python train.py \
                --batch_size 8 \
    --pretrain_epochs 1 \
    --content_lambda .4 \
    --pretrain_learning_rate 2e-4 \
    --g_adv_lambda 8. \
    --generator_lr 8e-5 \
    --discriminator_lr 3e-5 \
    --style_lambda 25. \
    --dataset_name {your dataset name}
</code></pre>
                <h3>
                    Monitor your training progress
                </h3>
                <p>
                    In our repo, TensorBoard is integrated perfectly so you can monitor model's performance easily by:
                </p>
                <pre class="language-bash"><code>tensorboard --logdir runs
</code></pre>
                <p>
                    After training for awhile, you should be able to see something like this:
                </p>
                <p>
                    <img alt="tensorboard-metrics" data-canonical-url="https://github.com/mnicnc404/CartoonGan-tensorflow/raw/master/images/tensorboard-metrics.jpg" src="https://res.cloudinary.com/devpost/image/fetch/s--oy9Mzc1M--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://github.com/mnicnc404/CartoonGan-tensorflow/raw/master/images/tensorboard-metrics.jpg">
                </p>
                <p>
                    In addition to metrics and loss functions, it is good practice to keep an eye on the images generated by GAN during training as well. Using our script, monitoring generated images on TensorBoard is a no-brainer:
                </p>
                <p>
                    <img alt="tensorboard-image-demo" data-canonical-url="https://github.com/mnicnc404/CartoonGan-tensorflow/raw/master/images/tensorboard-image-demo.jpg" src="https://res.cloudinary.com/devpost/image/fetch/s--AIk2s0_u--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://github.com/mnicnc404/CartoonGan-tensorflow/raw/master/images/tensorboard-image-demo.jpg">
                </p>
                <p>
                    For further details about training, we recommend reading
                    <a href="train.py" rel="nofollow">
                        train.py
                    </a>
                    .
                </p>
                <h3>
                    Inference with trained checkpoint
                </h3>
                <p>
                    Once your generator is well-trained, you can try cartoonizing with your trained checkpoint:
                </p>
                <pre class="language-nolang"><code># You should specify --light if your model is trained with --light
# If you didn't specify --light on your training, you should remove --light
# default of --out_dir is out
python inference_with_ckpt.py \
--m_path path/to/model/folder \
--img_path path/to/your/img.jpg \
--out_dir path/to/your/desired/output/folder \
--light
</code></pre>
                <p>
                    And generated image will be saved to
                    <code>
                        path/to/your/desired/output/folder/img.jpg
                    </code>
                    .
                </p>
                <h3>
                    Export checkpoint to SavedModel and tfjs
                </h3>
                <p>
                    Once your generator is well-trained, you can export your model to tfjs model and SavedModel:
                </p>
                <pre class="language-nolang"><code># You should specify --light if your model is trained with --light
# If you didn't specify --light on your training, you should remove --light
# default of --out_dir is exported_models
python export.py \
--m_path path/to/model/folder \
--out_dir path/to/your/desired/export/folder \
--light
</code></pre>
                <p>
                    And exported tfjs model and SavedModel will be saved to
                    <code>
                        path/to/your/desired/export/folder
                    </code>
                    .
                </p>
                <p>
                    Note that the whole model architecture is saved to SavedModel and tfjs model, so you don't need to specify
                    <code>
                        --light
                    </code>
                    anymore.
                </p>
                <p>
                    You can try cartoonizing with your exported SavedModel:
                </p>
                <pre class="language-nolang"><code># default of --out_dir is out
python inference_with_saved_model.py \
--m_path path/to/your/exported/SavedModelFolder \
--img_path path/to/your/img.jpg \
--out_dir path/to/your/desired/output/folder
</code></pre>
                <p>
                    And generated image will be saved to
                    <code>
                        path/to/your/desired/output/folder/img.jpg
                    </code>
                    .
                </p>
                <p>
                    We trained 2 model checkpoints and put them in the repo:
                    <code>
                        light_paprika_ckpt
                    </code>
                    and
                    <code>
                        light_shinkai_ckpt
                    </code>
                    (~7MB Total). You can play around the ckpts with
                    <code>
                        inference_with_ckpt.py
                    </code>
                    and
                    <code>
                        export.py
                    </code>
                    .
                </p>
                <p>
                    Also, we put our exported shinkai and paprika SavedModels in
                    <code>
                        exported_models
                    </code>
                    (~11MB Total). You can play around the SavedModels with
                    <code>
                        inference_with_saved_model.py
                    </code>
                    .
                </p>
                <p>
                    Image generated using our
                    <code>
                        exported_models/light_paprika_SavedModel
                    </code>
                    (left: original; right: generated):
                    <img alt="origami_demo.jpg" data-canonical-url="https://github.com/mnicnc404/CartoonGan-tensorflow/raw/master/images/origami_demo.jpg" src="https://res.cloudinary.com/devpost/image/fetch/s--D0QO-q-m--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://github.com/mnicnc404/CartoonGan-tensorflow/raw/master/images/origami_demo.jpg">
                </p>
                <h3>
                    (Will be deprecated) Export checkpoint to frozen_pb
                </h3>
                <p>
                    This script is just a demontration of backward compatibility.
                </p>
                <pre class="language-nolang"><code># You should specify --light if your model is trained with --light
# If you didn't specify --light on your training, you should remove --light
# default of --out_dir is optimized_pbs
python to_pb.py \
--m_path path/to/your/exported/SavedModelFolder \
--out_dir path/to/your/desired/export/folder \
--light
</code></pre>
                <h2>
                    Generate anime using trained CartoonGAN
                </h2>
                <p>
                    In this section, we explain how to generate anime using
                    <strong>
                        trained
                    </strong>
                    CartoonGAN.
                </p>
                <p>
                    If you don't want to train a CartoonGAN yourself (but want to generate anime anyway), you can simply visit
                    <a href="https://leemeng.tw/generate-anime-using-cartoongan-and-tensorflow2-en.html" rel="nofollow">
                        CartoonGAN web demo
                    </a>
                    or run
                    <a href="https://colab.research.google.com/drive/1WIZBHix_cYIGsBKa4phIwCq5qXwO8fRX" rel="nofollow">
                        this colab notebook
                    </a>
                    .
                </p>
                <p>
                    We will describe these methods in details in one minute.
                </p>
                <h3>
                    3 ways to use CartoonGANs
                </h3>
                <p>
                    Basically, there are 3 approachs to generate cartoon-style images in this repo:
                </p>
                <table class="responsive">
                    <thead>
                        <tr>
                            <th>
                                Approach
                            </th>
                            <th>
                                Description
                            </th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>
                                <a href="#cartoonize-using-tensorflowjs" rel="nofollow">
                                    Cartoonize using TensorFlow.js
                                </a>
                            </td>
                            <td>
                                Cartoonize images with TensorFlow.js on browser, no setup needed
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <a href="#cartoonize-using-colab-notebook" rel="nofollow">
                                    Cartoonize using Colab Notebook
                                </a>
                            </td>
                            <td>
                                Google Colab let us use free GPUs to cartoonize images faster
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <a href="#clone-this-repo-and-run-script" rel="nofollow">
                                    Clone this repo and run script
                                </a>
                            </td>
                            <td>
                                Suitable for power users and those who want to make this repo better :)
                            </td>
                        </tr>
                    </tbody>
                </table>
                <p>
                    You can start with preferred approach or watch the demos first (shown below).
                </p>
                <h3>
                    <a href="https://leemeng.tw/generate-anime-using-cartoongan-and-tensorflow2-en.html" rel="nofollow">
                        Cartoonize using TensorFlow.js
                    </a>
                </h3>
                <p>
                    This is by far the easiest way to interact with the CartoonGAN. Just visit our
                    <a href="https://leemeng.tw/generate-anime-using-cartoongan-and-tensorflow2-en.html" rel="nofollow">
                        blog post with web demo
                    </a>
                    and upload your images:
                </p>
                <p>
                    <img alt="tfjs-demo" data-canonical-url="https://github.com/mnicnc404/CartoonGan-tensorflow/raw/master/images/tfjs-demo.gif" src="https://res.cloudinary.com/devpost/image/fetch/s--oePY5MWz--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://github.com/mnicnc404/CartoonGan-tensorflow/raw/master/images/tfjs-demo.gif">
                </p>
                <p>
                    You can right-click on the result to save it.
                </p>
                <p>
                    Under the hood, the webpage utilize
                    <a href="https://www.tensorflow.org/js" rel="nofollow">
                        TensorFlow.js
                    </a>
                    to load the pretrained models and transform your images. However, due to the computation limits of the browsers, this approach currently only support static and relatively small images. If you want to transform gifs, keep reading.
                </p>
                <h3>
                    <a href="https://colab.research.google.com/drive/1WIZBHix_cYIGsBKa4phIwCq5qXwO8fRX" rel="nofollow">
                        Cartoonize using Colab Notebook
                    </a>
                </h3>
                <p>
                    The most exciting thing is to cartoonize existing gifs. We created a
                    <a href="https://colab.research.google.com/drive/1WIZBHix_cYIGsBKa4phIwCq5qXwO8fRX" rel="nofollow">
                        Colab notebook
                    </a>
                    which set up everything including
                    <a href="https://www.tensorflow.org/alpha" rel="nofollow">
                        TensorFlow 2.0
                    </a>
                    for you to achieve that:
                </p>
                <p>
                    <img alt="colab-demo" data-canonical-url="https://github.com/mnicnc404/CartoonGan-tensorflow/raw/master/images/colab-demo.gif" src="https://res.cloudinary.com/devpost/image/fetch/s--K7TMCRsc--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://github.com/mnicnc404/CartoonGan-tensorflow/raw/master/images/colab-demo.gif">
                </p>
                <p>
                    You got the idea. Try cartoonizing your favorite images using styles available in
                    <a href="https://colab.research.google.com/drive/1WIZBHix_cYIGsBKa4phIwCq5qXwO8fRX" rel="nofollow">
                        the notebook
                    </a>
                    .
                </p>
                <h3>
                    Clone this repo and run script
                </h3>
                <p>
                    This method is handy if you already clone the repo and set up the environment.
                </p>
                <p>
                    Currently, there are 4 styles available:
                </p>
                <ul>
                    <li>
                        <code>
                            shinkai
                        </code>
                    </li>
                    <li>
                        <code>
                            hayao
                        </code>
                    </li>
                    <li>
                        <code>
                            hosoda
                        </code>
                    </li>
                    <li>
                        <code>
                            paprika
                        </code>
                    </li>
                </ul>
                <p>
                    For demo purpose, let's assume we want to transform
                    <a href="input_images/temple.jpg" rel="nofollow">
                        input_images/temple.jpg
                    </a>
                    :
                </p>
                <p>
                    <img alt="temple" data-canonical-url="input_images/temple.jpg" src="https://res.cloudinary.com/devpost/image/fetch/s--ZARDknzN--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/v1/input_images/temple.jpg">
                </p>
                <p>
                    To cartoonize this image with
                    <code>
                        shinkai
                    </code>
                    and
                    <code>
                        hayao
                    </code>
                    styles, you can run:
                </p>
                <pre class="language-commandline"><code>python cartoonize.py \
                --input_dir input_images \
    --output_dir output_images \
    --styles shinkai hayao \
    --comparison_view horizontal
</code></pre>
                <p>
                    <img alt="cartoonize-script-demo" data-canonical-url="https://github.com/mnicnc404/CartoonGan-tensorflow/raw/master/images/cartoonize-script-demo.gif" src="https://res.cloudinary.com/devpost/image/fetch/s--lSpVtarM--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://github.com/mnicnc404/CartoonGan-tensorflow/raw/master/images/cartoonize-script-demo.gif">
                </p>
                <p>
                    The transformed result will be saved as
                    <a href="output_images/comparison/temple.jpg" rel="nofollow">
                        output_images/comparison/temple.jpg
                    </a>
                    like this:
                </p>
                <p>
                    <img alt="transformed_temple.jpg" data-canonical-url="https://github.com/mnicnc404/CartoonGan-tensorflow/raw/master/output_images/comparison/temple.jpg" src="https://res.cloudinary.com/devpost/image/fetch/s---x-4z0zp--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://github.com/mnicnc404/CartoonGan-tensorflow/raw/master/output_images/comparison/temple.jpg">
                </p>
                <p>
                    The left-most image will be the original image, followed by the styled result specified using
                    <code>
                        --styles
                    </code>
                    option.
                </p>
                <p>
                    To explore all options with detailed explaination, simply run
                    <code>
                        python cartoonize.py -h
                    </code>
                    :
                </p>
                <p>
                    <img alt="demo" data-canonical-url="images/cartoonize-script-demo.jpg" src="https://res.cloudinary.com/devpost/image/fetch/s--8RxuK8HW--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/v1/images/cartoonize-script-demo.jpg">
                </p>
                <p>
                    Currently,
                    <a href="cartoonize.py" rel="nofollow">
                        cartoonize.py
                    </a>
                    will load pretrained models released by the
                    <a href="http://cg.cs.tsinghua.edu.cn/people/%7EYongjin/Yongjin.htm" rel="nofollow">
                        author
                    </a>
                    of CartoonGAN and
                    <a href="https://github.com/Yijunmaverick/CartoonGAN-Test-Pytorch-Torch" rel="nofollow">
                        CartoonGAN-Test-Pytorch-Torch
                    </a>
                    to turn input images into cartoon-like images.
                </p>
                <h3>
                    Gallery of Generated Anime
                </h3>
                <p>
                    If you want to view more anime generated by CartoonGAN, please visit the blog article with language you prefer:
                </p>
                <table class="responsive">
                    <thead>
                        <tr>
                            <th>
                                Blog post
                            </th>
                            <th>
                                Language
                            </th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>
                                <a href="https://leemeng.tw/generate-anime-using-cartoongan-and-tensorflow2-en.html#Gallery:-some-anime-we-generated" rel="nofollow">
                                    Generate Anime using CartoonGAN and TensorFlow 2.0
                                </a>
                            </td>
                            <td>
                                English
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <a href="https://leemeng.tw/generate-anime-using-cartoongan-and-tensorflow2.html#%E4%B8%80%E4%BA%9B%E8%BD%89%E6%8F%9B%E5%BE%8C%E7%9A%84%E5%8B%95%E6%BC%AB%E7%B5%90%E6%9E%9C" rel="nofollow">
                                    用 CartoonGAN 及 TensorFlow 2 生成新海誠與宮崎駿動畫
                                </a>
                            </td>
                            <td>
                                繁體中文（Traditional Chinese）
                            </td>
                        </tr>
                    </tbody>
                </table>
                <h2>
                    Acknowledgement
                </h2>
                <ul>
                    <li>
                        Thanks to the author
                        <code>
                            [Chen et al., CVPR18]
                        </code>
                        who published this great work
                    </li>
                    <li>
                        <a href="https://github.com/Yijunmaverick/CartoonGAN-Test-Pytorch-Torch" rel="nofollow">
                            CartoonGAN-Test-Pytorch-Torch
                        </a>
                        where we extracted pretrained Pytorch model weights for TensorFlow usage
                    </li>
                    <li>
                        <a href="https://www.tensorflow.org/" rel="nofollow">
                            TensorFlow
                        </a>
                        which provide many useful tutorials for learning TensorFlow 2.0:
                        <ul>
                            <li>
                                <a href="https://www.tensorflow.org/alpha/tutorials/generative/dcgan" rel="nofollow">
                                    Deep Convolutional Generative Adversarial Network
                                </a>
                            </li>
                            <li>
                                <a href="https://www.tensorflow.org/alpha/tutorials/load_data/images" rel="nofollow">
                                    Build a Image Input Pipeline
                                </a>
                            </li>
                            <li>
                                <a href="https://www.tensorflow.org/tensorboard/r2/get_started" rel="nofollow">
                                    Get started with TensorBoard
                                </a>
                            </li>
                            <li>
                                <a href="https://www.tensorflow.org/tutorials/eager/custom_layers" rel="nofollow">
                                    Custom layers
                                </a>
                            </li>
                        </ul>
                    </li>
                    <li>
                        <a href="https://colab.research.google.com/" rel="nofollow">
                            Google Colaboratory
                        </a>
                        which allow us to train the models and
                        <a href="#cartoonize-using-colab-notebook" rel="nofollow">
                            cartoonize images
                        </a>
                        using free GPUs
                    </li>
                    <li>
                        <a href="https://www.tensorflow.org/js" rel="nofollow">
                            TensorFlow.js
                        </a>
                        team which help us a lot when building the
                        <a href="https://leemeng.tw/generate-anime-using-cartoongan-and-tensorflow2-en.html" rel="nofollow">
                            online demo
                        </a>
                        for CartoonGAN
                    </li>
                    <li>
                        <a href="https://github.com/taki0112/CartoonGAN-Tensorflow" rel="nofollow">
                            taki0112/CartoonGAN-Tensorflow
                        </a>
                        where we modify
                        <a href="https://github.com/taki0112/CartoonGAN-Tensorflow/blob/master/edge_smooth.py" rel="nofollow">
                            edge_smooth.py
                        </a>
                        to fit our needs
                    </li>
                </ul>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/python">
                                python
                            </a>
                        </span>
                    </li>
                </ul>
            </div>
            <nav class="app-links section">
                <h2>
                    Try it out
                </h2>
                <ul class="no-bullet" data-role="software-urls">
                    <li>
                        <a href="https://leemeng.tw/generate-anime-using-cartoongan-and-tensorflow2-en.html" rel="nofollow" target="_blank" title="https://leemeng.tw/generate-anime-using-cartoongan-and-tensorflow2-en.html">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                leemeng.tw
                            </span>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/mnicnc404/CartoonGan-tensorflow" rel="nofollow" target="_blank" title="https://github.com/mnicnc404/CartoonGan-tensorflow">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                github.com
                            </span>
                        </a>
                    </li>
                </ul>
            </nav>
        </div>
    </body>
</html>
