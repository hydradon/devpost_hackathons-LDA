<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li>
                        <div class="flex-video">
                            <iframe allowfullscreen="allowfullscreen" allowscriptaccess="always" class="video-embed" frameborder="0" height="371" mode="transparent" src="https://www.youtube.com/embed/Gvs1cc6u-vk?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;start=&amp;version=3&amp;wmode=transparent" type="text/html" webkitallowfullscreen="true" width="660" wmode="transparent">
                            </iframe>
                        </div>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="861974" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/861/974/datas/original.jpg">
                            <img alt="annotate-the-world &ndash; screenshot 1" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/861/974/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                            </i>
                        </p>
                    </li>
                </ul>
            </div>
            <div>
                <h2>
                    Inspiration
                </h2>
                <p>
                    The inspiration behind this is utilizing the advances of technology to serve as a third eye for those who are visually impaired. We wanted to create a technology that would be in hand that is just as useful, if not more useful, than just a white cane or any other sort of visual aid.
                </p>
                <h2>
                    What it does
                </h2>
                <p>
                    The app captures and identifies any objects that are on-screen using Tensorflow. When the user simply taps on the screen, using depth perception, the phone is able to tell the user what the object is and how far away it is. It can also tell you the relative orientation from the phone (e.g. "slightly to the left", "slightly to the right", or "directly in front"). This app also is completely on device, so those who do not have internet access or those who can't afford internet are free to use this without such burden. This app also works on any camera, where no need for a lidar or dual stereo.
                </p>
                <h2>
                    How I built it
                </h2>
                <p>
                    It was built in Android Studio with two Tensorflow models, one of which serves to find depth in images and the other to detect objects in images.
                </p>
                <h2>
                    Challenges I ran into
                </h2>
                <p>
                    Some of the challenges that we ran into were working with Android Studio in general. Debugging was a bit tedious, and the wait times to rebuild Gradle was often frustrating. There was also some initial concern processing depth perception, live, long to process, so we had to change up a bit of how we wanted the app to work.
                </p>
                <h2>
                    Accomplishments that I'm proud of
                </h2>
                <p>
                    We are proud of having built an app that would help aid those that are visually impaired, and to help potentially improve our community. We are also proud that there are other accessibility capabilities, such as not needing a specific camera, or not requiring internet access.
                </p>
                <h2>
                    What I learned
                </h2>
                <p>
                    We learned to use services, like Google Cloud, in being able to train and recognize objects.
We also learned how to develop apps for Android a bit better.
Most importantly, through the thought process and designing this app, I think that this taught us to try to think from a perspective much different from ours.
                </p>
                <h2>
                    What's next for annotate-the-world
                </h2>
                <p>
                    Better depth perception, and better accuracy overall.
                </p>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/android">
                                android
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/android-studio">
                                android-studio
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/google--2">
                                google
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/java">
                                java
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/machine-learning">
                                machine-learning
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag">
                            tensorflow
                        </span>
                    </li>
                </ul>
            </div>
            <nav class="app-links section">
                <h2>
                    Try it out
                </h2>
                <ul class="no-bullet" data-role="software-urls">
                    <li>
                        <a href="https://github.com/ivanmontero/annotate-the-world" rel="nofollow" target="_blank" title="https://github.com/ivanmontero/annotate-the-world">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                github.com
                            </span>
                        </a>
                    </li>
                </ul>
            </nav>
        </div>
    </body>
</html>
