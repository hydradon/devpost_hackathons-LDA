<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li class="text-center">
                        <a data-lightbox="798496" data-title="Enjins" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/798/496/datas/original.jpg">
                            <img alt="Tesseract meets CNN &ndash; screenshot 1" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/798/496/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Enjins
                            </i>
                        </p>
                    </li>
                </ul>
            </div>
            <div>
                <p>
                    <a href="https://gitlab.com/enjins/public/picnic" rel="nofollow">
                        Project can be found here
                    </a>
                    .
The CNN model is not included in the upload due to upload rate limit, but can be found in this repository.
                </p>
                <h2>
                    Inspiration
                </h2>
                <p>
                    Creativity always beats brute-force. We mimic how our brains look at the pictures, namely: if there's a label, let's read the label. If not: can we recognize the item?
                </p>
                <h2>
                    What it does
                </h2>
                <p>
                    To start of, we try to extract text from the images by using a library called Tesseract. After filtering the images with text, the remaining images are sent to the pre-trained CNN that uses the VGG-19 model as a base and by adding a few extra layers of our own, we can make the net a better fit for the specific images in the dataset.
                </p>
                <h2>
                    How we built it
                </h2>
                <p>
                    Like every project: start with some exploration and more importantly: be creative. We started with some drafts and discussions, went on with data analysis and decided to build 2 models and combine them in a clever workflow.
                </p>
                <h2>
                    Challenges we ran into
                </h2>
                <p>
                    During the analysis we noticed that the quality of photos could be improved. One way could be to let users send their photos through the app. When using the camera, users can see the label that is predicted by the CNN. If correct, the user can confirm this and thereby improving the quality of the data and adding more labeled data to the total dataset.
                </p>
                <h2>
                    Accomplishments that we're proud of
                </h2>
                <p>
                    Besides the fact that accuracy is quite well, we think we can easily improve it with some more ideas. We're proud that with some effort we can create stuff which is already quite valuable, and could be even more with ideas like the one above.
                </p>
                <h2>
                    What we learned
                </h2>
                <p>
                    Use cases like these are actually quite doable for a strong AI engine. Combining it in an infrastructure as described above, we think you can get up to 90% accuracy, taking in to account the feedback users give.
                </p>
                <h2>
                    What's next for Tesseract meets CNN
                </h2>
                <ul>
                    <li>
                        Image augmentation to enhance the training data
                    </li>
                    <li>
                        Experimenting with changing layers in the network
                    </li>
                    <li>
                        Contairize project and deploy on Kubernetes cluster
                    </li>
                    <li>
                        Setup CI/CD environment to make frequent updates possible
                    </li>
                    <li>
                        Model monitoring, in order to learn and auto-improve the models
                    </li>
                </ul>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/python">
                                python
                            </a>
                        </span>
                    </li>
                </ul>
            </div>
            <nav class="app-links section">
                <h2>
                    Try it out
                </h2>
                <ul class="no-bullet" data-role="software-urls">
                    <li>
                        <a href="https://gitlab.com/enjins/public/picnic" rel="nofollow" target="_blank" title="https://gitlab.com/enjins/public/picnic">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                gitlab.com
                            </span>
                        </a>
                    </li>
                </ul>
            </nav>
        </div>
    </body>
</html>
