<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li class="text-center">
                        <a data-lightbox="537434" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/537/434/datas/original.png">
                            <img alt="Vox Augmento &ndash; screenshot 1" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/537/434/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="537335" data-title="Skybox" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/537/335/datas/original.png">
                            <img alt="Vox Augmento &ndash; screenshot 2" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/537/335/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Skybox
                            </i>
                        </p>
                    </li>
                </ul>
            </div>
            <div>
                <h2>
                    Summary
                </h2>
                <p>
                    VR is a medium that&rsquo;s quickly becoming a new creative outlet. We believe it is a way of making music based on natural movements, without relying on existing instrument interfaces. The level of immersion can unlock latent musical abilities in new users, or extend the abilities of existing musicians.
                </p>
                <p>
                    <img alt="Demo" data-canonical-url="https://thumbs.gfycat.com/InsecureBlackandwhiteAlaskanhusky-size_restricted.gif" src="https://res.cloudinary.com/devpost/image/fetch/s--I76ViA7w--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://thumbs.gfycat.com/InsecureBlackandwhiteAlaskanhusky-size_restricted.gif">
                </p>
                <p>
                    <strong>
                        Inspiration
                    </strong>
                </p>
                <p>
                    Phillip proposed a general goal of creating a unique VR-centric music tool. Our initial analogue was a theremin, but in VR. The team has many musicians and individuals enthusiastic for novel expression in VR. Currently many other music or sonic manipulation apps rely heavily on skeuomorphic principles. Our design question was: How could we build a musical instrument that could not be realized outside VR?
                </p>
                <p>
                    <strong>
                        Philosophy
                    </strong>
                    We built Vox Augmento to enable both novice and experienced musical enthusiasts to express their musicality. The barrier to entry is low but the instrument&rsquo;s full expressive capability will need practice and mastery just like a real instrument.
                </p>
                <p>
                    <img alt="Philosophy Board" data-canonical-url="https://i.imgur.com/9W4EV5d.jpg" src="https://res.cloudinary.com/devpost/image/fetch/s--uOAwg2FL--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://i.imgur.com/9W4EV5d.jpg">
                </p>
                <p>
                    Story for Vox Augment
                </p>
                <p>
                    Sonic interaction and manipulation
Music and sound involves interaction and movement. The most engaged musical players often move in ways that don&rsquo;t directly influence the sound being produced. Vox Augmento makes fluid bodily expression inseparable from musical expression. Providing a novel mode of expression was high on the priority list for users
                </p>
                <p>
                    Visual understanding
Users want to revisit their actions in VR space, know that what they do exists in space.
                </p>
                <p>
                    Experimentation and discovery
Finger painting is wonderful. Playing, creating, and destroying is important to the user. Even during initial testing, unexpected expressive usages were discovered. By purposely minimizing menus and modes, a user is more free to try things for themselves.
                </p>
                <p>
                    Mastery
Novices in music can often feel that an instrument is daunting and be discouraged. The mode of expression should allow for both novices and experts to create amazing experiences. The instrument makes its limits and functions easily discoverable. Users who want to achieve mastery to express themselves in more fluid ways are encouraged.
                </p>
                <h2>
                    Product
                </h2>
                <p>
                    <strong>
                        Journey
                    </strong>
                    MVP
A user can paint what they speak as if placing a waveform in air. Moving the controller higher raises pitch, lowers the controller lowers the pitch. Colliding with the painted waveform will replay the sound.
                </p>
                <p>
                    Discovery
Team members discussed concepts of how sound and music interact within VR space. Quickly working through how people of different experience levels try to make music. Then asked how to best represent interaction with sounds or music. What does the X, Y, Z access mean to the creation process? Initial analogs to real world editing were demonstrated using Abelton. This let the entire team understand basic concepts of editing quick sound samples.
                </p>
                <p>
                    <img alt="Ableton Demo" data-canonical-url="https://i.imgur.com/ZgZmA4G.jpg" src="https://res.cloudinary.com/devpost/image/fetch/s--GDDtzrRf--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://i.imgur.com/ZgZmA4G.jpg">
                </p>
                <p>
                    A key insight was that not all users were musically literate. Would it be possible to use this VR as a medium to unlock a new world of creativity.
                </p>
                <p>
                    The team determined which qualities overlapped between different experiences, and how to guide novices to mastery without being overwhelming.
                </p>
                <p>
                    Example concepts:
                </p>
                <ul>
                    <li>
                        A particle field representing the playhead
                    </li>
                    <li>
                        Moving, rotating, shaping allow for changes in sound
                    </li>
                    <li>
                        Striking a sound plays that sound once over
                    </li>
                    <li>
                        Sounds correspond to an existing model
                    </li>
                </ul>
                <p>
                    <strong>
                        Design
                    </strong>
                    Assets were created in Tilt Brush, Blocks, and Maya.
                </p>
                <p>
                    We conducted quick surveys asking what comes to mind when trying to make a sound loop. This revealed several answers, many responses involved drawing a circular loop to represent make a sound play over-and-over. Another response was to let any sound loop, this would be achieved by selecting the sound for a select amount of time.
                </p>
                <p>
                    For ease MVP, a menu system or multi tap would allow loop mechanic to work.
                </p>
                <p>
                    <img alt="Design Meeting" data-canonical-url="https://i.imgur.com/EquKEzX.jpg" src="https://res.cloudinary.com/devpost/image/fetch/s--sxirJQh_--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://i.imgur.com/EquKEzX.jpg">
                </p>
                <p>
                    <strong>
                        Visuals
                    </strong>
                    Setting - Users are on a rock landscape platform. Burning man on the cliff.
Controller - A bone musical wand is used to represent an ancient paint brush. A light trail flows the tip.
Output - White sound bubbles are generated from the controller to represent record sound.
                </p>
                <p>
                    <strong>
                        Interaction
                    </strong>
                    Controller Trigger - Record spoken sounds and paints out the sounds as bubbles in the VR world
Modulation - Recording sounds while moving the controller in different motions will change the sound on playback
Collision - Collide the controller into a sound bubble to play it back
Delete - Menu button clears all record sonic recordings
                </p>
                <p>
                    <img alt="Philip Painting" data-canonical-url="https://i.imgur.com/bljxVa7.jpg" src="https://res.cloudinary.com/devpost/image/fetch/s--5C1px2OV--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://i.imgur.com/bljxVa7.jpg">
                </p>
                <h2>
                    Development
                </h2>
                <p>
                    Unity - Visual engine, environment,
Max/MSP - Realtime audio modulation and effects
                </p>
                <p>
                    First steps - Realtime link between Unity and Max. Get data about controller and collisions into the audio engine. Crucial to get this step to work, otherwise new platform would need to be chosen.
                </p>
                <p>
                    Second steps - Parallel development to produce working assets and interaction.
Recording and modulation
Mapping controller movements
Tweaking control schemes and sensitivities
                </p>
                <p>
                    Third  - Polish and final touches
                </p>
                <p>
                    Audio cleanup, looping, multi controller ideas were non-crucial and backlogged as nice to have. These were not accomplished during the initial build.
                </p>
                <p>
                    <img alt="Development IDE" data-canonical-url="https://i.imgur.com/8ggE8Sd.jpg" src="https://res.cloudinary.com/devpost/image/fetch/s--bMbDeBL9--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://i.imgur.com/8ggE8Sd.jpg">
                </p>
                <p>
                    <strong>
                        Persona
                    </strong>
                    There was a man who like to sing. This man liked to dance. One day he wanted to dance to sing! This man may not have been musically literate, but with VR he would more quickly move up to proficiency.
                </p>
                <p>
                    <strong>
                        Basic Mechanic
                    </strong>
                    Users using the headset microphone and controller paint sounds they make into the VR environment. The shape of the painting alters/modulates the sound. The painted sounds can be interacted with to re-play them. Painting sounds into a circular loop will let the painted sound loop over and over.
                </p>
                <p>
                    <strong>
                        Future or stretch goal Mechanics
                    </strong>
                </p>
                <ul>
                    <li>
                        Advanced control over the sounds in VR space. This includes editing the sounds, replacing, looping, and duplicating. Granular control will allow for more complex expression, ever increasing the range for users who try to achieve mastery.
                    </li>
                    <li>
                        We will avoid making digital representations of real world instruments. No drums, guitars, saxophones, etc...
                    </li>
                </ul>
                <h2>
                    Demo&rsquo;d Product
                </h2>
                <p>
                    Users are handed one controller with little instruction beyond the intent of the app. The goal of the user interaction is about discovery. The usage and discovery is not something the developers would be able to ever fully predict. The demo may even evoke new usages and practices not envisioned.
                </p>
                <p>
                    <img alt="In VR screenshot" data-canonical-url="https://i.imgur.com/Dkpt2xg.png" src="https://res.cloudinary.com/devpost/image/fetch/s--O7_axCpM--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://i.imgur.com/Dkpt2xg.png">
                </p>
                <p>
                    <strong>
                        Presentation Script
                    </strong>
                </p>
                <ol>
                    <li>
                        Philip wanted a way to express sonically unique to VR
                    </li>
                    <li>
                        Chris was the base case of a user who doesn&rsquo;t know how to play music but wants to
                    </li>
                    <li>
                        Vox Augmento acts a bridge to unlock and inspire musical creativity for both music beginners and experts
                    </li>
                    <li>
                        The basic interaction is use the vive controller trigger and movements to record sound into VR. This is represented as cloud bubbles
                    </li>
                </ol>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/unity">
                                unity
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag">
                            vive
                        </span>
                    </li>
                </ul>
            </div>
        </div>
    </body>
</html>
