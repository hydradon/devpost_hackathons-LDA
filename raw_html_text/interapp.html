<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li class="text-center">
                        <a data-lightbox="692675" data-title="Video call demo showing original feed on the left, the script output on the right along with its suggested action and feedback" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/692/675/datas/original.png">
                            <img alt="NA + Interapp &ndash; screenshot 1" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/692/675/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Video call demo showing original feed on the left, the script output on the right along with its suggested action and feedback
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="692676" data-title="Sample image demo showing original feed on the left, the script output on the right along with its suggested action and feedback" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/692/676/datas/original.png">
                            <img alt="NA + Interapp &ndash; screenshot 2" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/692/676/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Sample image demo showing original feed on the left, the script output on the right along with its suggested action and feedback
                            </i>
                        </p>
                    </li>
                </ul>
            </div>
            <div>
                <h1>
                    Interapp
                </h1>
                <p>
                    Interapp is a program that suggests user actions during a video call built on Machine Learning based on the emotion recognition of the image and audio of a video call.
                </p>
                <p>
                    The purposes of this project is to help user to notify the current emotion of the video calling subject and suggests them the action that could be taken to improve the mutual experiences of the video call. This is also useful for student that is taking video call as a type of interview, knowing the current emotion of the interviewer that initially could have gone unnoticed, might help student to avoid some pitfall of interview and thus getting a better result.
                </p>
                <h1>
                    Overview
                </h1>
                <p>
                    As a prototype, the python script will capture a specific windows on the screen and take computer own audio output as audio feed. Therefore, it given the script the capability to intergrate with any of the major conference or video call software including Skype, Facebook Messenger Call, Google Duo, etc
                </p>
                <p>
                    The structure of this project can roughly be separated into three part.
                </p>
                <h2>
                    Image (Face Sentiment Analysis)
                </h2>
                <p>
                    Although one always say he is deep with hiding their feeling, but almost everyone can't help but shown some of the emotion on their faces. By using Opencv library, we can extract faces inside the image efficiently thanks to its well implemented face detection function. Later the image with faces present is cropped then feed to the face emotion classifier built by Emopy one face at a time.
                </p>
                <p>
                    The result of the classifier which constist of different percentage of similarity of each emotion is transfer to the action suggestion model for further training.
                </p>
                <p>
                    <img alt="Labeled emotion analysis image output" data-canonical-url="https://raw.githubusercontent.com/pakzan/Interapp/master/readme_doc/label_sc.png" src="https://res.cloudinary.com/devpost/image/fetch/s--nQY9hj3W--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://raw.githubusercontent.com/pakzan/Interapp/master/readme_doc/label_sc.png" title="Labeled emotion analysis image output">
                </p>
                <h2>
                    Voice (Real-time Speech Emotion Recognizer)
                </h2>
                <p>
                    Speech Emotion or voice sentiment is also a hot topics with a lot of past research working on it. People tend to speak with increasing frequency when they are happy or interested, while talking in normalized pitch when they got bored. Although talking in different language and word, the base frequency of the speech is highly corelate to the speaker mood and emotion.
                </p>
                <p>
                    By doing short-time Fourier Transform (STFT), we are able to obtain the intensity of frequency versus short time chart. This is particularly useful becuase it enable researcher to treat it as a 2D data classifiation problem after signal processing.
                </p>
                <p>
                    In our project, this is assisted by the library OpenVokaturi.
                </p>
                <h2>
                    Action Suggestion (Reinforcement Learning using TensorFlow)
                </h2>
                <p>
                    By using the output from image and voice analysis, a Neural Network model with 128 hidden nodes and 2 hidden layers is self-trained. During the prototyping stage, user will get suggestion for action during the conversation in video call, eg. "Change topics", "Pay Attention!", etc. Then, user can rate its usefulness relate with the actual situation. The data will be submitted back to the program to further train the model at the end of the conversation so that the program will be even smarter.
                </p>
                <p>
                    Some of the action suggestion including
                </p>
                <ul>
                    <li>
                        <code>
                            change topic
                        </code>
                    </li>
                    <li>
                        <code>
                            engage in discussion
                        </code>
                    </li>
                    <li>
                        <code>
                            slow down
                        </code>
                    </li>
                    <li>
                        <code>
                            speed up
                        </code>
                    </li>
                    <li>
                        <code>
                            stop and listen
                        </code>
                    </li>
                    <li>
                        <code>
                            open conversation
                        </code>
                    </li>
                    <li>
                        <code>
                            ask questions
                        </code>
                    </li>
                    <li>
                        <code>
                            pay attention
                        </code>
                    </li>
                </ul>
                <p>
                    <img alt="Combined rseult of emotional analysis along with feedback function" data-canonical-url="https://raw.githubusercontent.com/pakzan/Interapp/master/readme_doc/gui_action.png" src="https://res.cloudinary.com/devpost/image/fetch/s--axc7Bs0d--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://raw.githubusercontent.com/pakzan/Interapp/master/readme_doc/gui_action.png" title="Combined rseult of emotional analysis along with feedback function">
                </p>
                <p>
                    Lastly, having the ability to capture image and sound of any program on computer, the program is not restricted on solely video call, but there is a vast possibility of it is capable of.
                </p>
                <h1>
                    Warps things up
                </h1>
                <p>
                    Interapp would like to express our gratitude toward these awesome packages that make this project possible
                </p>
                <ul>
                    <li>
                        <a href="https://github.com/thoughtworksarts/EmoPy" rel="nofollow">
                            Emopy
                        </a>
                        -- A deep neural net toolkit for emotion analysis via Facial Expression Recognition (FER) by thoughtworksarts
                    </li>
                    <li>
                        <a href="https://developers.vokaturi.com/downloads/sdk" rel="nofollow">
                            Vokaturi
                        </a>
                        --understand the emotion in a speaker&rsquo;s voice
                    </li>
                    <li>
                        <a href="https://www.tensorflow.org/tutorials/" rel="nofollow">
                            TensorFlow
                        </a>
                        --An open source machine learning framework for everyone
                    </li>
                </ul>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/python">
                                python
                            </a>
                        </span>
                    </li>
                </ul>
            </div>
            <nav class="app-links section">
                <h2>
                    Try it out
                </h2>
                <ul class="no-bullet" data-role="software-urls">
                    <li>
                        <a href="https://github.com/pakzan/Interapp" rel="nofollow" target="_blank" title="https://github.com/pakzan/Interapp">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                github.com
                            </span>
                        </a>
                    </li>
                </ul>
            </nav>
        </div>
    </body>
</html>
