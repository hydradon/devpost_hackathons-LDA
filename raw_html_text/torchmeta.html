<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li>
                        <div class="flex-video">
                            <iframe allowfullscreen="allowfullscreen" allowscriptaccess="always" class="video-embed" frameborder="0" height="371" mode="transparent" src="https://player.vimeo.com/video/360353764?byline=0&amp;portrait=0&amp;title=0#t=" type="text/html" webkitallowfullscreen="true" width="660" wmode="transparent">
                            </iframe>
                        </div>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="844871" data-title="Torchmeta" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/871/datas/original.png">
                            <img alt="Torchmeta &ndash; screenshot 1" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/871/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Torchmeta
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="844863" data-title="Data-loaders - Omniglot" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/863/datas/original.png">
                            <img alt="Torchmeta &ndash; screenshot 2" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/863/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Data-loaders - Omniglot
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="844870" data-title="Datasets available" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/870/datas/original.png">
                            <img alt="Torchmeta &ndash; screenshot 3" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/870/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Datasets available
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="844855" data-title="MetaModule" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/855/datas/original.png">
                            <img alt="Torchmeta &ndash; screenshot 4" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/855/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                MetaModule
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="844854" data-title="Creating models with MetaModule" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/854/datas/original.png">
                            <img alt="Torchmeta &ndash; screenshot 5" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/854/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Creating models with MetaModule
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="844868" data-title="Installation" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/868/datas/original.png">
                            <img alt="Torchmeta &ndash; screenshot 6" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/868/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Installation
                            </i>
                        </p>
                    </li>
                </ul>
            </div>
            <div>
                <h2>
                    Inspiration
                </h2>
                <p>
                    The problem with data-loading in meta-learning is that usually we need not only to have a batch of example, but a batch of
                    <em>
                        tasks
                    </em>
                    , themselves containing multiple examples. This shift in paradigm makes it hard to build data pipelines for meta-learning in vanilla PyTorch. The goal of the data-loaders in Torchmeta was to have an equivalent to the usual
                    <code>
                        Dataset
                    </code>
                    and
                    <code>
                        DataLoader
                    </code>
                    from PyTorch, but at a "meta" level.
                </p>
                <p>
                    A huge inspiration comes from OpenAI Gym, and how it made it much easier to use reinforcement learning. I wanted to have something similar for meta-learning, something that allowed fast development of meta-learning algorithms. One aspect of Gym that I think helped a lot was its unified interface for all environments; it makes it very easy to switch environments. This is an issue I saw with meta-learning code available online, where almost all of them are tested on a single dataset (and usually it's Omniglot, sometimes Mini-ImageNet). Evaluation on other benchmarks requires major rework of these codes. I wanted to have something as simple as Gym to switch between meta-learning benchmarks.
                </p>
                <p>
                    Another issue I saw was the lack of standard for some of the datasets in meta-learning. A canonical example is how Mini-ImageNet was originally introduced in (Vinyals et al., 2016), but the split that is considered standard now is the one used in (Ravi et al., 2017). This situation still exists for some datasets (e.g. CUB). It is hard to keep track of the "correct" version the algorithms should be evaluated on. Having all of them at hand, with standard meta-train/meta-validation/meta-test, in a library like Torchmeta is a step forward for reproducibility in meta-learning.
                </p>
                <h2>
                    What it does
                </h2>
                <p>
                    Torchmeta provides extensions for PyTorch to simplify the development of meta-learning algorithms in PyTorch. It features:
                </p>
                <ul>
                    <li>
                        <p>
                            A unified interface inspired by Torchvision for both few-shot classification and regression problems, to allow easy benchmarks on multiple datasets and reproducibility. Here is a list of the datasets available in Torchmeta:
                        </p>
                        <ul>
                            <li>
                                <strong>
                                    Few-shot regression
                                </strong>
                                (toy problems):
                                <ul>
                                    <li>
                                        Sine waves (
                                        <a href="https://arxiv.org/abs/1703.03400" rel="nofollow">
                                            Finn et al., 2017
                                        </a>
                                        )
                                    </li>
                                    <li>
                                        Harmonic functions (
                                        <a href="https://arxiv.org/abs/1806.07528" rel="nofollow">
                                            Lacoste et al., 2018
                                        </a>
                                        )
                                    </li>
                                    <li>
                                        Sinusoid &amp; lines (
                                        <a href="https://arxiv.org/abs/1806.02817" rel="nofollow">
                                            Finn et al., 2018
                                        </a>
                                        )
                                    </li>
                                </ul>
                            </li>
                            <li>
                                <strong>
                                    Few-shot classification
                                </strong>
                                (image classification):
                                <ul>
                                    <li>
                                        Omniglot (
                                        <a href="http://www.sciencemag.org/content/350/6266/1332.short" rel="nofollow">
                                            Lake et al., 2015
                                        </a>
                                        <a href="https://arxiv.org/abs/1902.03477" rel="nofollow">
                                            , 2019
                                        </a>
                                        )
                                    </li>
                                    <li>
                                        Mini-ImageNet (
                                        <a href="https://arxiv.org/abs/1606.04080" rel="nofollow">
                                            Vinyals et al., 2016
                                        </a>
                                        ,
                                        <a href="https://openreview.net/forum?id=rJY0-Kcll" rel="nofollow">
                                            Ravi et al., 2017
                                        </a>
                                        )
                                    </li>
                                    <li>
                                        Tiered-ImageNet (
                                        <a href="https://arxiv.org/abs/1803.00676" rel="nofollow">
                                            Ren et al., 2018
                                        </a>
                                        )
                                    </li>
                                    <li>
                                        CIFAR-FS (
                                        <a href="https://arxiv.org/abs/1805.08136" rel="nofollow">
                                            Bertinetto et al., 2018
                                        </a>
                                        )
                                    </li>
                                    <li>
                                        Fewshot-CIFAR100 (
                                        <a href="https://arxiv.org/abs/1805.10123" rel="nofollow">
                                            Oreshkin et al., 2018
                                        </a>
                                        )
                                    </li>
                                </ul>
                            </li>
                        </ul>
                    </li>
                    <li>
                        <p>
                            A thin extension of PyTorch's Module, called MetaModule, that simplifies the creation of certain meta-learning models (e.g. gradient based meta-learning methods).
                        </p>
                    </li>
                </ul>
                <p>
                    <img alt="MetaModule" data-canonical-url="https://raw.githubusercontent.com/tristandeleu/pytorch-meta/master/docs/assets/metamodule.png" src="https://res.cloudinary.com/devpost/image/fetch/s--QkUUKkKX--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://raw.githubusercontent.com/tristandeleu/pytorch-meta/master/docs/assets/metamodule.png">
                </p>
                <p>
                    To try Torchmeta, you can install it with
                    <code>
                        pip install torchmeta
                    </code>
                    .
                </p>
                <h2>
                    How I built it
                </h2>
                <p>
                    I gathered the links to the datasets and possible splits (in
                    <code>
                        torchmeta.datasets.assets
                    </code>
                    ) from code available online, and processed it with HDF5. I built it following very closely the design of Torchvision and PyTorch. For example, all datasets have
                    <code>
                        transform
                    </code>
                    and
                    <code>
                        target_transform
                    </code>
                    arguments, similar to the datasets in Torchvision (these accept transforms from Torchvision as well), and the data-loader for Torchmeta
                    <code>
                        BatchMetaDataLoader
                    </code>
                    is available in
                    <code>
                        torchmeta.utils.data
                    </code>
                    (following
                    <code>
                        torch.utils.data
                    </code>
                    for
                    <code>
                        DataLoader
                    </code>
                    ).
                </p>
                <h2>
                    Challenges I ran into
                </h2>
                <p>
                    Most of the challenges I ran into were related to versioning of the datasets; as I was modifying the processing for the datasets, previously processed data was not working anymore. This caused a lot of headaches.
                </p>
                <p>
                    Another challenge was the processing of Mini-Imagenet and Tiered-Imagenet. In the version made available by the original authors of these datasets, they were given as large Pickle files, which would have made data loading very difficult. I overcame this by using HDF5 instead.
                </p>
                <h2>
                    Accomplishments that I'm proud of
                </h2>
                <p>
                    I spent a lot of time thinking about an interface that is flexible enough for meta-learning problems, but also simple enough to use so that it's easy to include a new dataset. That's how I settled on this "3-layer" design, with
                    <code>
                        CombinationMetaDataset
                    </code>
                    responsible for creating the tasks, a
                    <code>
                        ClassDataset
                    </code>
                    that downloads the data and generates a pool of classes, and
                    <code>
                        Task
                    </code>
                    which is a PyTorch dataset. I am happy with how this turned out. I'm also proud of how I used HDF5 for datasets in a way which is compatible with
                    <code>
                        DataLoader
                    </code>
                    (which was an unsolved issue on Torchvision).
                </p>
                <p>
                    Another thing I am proud of is the
                    <code>
                        MetaModule
                    </code>
                    . The main focus of the library originally was on the data-loaders, but I'm glad I added the
                    <code>
                        MetaModule
                    </code>
                    . This was inspired by a previous project of mine
                    <a href="https://github.com/tristandeleu/pytorch-maml-rl" rel="nofollow">
                        pytorch-maml-rl
                    </a>
                    , where I used this idea of an extra parameter for the model.
                    <code>
                        MetaModule
                    </code>
                    takes it a step further and makes it as easy to create a model ready for meta-learning (especially gradient-based methods) as a vanilla PyTorch model. I'm really proud of this, seeing how easy it is to create meta-learning algorithms with that.
                </p>
                <h2>
                    What I learned
                </h2>
                <p>
                    To make it as integrated as possible with PyTorch and Torchvision, I learned a lot about the inner workings of these two libraries, especially how the
                    <code>
                        DataLoader
                    </code>
                    works (with multiprocessing).
                </p>
                <h2>
                    What's next for Torchmeta
                </h2>
                <p>
                    The next step is to get more datasets available through Torchmeta. One notable missing dataset at the moment is the
                    <a href="https://github.com/google-research/meta-dataset/" rel="nofollow">
                        Meta-Dataset
                    </a>
                    (
                    <a href="https://arxiv.org/abs/1903.03096" rel="nofollow">
                        Triantafillou et al., 2019
                    </a>
                    ) . Unfortunately this one is particularly challenging for two reasons:
                </p>
                <ul>
                    <li>
                        Downloading &amp; processing the data is long (12 to 24 hours, only for processing), which would be very impractical for the auto-download and processing feature in Torchmeta. One solution might be to allow Torchmeta to copy the dataset from a local folder if it exists, so that processing &amp; download only happens once (even when launching jobs on a cluster).
                    </li>
                    <li>
                        The processing code of Meta-Dataset is in Tensorflow. This is unfortunately a big requirement to have in Torchmeta, which I am not comfortable adding for only this feature.
                    </li>
                </ul>
                <p>
                    Another dataset I would like to include is CUB (
                    <a href="https://arxiv.org/abs/1802.04376" rel="nofollow">
                        Hilliard et al., 2018
                    </a>
                    ), but unfortunately this lacks any fixed split meta-train/meta-validation/meta-test, which is an issue for reproducibility.
                </p>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/python">
                                python
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/pytorch">
                                pytorch
                            </a>
                        </span>
                    </li>
                </ul>
            </div>
            <nav class="app-links section">
                <h2>
                    Try it out
                </h2>
                <ul class="no-bullet" data-role="software-urls">
                    <li>
                        <a href="https://github.com/tristandeleu/pytorch-meta" rel="nofollow" target="_blank" title="https://github.com/tristandeleu/pytorch-meta">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                github.com
                            </span>
                        </a>
                    </li>
                    <li>
                        <a href="https://tristandeleu.github.io/pytorch-meta/" rel="nofollow" target="_blank" title="https://tristandeleu.github.io/pytorch-meta/">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                tristandeleu.github.io
                            </span>
                        </a>
                    </li>
                </ul>
            </nav>
        </div>
    </body>
</html>
