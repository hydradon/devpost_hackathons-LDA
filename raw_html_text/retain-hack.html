<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div>
                <h2>
                    Inspiration
                </h2>
                <p>
                    Generally speaking, the whole after-sales customer experience is broken. This includes many aspects - from delivery to returns, services and more. Another aspect is the retargeting of existing customers without annoying them by sending out untargeted vouchers and newsletters or showing them unnecessary ads. We aim to change this with our solution and we built a foundation for changing after-sales experiences: a personal inventory of bought products.
                </p>
                <h2>
                    What it does
                </h2>
                <p>
                    Our solution extracts the purchase history with all kind of product information and categories. Next, it analyzes the data, derives statistics and matches the categories with the current page structure to derive the listing categories and match these with our current database. Based on these insights, we allow a better retargeting and make better suggestions.
                </p>
                <h2>
                    How we built it
                </h2>
                <p>
                    We received a huge amount of sample data (in two files) from idealo (all the purchases from April and May (partly)). Using the idealo API we enriched the sample data sets with category information. We used Python, Power BI, R, Excel to analyze and enrich the datasets and to do machine learning modelling. We derived the html category trees using R web scraping.
                </p>
                <h2>
                    Challenges we ran into
                </h2>
                <p>
                    Unfortunately, the purchases data only contains an article sku per purchase but no category information. So we decided to do a two-step process to enrich the purchases data with rich category information. If we worked on the whole data set, we would have to make ~120.000 API requests, one per article sku. This would even be a huge challenge timewise. So we decided to reduce the purchases data down to all the buyers with at least 100 purchases each. This brought down the number of unique article sku's from 120.000 to around 10.000. 
First, we did around 10.000 API requests to get an atomic category label for each article sku. Then we scraped the idealo website for the category pages. Via the breadcrumb information, we were able to get a full category path for each atomic category label.
                </p>
                <p>
                    Even with the scraped full category path information we were only able to enrich around 56% of the purchase data. We would have to further investigate how we could get hold of the missing category paths.
                </p>
                <h2>
                    Accomplishments that we're proud of
                </h2>
                <p>
                    Having found a feasible workaround to get the full category information.
                </p>
                <p>
                    Having a clean data set now and starting some analysis.
                </p>
                <p>
                    Having (manually) created a retargeting matrix based on full category paths in order to fine-grain retargeting based on the categories of previous purchases.
                </p>
                <h2>
                    What we learned
                </h2>
                <p>
                    No data, no AI. As almost always don't expect clean tidy data even from big data providers. As often said, data preprocessing and munging takes up 80% or more of your time before actually getting to the "sexy" parts of machine learning modelling.
                </p>
                <p>
                    Also, we learned that focusing on one thing is key and that building the foundation for the planned solution will take way longer than expected.
                </p>
                <h2>
                    What's next for retAIn.hack
                </h2>
                <p>
                    Combine dataset with other external data -&gt; Combine with image recognition -&gt; Match with personal products bought before -&gt; integrate AR for easy user interaction -&gt; match with a personal assistant for service issues
                </p>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/idealo">
                                idealo
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/python">
                                python
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/r">
                                r
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag">
                            webscraping
                        </span>
                    </li>
                </ul>
            </div>
        </div>
    </body>
</html>
