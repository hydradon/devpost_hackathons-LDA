<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div>
                <h2>
                    Inspiration
                </h2>
                <p>
                    Helping the UN operations in the underdeveloped nations.
                </p>
                <h2>
                    What it does
                </h2>
                <p>
                    It converts OCR images to an ordered sequence of digits and puncturations.
                </p>
                <h2>
                    How we built it
                </h2>
                <p>
                    A residual neural net is firstly used to scan patches of images to extract local features of the digits, punctuations and other symbols. Afterwards, a seq2seq translation/transduction model is employed to squentially evaluate and convert the local information gathered by the resnet, into a sequence of digits translation.
                </p>
                <h2>
                    Challenges we ran into
                </h2>
                <ol>
                    <li>
                        The restricted quality and quantity of training data posed a serious limitation the model capacity, observed from overfitting during training.
                    </li>
                    <li>
                        Without explicit image segmentation at the preprocessing stage, we implicitly segment, or in other words, sequentially parse the images information, using a seq2seq model widely applied in NLP and NMT.
                    </li>
                </ol>
                <h2>
                    Accomplishments that we're proud of
                </h2>
                <p>
                    We can reach 26% percent accuracy on the test set validated by the server, after pretraining the resnet part on mnist dataset for 100 epochs followed by training the complete pipeline for 4000 epochs.
                </p>
                <h2>
                    What we learned
                </h2>
                <p>
                    Identifying a mature image segmentation and semantic recognition model or algorithm would make things a lot easier...
But building a novel neural architecture, train and evaluate it on your own certainly has a lot of fun nonetheless.
                </p>
                <h2>
                    What's next for OCR2Text
                </h2>
                <p>
                    Improve the pipeline accuracy! Incorporating some pretrained model looks like the only way to go.
                </p>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag">
                            tensorflow-matplotlib-opencv
                        </span>
                    </li>
                </ul>
            </div>
            <nav class="app-links section">
                <h2>
                    Try it out
                </h2>
                <ul class="no-bullet" data-role="software-urls">
                    <li>
                        <a href="https://github.com/harveyyan/ocr2text" rel="nofollow" target="_blank" title="https://github.com/harveyyan/ocr2text">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                github.com
                            </span>
                        </a>
                    </li>
                </ul>
            </nav>
        </div>
    </body>
</html>
