<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li>
                        <div class="flex-video">
                            <iframe allowfullscreen="allowfullscreen" allowscriptaccess="always" class="video-embed" frameborder="0" height="371" mode="transparent" src="https://www.youtube.com/embed/15p8nqRELFA?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;start=&amp;version=3&amp;wmode=transparent" type="text/html" webkitallowfullscreen="true" width="660" wmode="transparent">
                            </iframe>
                        </div>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="843290" data-title="Project Architecture and Roles" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/843/290/datas/original.jpg">
                            <img alt="VocabViz &ndash; screenshot 1" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/843/290/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Project Architecture and Roles
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="843362" data-title="VocabViz Logo" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/843/362/datas/original.png">
                            <img alt="VocabViz &ndash; screenshot 2" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/843/362/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                VocabViz Logo
                            </i>
                        </p>
                    </li>
                </ul>
            </div>
            <div>
                <h1>
                    VocabViz
                </h1>
                <p>
                    Learning new language vocabulary through an interactive AR experience.
                </p>
                <h2>
                    Team
                </h2>
                <ul>
                    <li>
                        <strong>
                            Hector Castillo
                        </strong>
                        -
                        <em>
                            MIT '20
                        </em>
                        | Integration, Infrastructure
                    </li>
                    <li>
                        <strong>
                            Evan Hostetler
                        </strong>
                        -
                        <em>
                            MIT '22
                        </em>
                        | Hardware Specialist, Branding
                    </li>
                    <li>
                        <strong>
                            Anthony Nardomarino
                        </strong>
                        -
                        <em>
                            MIT '22
                        </em>
                        | Object Classification Specialist
                    </li>
                    <li>
                        <strong>
                            Tony Terrasa
                        </strong>
                        -
                        <em>
                            MIT '21
                        </em>
                        | AR Specialist, Integration
                    </li>
                    <li>
                        <strong>
                            Grady Thomas
                        </strong>
                        -
                        <em>
                            MIT '23
                        </em>
                        | Translation API Specialist
                    </li>
                </ul>
                <h2>
                    Inspiration
                </h2>
                <p>
                    We saw a huge opportunity to transform the way people learn languages by using computer vision to reimagine the most effective language learning strategy: immersion. At Vocab Viz we are driven not only to help the world learn new languages with practical tools, but to bring the world a little closer together.
                </p>
                <h2>
                    What It Does
                </h2>
                <p>
                    VocabViz is a way to learn vocabulary in different languages by detecting what an object is and translating it in real time using the camera on your device.
                </p>
                <h2>
                    How We Built It
                </h2>
                <p>
                    VocabViz runs on four main technologies. These include:
                </p>
                <ul>
                    <li>
                        Python
                    </li>
                    <li>
                        <a href="https://cloud.ibm.com/catalog/services/visual-recognition" rel="nofollow">
                            IBM Visual Recognition
                        </a>
                    </li>
                    <li>
                        <a href="https://cloud.google.com/translate/?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=na-US-all-en-dr-bkws-all-all-trial-e-dr-1007179&amp;utm_content=text-ad-none-any-DEV_c-CRE_297670894993-ADGP_Hybrid+%7C+AW+SEM+%7C+BKWS+%7C+US+%7C+en+%7C+EXA+%7E+ML/AI+%7E+Translation+API+%7E+google+cloud+translate-KWID_43700037004364741-kwd-166600839370&amp;utm_term=KW_google%20cloud%20translate-ST_google+cloud+translate&amp;gclid=Cj0KCQjwn_LrBRD4ARIsAFEQFKue6OWXW_-XTgIPRACTeE5FLx12wreHO63RJapJ-rZMMRt2lUtndhgaAvfXEALw_wcB" rel="nofollow">
                            Google Cloud Translation API
                        </a>
                    </li>
                    <li>
                        <a href="https://https://opencv.org/" rel="nofollow">
                            OpenCV - Object Tracking and I/O
                        </a>
                    </li>
                </ul>
                <p>
                    We start with a video stream. This can be fed in through any input, but for simplicity we chose the built-it webcam for our laptop. A section of the screen is then selected to be recognized and run through the IBM API.
                </p>
                <h2>
                    Challenges Encountered
                </h2>
                <p>
                    With such a short time span, some of the hardest challenges were to download the proper dependencies.
                </p>
                <p>
                    Another challenge we faced was to determine which of the outputs from IBM&rsquo;s API to choose to display. We ended up using a system that works like a weighted average by class number and percentage match.
                </p>
                <p>
                    One of the hardest things about working with several parts that get coded by different people is ensuring that the inputs and outputs of the different modules are compatible. We ran into an issue where the output of the IBM API was a string, but the most convenient way to read that information was by reading it out of a JSON into a dictionary.
                </p>
                <h2>
                    Accomplishments
                </h2>
                <p>
                    We were very proud of the integration between our four main technologies that allowed for a functional visual translator. The fact that we accomplished so much within a day with limited coding experience is something we&rsquo;re very proud of.
                </p>
                <h2>
                    What We Learned
                </h2>
                <p>
                    We learned how to use object tracking in OpenCV.
                </p>
                <p>
                    Furthermore, this being one of the first major collaborative projects done by some of the members of the team, several team members learned to use Git through this project. We also learned about the importance of documenting and making agreements as early as possible about the formats of the inputs and outputs of different modules. We saw an incompatibility, and because of this, we were able to combat it and sure that the data was passed as effectively as possible through the workflow.
                </p>
                <h2>
                    What's Next
                </h2>
                <p>
                    This application could be quite powerful as a mobile application. This would give people the ability to learn new vocabulary on the go.
                </p>
                <p>
                    We also foresee several improvements to the user interface. For example, plugging into a dictionary API could give a way to not just translate the word, but give the option for scrolling over to show more information including definition, sentence examples, synonyms and antonyms. Features could be added to the GUI to allow for easier change of language and the ability to see more than just two languages displayed on the screen.
                </p>
                <p>
                    Furthermore, one of the powerful things of IBM&rsquo;s API is that it gives you several possibilities for the identification of the object. A useful future feature would be to cycle through different identifications as a means to learn different ways to describe the object that you are looking at and trying to describe in another language.
                </p>
                <h2>
                    Dependencies
                </h2>
                <p>
                    The following will be necessary to run VocabViz
                </p>
                <ul>
                    <li>
                        Python2.7
                    </li>
                    <li>
                        Pillow==6.1.0
                    </li>
                    <li>
                        OpenCV-Contrib==3.4.4
                    </li>
                    <li>
                        Numpy==1.16.5
                    </li>
                    <li>
                        ibm-watson==3.4.0
                    </li>
                    <li>
                        google-cloud-translate==1.6.0
                    </li>
                </ul>
                <pre class="language-nolang"><code>  pip install opencv-contrib-python==3.4.4.19  
        pip install pillow
  pip install numpy
  pip install ibm_watson
  pip install --upgrade google-cloud-translate
</code></pre>
                <p>
                    In order to run the google translate, you need the private key to access Google Cloud Services. Download your key and make sure the following environment variable is set:
                </p>
                <pre class="language-nolang"><code>  export GOOGLE_APPLICATION_CREDENTIALS="/path/to/key"
</code></pre>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/google-cloud">
                                google-cloud
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/ibm-watson">
                                ibm-watson
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/opencv">
                                opencv
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/python">
                                python
                            </a>
                        </span>
                    </li>
                </ul>
            </div>
            <nav class="app-links section">
                <h2>
                    Try it out
                </h2>
                <ul class="no-bullet" data-role="software-urls">
                    <li>
                        <a href="https://github.com/HectorACastillo/HackMIT2019" rel="nofollow" target="_blank" title="https://github.com/HectorACastillo/HackMIT2019">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                github.com
                            </span>
                        </a>
                    </li>
                </ul>
            </nav>
        </div>
    </body>
</html>
