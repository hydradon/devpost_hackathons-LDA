<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li>
                        <div class="flex-video">
                            <iframe allowfullscreen="allowfullscreen" allowscriptaccess="always" class="video-embed" frameborder="0" height="371" mode="transparent" src="https://www.youtube.com/embed/vE7q2J6y1Fg?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;start=&amp;version=3&amp;wmode=transparent" type="text/html" webkitallowfullscreen="true" width="660" wmode="transparent">
                            </iframe>
                        </div>
                    </li>
                </ul>
            </div>
            <div>
                <h2>
                    HEAR - Generating Subtitles for Life
                </h2>
                <h3>
                    Introduction
                </h3>
                <p>
                    HEAR is an iOS application that adds visual aid during an oral conversation for individuals with hearing impairments. It uses
                    <strong>
                        speech-to-text
                    </strong>
                    technology integrated with
                    <strong>
                        Augmented Reality
                    </strong>
                    and
                    <strong>
                        facial recognition
                    </strong>
                    to add subtitles underneath each speaker throughout a conversation.
                </p>
                <h3>
                    Demo
                </h3>
                <h5>
                    A simple scenario showcasing our app in a classroom environment.
                    <br>
                    <br>
                </h5>
                <p>
                    <img alt="Demo Gif" data-canonical-url="https://github.com/jacobrs/HEAR/raw/master/demo.gif" src="https://res.cloudinary.com/devpost/image/fetch/s--tfyf5qZ2--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://github.com/jacobrs/HEAR/raw/master/demo.gif">
                    <br>
                    <br>
                </p>
                <h5>
                    A simple scenario showcasing our app in a conversational environment.
                    <br>
                    <br>
                </h5>
                <p>
                    <img alt="Demo Gif" data-canonical-url="https://github.com/jacobrs/HEAR/raw/master/demo-convo.gif" src="https://res.cloudinary.com/devpost/image/fetch/s--3re0hsrn--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://github.com/jacobrs/HEAR/raw/master/demo-convo.gif">
                </p>
                <h3>
                    Inspiration
                </h3>
                <p>
                    Inspired by a recent conference talk on accessibility as well as family members that are hearing impaired, we wanted to create a hack that targeted pain points that individuals with hard of hearing deal with, every day.
                </p>
                <h3>
                    Technologies
                    <br>
                    <br>
                </h3>
                <img data-canonical-url="https://developer.apple.com/assets/elements/icons/arkit/arkit-64x64_2x.png" src="https://res.cloudinary.com/devpost/image/fetch/s--jhZMkpaz--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://developer.apple.com/assets/elements/icons/arkit/arkit-64x64_2x.png">
                <img data-canonical-url="https://developer.apple.com/assets/elements/icons/core-ml/core-ml-64x64_2x.png" src="https://res.cloudinary.com/devpost/image/fetch/s--uqpjNHHw--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://developer.apple.com/assets/elements/icons/core-ml/core-ml-64x64_2x.png">
                <img data-canonical-url="https://developer.apple.com/assets/elements/icons/sirikit/sirikit-64x64_2x.png" src="https://res.cloudinary.com/devpost/image/fetch/s--PIvdAovQ--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://developer.apple.com/assets/elements/icons/sirikit/sirikit-64x64_2x.png">
                <img data-canonical-url="https://developer.apple.com/assets/elements/icons/spritekit/spritekit-64x64_2x.png" src="https://res.cloudinary.com/devpost/image/fetch/s--g5f9Njkz--/c_limit,f_auto,fl_lossy,q_auto:eco,w_900/https://developer.apple.com/assets/elements/icons/spritekit/spritekit-64x64_2x.png">
                <p>
                    <br>
                </p>
                <h4>
                    ARKit 2
                </h4>
                <p>
                    The ARKit 2 was used to capture objects in a 3D scene and attach subtitle nodes to them allowing the subtitles to follow speakers. Subtitle text size is dictated based off distance which would not be possible without ARKit.
                </p>
                <h4>
                    CoreML 2
                </h4>
                <p>
                    CoreML2 was mostly used for its computer vision application. HEAR uses facial recognition to detect potential speakers and to position subtitles in the right position. This is achieved efficiently by utilizing the Vision API.
                </p>
                <h4>
                    SiriKit
                </h4>
                <p>
                    Speech to text is the most important feature of HEAR and for that reason, the SiriKit was chosen to transcribe speech from speakers to subtitles. Having Siri perform some computations and natural language processing locally helps speedup the transcription which leads to a better user experience.
                </p>
                <h4>
                    SpriteKit
                </h4>
                <p>
                    HEAR uses SpriteKit to overlay the subtitles in a 3D environment. SpriteKit also allows text customization to make the text clearer and more legible on varying backgrounds.
                </p>
                <h3>
                    Challenges
                </h3>
                <p>
                    As none of the members were familiar with Swift or iOS development, creating the HEAR iOS application and utilizing advanced technologies was both challenging and exciting. While the learning curve was steep, working together through paired programming helped us work through problems efficiently as well as ease the transition of learning a completely new environment.
Technically, we ran into trouble using SpriteKit and ARKit, as most tutorials and documentation required the user to touch where they wanted to place an object. We wanted our object placed based off of the decision made from the facial recognition software we created. Calculating the true depth and changing the subtitle attributes accordingly required more math than we were ready for.
                </p>
                <h3>
                    Future Plans
                </h3>
                <p>
                    The HEAR team has many ambitious plans for the application some of which include:
                </p>
                <ul>
                    <li>
                        Simultaneous speakers and subtitles
                    </li>
                    <li>
                        More accurate speaker tracking
                    </li>
                    <li>
                        Higher accuracy in noisy environments
                    </li>
                    <li>
                        Syncing of conversations to cloud for later review
                    </li>
                    <li>
                        Integration into augmented reality lenses
                    </li>
                    <li>
                        Real time translation of subtitles
                    </li>
                </ul>
                <h3>
                    Authors
                </h3>
                <p>
                    Benjamin Barault, Francesco Valela, Jacob Gagn&eacute;, Tobi D&eacute;cary-Larocque
                </p>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag">
                            arkit
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag">
                            coreml
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag">
                            sirikit
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/sprite-kit">
                                sprite-kit
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/swift">
                                swift
                            </a>
                        </span>
                    </li>
                </ul>
            </div>
            <nav class="app-links section">
                <h2>
                    Try it out
                </h2>
                <ul class="no-bullet" data-role="software-urls">
                    <li>
                        <a href="https://github.com/jacobrs/HEAR" rel="nofollow" target="_blank" title="https://github.com/jacobrs/HEAR">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                github.com
                            </span>
                        </a>
                    </li>
                </ul>
            </nav>
        </div>
    </body>
</html>
