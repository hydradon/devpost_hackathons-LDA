<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li>
                        <div class="flex-video">
                            <iframe allowfullscreen="allowfullscreen" allowscriptaccess="always" class="video-embed" frameborder="0" height="371" mode="transparent" src="https://www.youtube.com/embed/3ry-XFrLBKE?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;start=&amp;version=3&amp;wmode=transparent" type="text/html" webkitallowfullscreen="true" width="660" wmode="transparent">
                            </iframe>
                        </div>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="844074" data-title="Burned house identification" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/074/datas/original.png">
                            <img alt="BeyondVision.ai &ndash; screenshot 1" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/074/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Burned house identification
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="844075" data-title="Pole identification" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/075/datas/original.png">
                            <img alt="BeyondVision.ai &ndash; screenshot 2" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/075/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Pole identification
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="844076" data-title="Non-burned house" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/076/datas/original.png">
                            <img alt="BeyondVision.ai &ndash; screenshot 3" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/076/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Non-burned house
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="844077" data-title="Product Vision mockup: Integrated GIS system for Utilities" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/077/datas/original.png">
                            <img alt="BeyondVision.ai &ndash; screenshot 4" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/077/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                                Product Vision mockup: Integrated GIS system for Utilities
                            </i>
                        </p>
                    </li>
                </ul>
            </div>
            <div>
                <h2>
                    Inspiration
                </h2>
                <p>
                    Wildfires are one of the biggest recurring problems faced in California today. They cause loss of life and property and are extremely expensive. In the US, there are 4.5 million homes at risk of being affected by wildfires, with 2 million being in California. Over the past 10 years, losses from wildfires have gone beyond $5.1 billion. Being students in Berkeley, this affects us dearly and we wanted to use our technical skills to combat the problem. When we got to know about drones flying over wildfire affected regions, we realized that creating a system to help first responders would be beneficial in terms of time and cost, and would help people that have already been through a lot of suffering.
                </p>
                <p>
                    Another aspect of wildfires is the reason that they are caused. When we got to know about last year's fires being caused due to vegetation impacting utility cables, we sought to look at prevention aspect as well, so as to have a well rounded solution. Most utility infrastructure is very old and requires regular maintenance. However, it is hard to prioritize which infrastructure to inspect first, since the process is extremely manual and individuals are required to drive down and look at the affected poles/cables. As drones get adopted to fly over these poles and cables for inspection, they generate a lot of images which have to be manually looked through. This takes time and effort, and has also been inaccurate over time because of fatigue. To combat this problem, we wanted to create a first level solution that could categorize images in categories and reduce the number to be looked at, so as to speed up the decision making process, and thus prevent wildfires by timely maintenance.
                </p>
                <p>
                    We wanted to use the Computer Vision capabilities of drones and the resources provided by PyTorch to create a positive impact on businesses (like PG&amp;E) and people by protecting them and even helping them recover after a disaster.
                </p>
                <h2>
                    What it does
                </h2>
                <p>
                    We have a two-part solution:
                </p>
                <p>
                    <strong>
                        Prevention
                    </strong>
                    : Drones are flown over utility poles and lines to inspect for maintenance problems. However, drones capture large number of images which have to be manually sorted through in order to find problems. This results in a lot of time being invested and over time, bad judgement calls due to human fatigue. The system we have developed here utilizes deep learning to assist in the first level of separation between utility poles and images with only cables/vegetation, which can then be operated upon by the human evaluators.
                </p>
                <p>
                    <strong>
                        Rehabilitation
                    </strong>
                    : Drones are increasingly being flown over wildfire affected areas in California to assist in rehabilitation efforts and identify whether or not it is safe for people to return to their homes. In most cases however, this identification is a largely manual process with human operators going through a large number of images and making judgement calls. Considering how important time is as a factor in rescue and rehabiliation operations, we have created a system that can identify burned homes and along with location information correlated with the image, help first responders in their tasks. This speeds up the operation and allows for valuable human resources to be reassigned to the rehabilitation tasks.
                </p>
                <p>
                    In the portal we have shared, operators can add the image they want to analyze for burned homes or poles and the system will output the result. Over time, we would want people to upload multiple images and have the results come out in separate folders in order to further speed up operations. We would also want to further integrate this into a GIS system that can depict high risk infrastructure with details (as showed in the video).
                </p>
                <h2>
                    How we built it
                </h2>
                <p>
                    We used Google Colab and fastai built upon pytorch to create models by training on the data we collected. We collected all the data we could before building the model. Since this was limited data, we used data augmentation techniques to help the model generalize better. We used deeper neural nets for higher accuracy. Once we got the model weights, we used Render as a service to host our model and make it interactive for people to play around with. We have also attached images in the shared code to test the system with.
                </p>
                <h2>
                    Challenges we ran into
                </h2>
                <p>
                    The limited amount of data was the biggest challenge we had, because of which it was hard to train models. The transforms and data augmentation techniques really helped us to create a model that could give high accuracy. Apart from the difficulty in gathering the data, it had to be annotated manually, which gave us an appreciation for how time-consuming and difficult it is, especially when the stakes are high.
                </p>
                <p>
                    Building a simple, seamless flow for an end-user, and dynamically loading the model with limited cloud resources were the two very important hurdles we had to overcome in order to make the solution usable. Initially, we tried to build the cloud infrastructure in AWS using AWS Lambda and AWS CloudGateway API but we wanted to send images in multipart/form-data format to our backend and there wasn't a good parser library for the same. Hence, we had to fall back to using render.
                </p>
                <h2>
                    Accomplishments that we're proud of
                </h2>
                <p>
                    Considering the fact that our primary users would be people who are not necessarily tech savvy, we were able to come up with an extremely simple and usable interface which would make their jobs much more efficient. By integrating the models we have with a lightweight front end framework, we would be able to quickly provide value for those in need.
                </p>
                <p>
                    We are also proud of the fact of how were able to come up with an end-of-end system/pipeline/infrastructure that we can easily replicate for other use cases as we move along further. Most of all however, we are excited about the potential to be able to cause a positive impact using our skills.
                </p>
                <h2>
                    What we learned
                </h2>
                <p>
                    We learned that there are many open source tools and technologies available in the market for us to begin learning, experimenting with and implementing valuable services. Especially with PyTorch, it became very easy for us to apply the theory we had read and see tangible outputs in short periods of time. We soon learned about fastai built on top of PyTorch that allowed us to further speed up our experimentations and decision making.
                </p>
                <p>
                    We also learned how valuable open source data, forums and technologies are, and are thankful to all those who create these and give students like us opportunities to innovate.
                </p>
                <h2>
                    What's next for BeyondVision.ai
                </h2>
                <p>
                    We feel that there are a lot of use cases and challenges in the world that could be combated with deep learning open source technologies like PyTorch. As we progress, we would want to develop an end-to-end system which has minimum user interaction in order to speed up menial tasks. The multiple image upload and GIS integration are reflections of this ambition. We would also want to explore other use cases which we can expand our system to address.
                </p>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag">
                            fastai
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag">
                            google-colab
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/javascript">
                                javascript
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/python">
                                python
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/pytorch">
                                pytorch
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag">
                            render
                        </span>
                    </li>
                </ul>
            </div>
            <nav class="app-links section">
                <h2>
                    Try it out
                </h2>
                <ul class="no-bullet" data-role="software-urls">
                    <li>
                        <a href="https://beyondvision-ai.onrender.com/" rel="nofollow" target="_blank" title="https://beyondvision-ai.onrender.com/">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                beyondvision-ai.onrender.com
                            </span>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/Ankit050/pytorchhackathon" rel="nofollow" target="_blank" title="https://github.com/Ankit050/pytorchhackathon">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                github.com
                            </span>
                        </a>
                    </li>
                </ul>
            </nav>
        </div>
    </body>
</html>
