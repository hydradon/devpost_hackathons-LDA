<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li class="text-center">
                        <a data-lightbox="844086" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/086/datas/original.png">
                            <img alt="En Fran&ccedil;ais, Si Vous Plait? &ndash; screenshot 1" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/086/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="844087" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/087/datas/original.png">
                            <img alt="En Fran&ccedil;ais, Si Vous Plait? &ndash; screenshot 2" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/087/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="844088" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/088/datas/original.png">
                            <img alt="En Fran&ccedil;ais, Si Vous Plait? &ndash; screenshot 3" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/088/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                            </i>
                        </p>
                    </li>
                    <li class="text-center">
                        <a data-lightbox="844085" href="https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/085/datas/original.png">
                            <img alt="En Fran&ccedil;ais, Si Vous Plait? &ndash; screenshot 4" class="software_photo_image image-replacement" onerror="this.onerror=null;this.src='https://devpost-challengepost.netdna-ssl.com/assets/defaults/thumbnail-placeholder-42bcab8d8178b413922ae2877d8b0868.gif';" src="//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/844/085/datas/gallery.jpg">
                        </a>
                        <span class="expand-tag">
                            <i class="fas fa-expand">
                            </i>
                        </span>
                        <p>
                            <i>
                            </i>
                        </p>
                    </li>
                </ul>
            </div>
            <div>
                <h1>
                    En Fran&ccedil;ais, Si Vous Plait?
                </h1>
                <p>
                    <strong>
                        This is a machine learning natural language processing (NLP) project submission for the
                        <a href="https://pytorch.devpost.com/" rel="nofollow">
                            Global PyTorch Summer Hackathon! #PTSH19
                        </a>
                    </strong>
                    . Pour la documentation en fran&ccedil;ais,
                    <a href="https://github.com/lucylow/en_francais_si_vous_plait-/blob/master/README-fr.md" rel="nofollow">
                        cliquez ici!
                    </a>
                </p>
                <hr>
                <h2>
                    Language Barrier Motivation
                </h2>
                <ul>
                    <li>
                        French-English translation service using natural language processing (NLP) with a vision of connecting people through language and advancing a
                        <strong>
                            barrier free society for billingual speakers
                        </strong>
                    </li>
                    <li>
                        As a Canadian citizen, ensure respect for
                        <strong>
                            English and French as the offical languages of Canada
                        </strong>
                        and have equality of status, rights, and privileges
                    </li>
                </ul>
                <hr>
                <h2>
                    Applications &amp; Market Opportunities
                </h2>
                <ul>
                    <li>
                        <strong>
                            Customer Service
                        </strong>
                        <ul>
                            <li>
                                Chatbots taking over repetitive
                                <strong>
                                    easy-to-automate human jobs
                                </strong>
                            </li>
                            <li>
                                Ex: Bank tellers, cashiers, or sales associates
                            </li>
                        </ul>
                    </li>
                    <li>
                        <strong>
                            Legal Industry
                        </strong>
                        <ul>
                            <li>
                                NLP used to
                                <strong>
                                    automate or summarize
                                </strong>
                                long and mundane documents
                            </li>
                            <li>
                                Ex: One legal case has an average of 400-500 pages
                            </li>
                        </ul>
                    </li>
                    <li>
                        <strong>
                            Financial Industry
                        </strong>
                        <ul>
                            <li>
                                <strong>
                                    Reduce the manual processing
                                </strong>
                                required to retrive corporate data
                            </li>
                            <li>
                                Ex: Information from financial reports, press releases, or news articles
                            </li>
                        </ul>
                    </li>
                </ul>
                <hr>
                <h2>
                    Natural Language Processing (NLP)
                </h2>
                <ul>
                    <li>
                        Sub-field in
                        <strong>
                            Artifical Intelligence using machine learning and artifical neural networks
                        </strong>
                    </li>
                    <li>
                        Ability of a machine to analyse, understand, and generate human speech
                    </li>
                    <li>
                        Natural languages
                        <ul>
                            <li>
                                <strong>
                                    Languages that are native to people
                                </strong>
                            </li>
                            <li>
                                Ex: English, French, or Mandarin
                            </li>
                        </ul>
                    </li>
                    <li>
                        Artificial languages
                        <ul>
                            <li>
                                <strong>
                                    Languages that computers can operate on
                                </strong>
                            </li>
                            <li>
                                Ex: Python, Java, or C++
                            </li>
                        </ul>
                    </li>
                </ul>
                <hr>
                <h2>
                    Technical Tools
                </h2>
                <ul>
                    <li>
                        <p>
                            <a href="https://pytorch.org" rel="nofollow">
                                <strong>
                                    Pytorch
                                </strong>
                            </a>
                        </p>
                        <ul>
                            <li>
                                Open source deep learning research platform that provides maximum flexibility and speed and provides tensors that live on the GPU accelerating the computation
                            </li>
                        </ul>
                    </li>
                    <li>
                        <p>
                            <a href="https://ai.facebook.com/tools/fairseq/" rel="nofollow">
                                <strong>
                                    Facebook Research's Fairseq
                                </strong>
                            </a>
                        </p>
                        <ul>
                            <li>
                                Sequence modeling toolkit written in PyTorch
                            </li>
                            <li>
                                Train custom models for
                                <strong>
                                    Neural Machine Translation (NMT)
                                </strong>
                                - translation, summarization, language modeling, and other text generation tasks
                            </li>
                        </ul>
                    </li>
                    <li>
                        <p>
                            <a href="https://arxiv.org/pdf/1706.03762.pdf" rel="nofollow">
                                <strong>
                                    Transformer Machine Learning Model with Sequence-Aligned RNNs or CNNs
                                </strong>
                            </a>
                        </p>
                        <ul>
                            <li>
                                Machine language translation transformer model from
                                <a href="https://arxiv.org/abs/1706.03762" rel="nofollow">
                                    <strong>
                                        <em>
                                            Attention Is All You Need
                                        </em>
                                    </strong>
                                </a>
                                using
                                <strong>
                                    encoder-decoder attention mechanisms
                                </strong>
                                in a
                                <strong>
                                    sequence-to-sequence model
                                </strong>
                                that features stacked self attention layers
                            </li>
                            <li>
                                Transduction model relying on
                                <strong>
                                    self-attention layers to compute input and output represenations
                                </strong>
                                where the attention functions maps [query, key-value pairs] to vector outputs of [query, key-value pairs]
                            </li>
                            <li>
                                The encoder maps sequence X_n (x_1, x_2 ... x_n) --&gt; sequence Z_n (z_1, z_2 ... z_n). From Z_n, the decoder generates sequence Y_n (y_1, y_2 ... y_n) element by element.
                            </li>
                        </ul>
                    </li>
                </ul>
                <hr>
                <h2>
                    Convolutional Self-Attention Transformer Modelling
                </h2>
                <ul>
                    <li>
                        <p>
                            Measure speed translations
                        </p>
                        <ul>
                            <li>
                                Record the translation time once machine learning system is shown a sentence to quantify results
                            </li>
                            <li>
                                "On the
                                <strong>
                                    WMT 2014 English-to-French translation task
                                </strong>
                                (a widely used
                                <strong>
                                    benchmark metric
                                </strong>
                                for judging the accuracy of machine translation), attention model establishes a BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature"
                            </li>
                        </ul>
                    </li>
                    <li>
                        <p>
                            Gating to control flow of hidden-units
                        </p>
                    </li>
                    <li>
                        <p>
                            <strong>
                                Multi-Hop Attention Functionality
                            </strong>
                        </p>
                        <ul>
                            <li>
                                Self attention layers - where all the keys, values, and queries come from the same input
                            </li>
                            <li>
                                CNN encoder creates a vector for each word to be translated, and CNN decoder translates words while PyTorch computations are being simultaneously made.
                                <strong>
                                    Network has two decoder layers and attention is paid to each layer.
                                </strong>
                            </li>
                            <li>
                                <strong>
                                    Multi-hop Attention
                                </strong>
                                tensor computations where green lines represent attention paid to each French word.
                            </li>
                        </ul>
                    </li>
                </ul>
                <hr>
                <h2>
                    French-English Translation Dataset
                </h2>
                <ul>
                    <li>
                        Statistical machine translation
                        <a href="http://statmt.org/wmt14/translation-task.html#Download" rel="nofollow">
                            WMT 2014 French-English Benchmark
                        </a>
                        with
                        <strong>
                            corpus size 2.3GB and 36 million sentence pairs
                        </strong>
                        . Dataset too big to include in repo -
                        <strong>
                            download and extract to /data/iwslt14/
                        </strong>
                        to replace iwslt14.en.txt and iwslt14.fr.txt
                    </li>
                    <li>
                        For French-English translations, order of words matter and and the number of words can be added during the translation. "Black cat" translate to "chat noir" and the "not" translate to "ne ___ pas". Refer to image below:
                    </li>
                    <li>
                        Dataset includes: Commoncrawl, Europarl-v7, Giga, News-commentary, and Undoc data
                    </li>
                </ul>
                <hr>
                <h2>
                    Pre-Process the WMT2014 Text Data
                </h2>
                <pre class="language-terminal"><code>cd data/
bash prepare-iwslt14.sh

TEXT=data/iwslt14.tokenized.fr-en

# Binarize data
$ fairseq preprocess -sourcelang fr -targetlang en \
-trainpref $TEXT/train -validpref $TEXT/valid -testpref $TEXT/test \
-thresholdsrc 3 -thresholdtgt 3 -destdir data-bin/iwslt14.tokenized.fr-en
-workers 60
</code></pre>
                <hr>
                <h2>
                    Technical Train the French-English Model
                </h2>
                <p>
                    <strong>
                        Train new CNN model (dropout rate of 0.2) with *-fairseq train
                    </strong>
                    *
                </p>
                <pre class="language-python"><code>$ mkdir -p trainings/fconv

$ fairseq train -sourcelang fr -targetlang en -datadir data-bin/iwslt14.tokenized.fr-en \
-model fconv -nenclayer 4 -nlayer 3 -dropout 0.2 -optim nag -lr 0.25 -clip 0.1 \
-momentum 0.99 -timeavg -bptt 0 
-savedir trainings/fconv
</code></pre>
                <p>
                    <strong>
                        Model Generation with *-fairseq generate
                    </strong>
                    *
                </p>
                <pre class="language-python"><code>$ DATA=data-bin/iwslt14.tokenized.fr-en

$ fairseq generate-lines -sourcedict $DATA/dict.fr.th7 -targetdict $DATA/dict.en.th7 \
-path trainings/fconv/model_best_opt.th7 -beam 10 -nbest 
| [target] Dictionary: 24738 types
| [source] Dictionary: 35474 types

&gt; Je ne crains pas de mourir.

Source: Je ne crains pas de mourir.
Original_Sentence: Je ne crains pas de mourir.
Hypothesis: -0.23804219067097 I am not scared of dying.
Attention_Maxima: 2 2 3 4 5 6 7 8 9
Hypothesis: -0.23861141502857 I am not scared of dying.
Attention_Maxima: 2 2 3 4 5 7 6 7 9 9
</code></pre>
            </div>
            <div class="" id="built-with">
                <h2>
                    Built With
                </h2>
                <ul class="no-bullet inline-list">
                    <li>
                        <span class="cp-tag">
                            attention
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag">
                            cnn
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag">
                            convolutional-neural-network
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag">
                            fairseq
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/natural-language-processing">
                                natural-language-processing
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag recognized-tag">
                            <a href="https://devpost.com/software/built-with/pytorch">
                                pytorch
                            </a>
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag">
                            sequence-to-sequence
                        </span>
                    </li>
                    <li>
                        <span class="cp-tag">
                            transformer-encoder
                        </span>
                    </li>
                </ul>
            </div>
            <nav class="app-links section">
                <h2>
                    Try it out
                </h2>
                <ul class="no-bullet" data-role="software-urls">
                    <li>
                        <a href="https://github.com/lucylow/En_francais_si_vous_plait-" rel="nofollow" target="_blank" title="https://github.com/lucylow/En_francais_si_vous_plait-">
                            <i class="ss-icon ss-link">
                            </i>
                            <span>
                                github.com
                            </span>
                        </a>
                    </li>
                </ul>
            </nav>
        </div>
    </body>
</html>
