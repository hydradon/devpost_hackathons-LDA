<html>
    <head>
    </head>
    <body>
        <div class="large-9 columns" id="app-details-left">
            <div id="gallery">
                <ul>
                    <li>
                        <div class="flex-video">
                            <iframe allowfullscreen="allowfullscreen" allowscriptaccess="always" class="video-embed" frameborder="0" height="371" mode="transparent" src="https://www.youtube.com/embed/Lusj0-UuiG8?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;start=&amp;version=3&amp;wmode=transparent" type="text/html" webkitallowfullscreen="true" width="660" wmode="transparent">
                            </iframe>
                        </div>
                    </li>
                </ul>
            </div>
            <div>
                <h2>
                    Inspiration
                </h2>
                <p>
                    We wanted to help a group often overlooked by society-- the blind.
                </p>
                <h2>
                    What it does
                </h2>
                <p>
                    Helps the visually impaired regain their independence by providing them with tactile feedback to avoid obstacles and text-to-speech which describes the surrounding world.
                </p>
                <h2>
                    How we built it
                </h2>
                <ul>
                    <li>
                        AlwaysAI to implement object recognition
                    </li>
                    <li>
                        Arduino Uno to control proximity sensors and tactile feedback
                    </li>
                    <li>
                        Raspberry Pi to communicate recognized objects to user via speech synthesis
                    </li>
                    <li>
                        Laser cutting to custom design a frame
                    </li>
                </ul>
                <h2>
                    Challenges we ran into
                </h2>
                <ul>
                    <li>
                        Working around the poor range and precision of ultrasonic proximity detectors
                    </li>
                    <li>
                        Powering the multitude of servos and sensors
                    </li>
                    <li>
                        Setbacks when trying to integrate text-to-speech library with AlwaysAI
                    </li>
                    <li>
                        Not enough computational power on Raspberry Pi to utilize AlwaysAI
                    </li>
                </ul>
                <h2>
                    Accomplishments that we're proud of
                </h2>
                <ul>
                    <li>
                        Designing a portable power supply to support multiple servos, sensors and an Arduino
                    </li>
                    <li>
                        Custom designing a flexible, adaptable frame to support the electronics
                    </li>
                </ul>
                <h2>
                    What we learned
                </h2>
                <ul>
                    <li>
                        How to work under high-pressure deadlines
                    </li>
                    <li>
                        Integrate sensors and peripherals with Raspberry Pi and Arduino
                    </li>
                </ul>
                <h2>
                    What's next for Sonic Navigation and Object Recognition
                </h2>
                <ul>
                    <li>
                        Making the design more compact, discreet, and lightweight
                    </li>
                </ul>
            </div>
        </div>
    </body>
</html>
