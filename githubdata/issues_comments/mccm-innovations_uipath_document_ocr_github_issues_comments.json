[
    {
        "url": "https://api.github.com/repos/mccm-innovations/UiPath_Document_OCR/issues/comments/527400859",
        "html_url": "https://github.com/mccm-innovations/UiPath_Document_OCR/issues/1#issuecomment-527400859",
        "issue_url": "https://api.github.com/repos/mccm-innovations/UiPath_Document_OCR/issues/1",
        "id": 527400859,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUyNzQwMDg1OQ==",
        "user": {
            "login": "aarcosg",
            "id": 4061823,
            "node_id": "MDQ6VXNlcjQwNjE4MjM=",
            "avatar_url": "https://avatars1.githubusercontent.com/u/4061823?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/aarcosg",
            "html_url": "https://github.com/aarcosg",
            "followers_url": "https://api.github.com/users/aarcosg/followers",
            "following_url": "https://api.github.com/users/aarcosg/following{/other_user}",
            "gists_url": "https://api.github.com/users/aarcosg/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/aarcosg/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/aarcosg/subscriptions",
            "organizations_url": "https://api.github.com/users/aarcosg/orgs",
            "repos_url": "https://api.github.com/users/aarcosg/repos",
            "events_url": "https://api.github.com/users/aarcosg/events{/privacy}",
            "received_events_url": "https://api.github.com/users/aarcosg/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-09-03T10:28:37Z",
        "updated_at": "2019-09-03T10:28:37Z",
        "author_association": "CONTRIBUTOR",
        "body": "Hi @jialvarez.\r\n\r\nSadly, this project is closed as we developed it for an UiPath competition the last year. However, I would like to give you some tips.\r\n\r\nThe inference task should run faster even with that warning. I think that it is taking more time because the models have not been loaded in memory (warmup). First, you should make a first call to the /ping endpoint once the inference server is up and running so that models are loaded in memory and get ready for the following endpoint calls. Warming up models is a very time-consuming task.\r\n\r\nLet me know if your execution times are lower after that. I am sorry because we cannot provide to you further assistance.\r\n\r\nRegards,\r\n\u00c1lvaro\r\n"
    },
    {
        "url": "https://api.github.com/repos/mccm-innovations/UiPath_Document_OCR/issues/comments/527867896",
        "html_url": "https://github.com/mccm-innovations/UiPath_Document_OCR/issues/1#issuecomment-527867896",
        "issue_url": "https://api.github.com/repos/mccm-innovations/UiPath_Document_OCR/issues/1",
        "id": 527867896,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUyNzg2Nzg5Ng==",
        "user": {
            "login": "jialvarez",
            "id": 827495,
            "node_id": "MDQ6VXNlcjgyNzQ5NQ==",
            "avatar_url": "https://avatars3.githubusercontent.com/u/827495?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jialvarez",
            "html_url": "https://github.com/jialvarez",
            "followers_url": "https://api.github.com/users/jialvarez/followers",
            "following_url": "https://api.github.com/users/jialvarez/following{/other_user}",
            "gists_url": "https://api.github.com/users/jialvarez/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jialvarez/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jialvarez/subscriptions",
            "organizations_url": "https://api.github.com/users/jialvarez/orgs",
            "repos_url": "https://api.github.com/users/jialvarez/repos",
            "events_url": "https://api.github.com/users/jialvarez/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jialvarez/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-09-04T11:54:58Z",
        "updated_at": "2019-09-04T11:54:58Z",
        "author_association": "NONE",
        "body": "Hi again,\r\n\r\nI made a call to /ping endpoint and is taking 60sec too. I remember that in my first tests three days ago, the first call took this long time, but subsequent calls were acceptably fast (8 sec).\r\n\r\nI can't get that working time again, because in every call is processing that warmup you're talking about. I mean, in every call is loading the models as if it was its first time. Is there any way to ask the software for storing the models in memory?\r\n\r\nThanks for your help!"
    },
    {
        "url": "https://api.github.com/repos/mccm-innovations/UiPath_Document_OCR/issues/comments/528007073",
        "html_url": "https://github.com/mccm-innovations/UiPath_Document_OCR/issues/1#issuecomment-528007073",
        "issue_url": "https://api.github.com/repos/mccm-innovations/UiPath_Document_OCR/issues/1",
        "id": 528007073,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUyODAwNzA3Mw==",
        "user": {
            "login": "aarcosg",
            "id": 4061823,
            "node_id": "MDQ6VXNlcjQwNjE4MjM=",
            "avatar_url": "https://avatars1.githubusercontent.com/u/4061823?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/aarcosg",
            "html_url": "https://github.com/aarcosg",
            "followers_url": "https://api.github.com/users/aarcosg/followers",
            "following_url": "https://api.github.com/users/aarcosg/following{/other_user}",
            "gists_url": "https://api.github.com/users/aarcosg/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/aarcosg/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/aarcosg/subscriptions",
            "organizations_url": "https://api.github.com/users/aarcosg/orgs",
            "repos_url": "https://api.github.com/users/aarcosg/repos",
            "events_url": "https://api.github.com/users/aarcosg/events{/privacy}",
            "received_events_url": "https://api.github.com/users/aarcosg/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-09-04T17:40:01Z",
        "updated_at": "2019-09-04T17:49:22Z",
        "author_association": "CONTRIBUTOR",
        "body": "Hi @jialvarez,\r\n\r\nThat makes sense. Probably you are running out of memory and Python's garbage collector is doing its job. \r\n\r\nThere is a singleton for each model and you can find all of them in the `predictor.py` file. I would recommend you to just warm-up the specific models that you will use. For instance, you can comment the line 198 so the driving license model is not loaded. Another possible solution would be making a call to a model's endpoint and ignore its running time once. \r\n\r\nNote that all of the text detection models developed for this project use a lot of memory since they are based on deep neural networks and we aimed to achieve a high grade of accuracy rather than speed or low memory consumption.\r\n\r\nI hope that these tips can help you. By the way, it was a project developed for a code competition. Currently, we have created a better OCR engine for Spanish ID cards that is being used by our clients. So this project is just a good starting point.\r\n\r\nRegards,\r\n\u00c1lvaro"
    }
]