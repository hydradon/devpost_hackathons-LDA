[
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/159051952",
        "pull_request_review_id": 85942347,
        "id": 159051952,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1OTA1MTk1Mg==",
        "diff_hunk": "@@ -9,19 +9,17 @@ def set_usr_dir(config_path: str, usr_dir_name='USR_DIR') -> PurePath:\n     Make a serialization user dir.\n     \"\"\"\n     config = read_json(config_path)\n-    try:",
        "path": "deeppavlov/core/commands/utils.py",
        "position": null,
        "original_position": 4,
        "commit_id": "2eb6384a27500ab40bbce728b918ac5fff199b77",
        "original_commit_id": "0a8c536f70ae5b58a983e130b46d0daddb25a0bb",
        "user": {
            "login": "my-master",
            "id": 9787475,
            "node_id": "MDQ6VXNlcjk3ODc0NzU=",
            "avatar_url": "https://avatars1.githubusercontent.com/u/9787475?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/my-master",
            "html_url": "https://github.com/my-master",
            "followers_url": "https://api.github.com/users/my-master/followers",
            "following_url": "https://api.github.com/users/my-master/following{/other_user}",
            "gists_url": "https://api.github.com/users/my-master/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/my-master/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/my-master/subscriptions",
            "organizations_url": "https://api.github.com/users/my-master/orgs",
            "repos_url": "https://api.github.com/users/my-master/repos",
            "events_url": "https://api.github.com/users/my-master/events{/privacy}",
            "received_events_url": "https://api.github.com/users/my-master/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "try...except KeyError is more pythonic way to deal with dictionary keys checking than if...else",
        "created_at": "2017-12-29T11:29:55Z",
        "updated_at": "2018-01-09T08:04:16Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/1#discussion_r159051952",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/1",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/159051952"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/1#discussion_r159051952"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/1"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/159052038",
        "pull_request_review_id": 85942347,
        "id": 159052038,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1OTA1MjAzOA==",
        "diff_hunk": "@@ -9,19 +9,17 @@ def set_usr_dir(config_path: str, usr_dir_name='USR_DIR') -> PurePath:\n     Make a serialization user dir.\n     \"\"\"\n     config = read_json(config_path)\n-    try:\n+    if 'usr_dir' in config:\n         usr_dir = Path(config['usr_dir'])\n-    except KeyError:\n-        parent = Path(config_path).resolve().parent\n-        usr_dir = parent.joinpath(usr_dir_name)\n+    else:\n+        usr_dir = Path(config_path).expanduser().absolute().parent / usr_dir_name",
        "path": "deeppavlov/core/commands/utils.py",
        "position": null,
        "original_position": 11,
        "commit_id": "2eb6384a27500ab40bbce728b918ac5fff199b77",
        "original_commit_id": "0a8c536f70ae5b58a983e130b46d0daddb25a0bb",
        "user": {
            "login": "my-master",
            "id": 9787475,
            "node_id": "MDQ6VXNlcjk3ODc0NzU=",
            "avatar_url": "https://avatars1.githubusercontent.com/u/9787475?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/my-master",
            "html_url": "https://github.com/my-master",
            "followers_url": "https://api.github.com/users/my-master/followers",
            "following_url": "https://api.github.com/users/my-master/following{/other_user}",
            "gists_url": "https://api.github.com/users/my-master/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/my-master/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/my-master/subscriptions",
            "organizations_url": "https://api.github.com/users/my-master/orgs",
            "repos_url": "https://api.github.com/users/my-master/repos",
            "events_url": "https://api.github.com/users/my-master/events{/privacy}",
            "received_events_url": "https://api.github.com/users/my-master/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "Currently usr_dir should be defined relatively to config path, easier to perform experiments and debugging.",
        "created_at": "2017-12-29T11:31:15Z",
        "updated_at": "2018-01-09T08:04:16Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/1#discussion_r159052038",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/1",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/159052038"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/1#discussion_r159052038"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/1"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/159052754",
        "pull_request_review_id": 85942347,
        "id": 159052754,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1OTA1Mjc1NA==",
        "diff_hunk": "@@ -9,19 +9,17 @@ def set_usr_dir(config_path: str, usr_dir_name='USR_DIR') -> PurePath:\n     Make a serialization user dir.\n     \"\"\"\n     config = read_json(config_path)\n-    try:\n+    if 'usr_dir' in config:\n         usr_dir = Path(config['usr_dir'])\n-    except KeyError:\n-        parent = Path(config_path).resolve().parent\n-        usr_dir = parent.joinpath(usr_dir_name)\n+    else:\n+        usr_dir = Path(config_path).expanduser().absolute().parent / usr_dir_name\n \n-    if not usr_dir.exists():\n-        usr_dir.mkdir()\n+    usr_dir.mkdir(mode=0o755, exist_ok=True)",
        "path": "deeppavlov/core/commands/utils.py",
        "position": 10,
        "original_position": 15,
        "commit_id": "2eb6384a27500ab40bbce728b918ac5fff199b77",
        "original_commit_id": "0a8c536f70ae5b58a983e130b46d0daddb25a0bb",
        "user": {
            "login": "my-master",
            "id": 9787475,
            "node_id": "MDQ6VXNlcjk3ODc0NzU=",
            "avatar_url": "https://avatars1.githubusercontent.com/u/9787475?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/my-master",
            "html_url": "https://github.com/my-master",
            "followers_url": "https://api.github.com/users/my-master/followers",
            "following_url": "https://api.github.com/users/my-master/following{/other_user}",
            "gists_url": "https://api.github.com/users/my-master/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/my-master/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/my-master/subscriptions",
            "organizations_url": "https://api.github.com/users/my-master/orgs",
            "repos_url": "https://api.github.com/users/my-master/repos",
            "events_url": "https://api.github.com/users/my-master/events{/privacy}",
            "received_events_url": "https://api.github.com/users/my-master/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "Better: usr_dir.mkdir(exist_ok=True)",
        "created_at": "2017-12-29T11:40:19Z",
        "updated_at": "2018-01-09T08:04:16Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/1#discussion_r159052754",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/1",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/159052754"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/1#discussion_r159052754"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/1"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/159052781",
        "pull_request_review_id": 85942347,
        "id": 159052781,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1OTA1Mjc4MQ==",
        "diff_hunk": "@@ -9,19 +9,17 @@ def set_usr_dir(config_path: str, usr_dir_name='USR_DIR') -> PurePath:\n     Make a serialization user dir.\n     \"\"\"\n     config = read_json(config_path)\n-    try:\n+    if 'usr_dir' in config:\n         usr_dir = Path(config['usr_dir'])\n-    except KeyError:\n-        parent = Path(config_path).resolve().parent\n-        usr_dir = parent.joinpath(usr_dir_name)\n+    else:\n+        usr_dir = Path(config_path).expanduser().absolute().parent / usr_dir_name\n \n-    if not usr_dir.exists():\n-        usr_dir.mkdir()\n+    usr_dir.mkdir(mode=0o755, exist_ok=True)\n \n     paths.USR_PATH = usr_dir\n     return usr_dir\n \n \n def set_vocab_path() -> PurePath:\n-    return paths.USR_PATH.joinpath('vocab.txt')\n+    return paths.USR_PATH / 'vocab.txt'",
        "path": "deeppavlov/core/commands/utils.py",
        "position": 18,
        "original_position": 23,
        "commit_id": "2eb6384a27500ab40bbce728b918ac5fff199b77",
        "original_commit_id": "0a8c536f70ae5b58a983e130b46d0daddb25a0bb",
        "user": {
            "login": "my-master",
            "id": 9787475,
            "node_id": "MDQ6VXNlcjk3ODc0NzU=",
            "avatar_url": "https://avatars1.githubusercontent.com/u/9787475?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/my-master",
            "html_url": "https://github.com/my-master",
            "followers_url": "https://api.github.com/users/my-master/followers",
            "following_url": "https://api.github.com/users/my-master/following{/other_user}",
            "gists_url": "https://api.github.com/users/my-master/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/my-master/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/my-master/subscriptions",
            "organizations_url": "https://api.github.com/users/my-master/orgs",
            "repos_url": "https://api.github.com/users/my-master/repos",
            "events_url": "https://api.github.com/users/my-master/events{/privacy}",
            "received_events_url": "https://api.github.com/users/my-master/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "Ok",
        "created_at": "2017-12-29T11:40:37Z",
        "updated_at": "2018-01-09T08:04:16Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/1#discussion_r159052781",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/1",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/159052781"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/1#discussion_r159052781"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/1"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/160338891",
        "pull_request_review_id": 87436399,
        "id": 160338891,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MDMzODg5MQ==",
        "diff_hunk": "@@ -9,19 +9,17 @@ def set_usr_dir(config_path: str, usr_dir_name='USR_DIR') -> PurePath:\n     Make a serialization user dir.\n     \"\"\"\n     config = read_json(config_path)\n-    try:\n+    if 'usr_dir' in config:\n         usr_dir = Path(config['usr_dir'])\n-    except KeyError:\n-        parent = Path(config_path).resolve().parent\n-        usr_dir = parent.joinpath(usr_dir_name)\n+    else:\n+        usr_dir = Path(config_path).expanduser().absolute().parent / usr_dir_name\n \n-    if not usr_dir.exists():\n-        usr_dir.mkdir()\n+    usr_dir.mkdir(mode=0o755, exist_ok=True)",
        "path": "deeppavlov/core/commands/utils.py",
        "position": 10,
        "original_position": 15,
        "commit_id": "2eb6384a27500ab40bbce728b918ac5fff199b77",
        "original_commit_id": "0a8c536f70ae5b58a983e130b46d0daddb25a0bb",
        "user": {
            "login": "yoptar",
            "id": 5615053,
            "node_id": "MDQ6VXNlcjU2MTUwNTM=",
            "avatar_url": "https://avatars2.githubusercontent.com/u/5615053?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yoptar",
            "html_url": "https://github.com/yoptar",
            "followers_url": "https://api.github.com/users/yoptar/followers",
            "following_url": "https://api.github.com/users/yoptar/following{/other_user}",
            "gists_url": "https://api.github.com/users/yoptar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yoptar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yoptar/subscriptions",
            "organizations_url": "https://api.github.com/users/yoptar/orgs",
            "repos_url": "https://api.github.com/users/yoptar/repos",
            "events_url": "https://api.github.com/users/yoptar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yoptar/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "default value for mode is `0o777`, so i think mode should not be omitted",
        "created_at": "2018-01-09T08:06:45Z",
        "updated_at": "2018-01-09T08:06:45Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/1#discussion_r160338891",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/1",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/160338891"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/1#discussion_r160338891"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/1"
            }
        },
        "in_reply_to_id": 159052754
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/160388021",
        "pull_request_review_id": 87494115,
        "id": 160388021,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MDM4ODAyMQ==",
        "diff_hunk": "@@ -9,19 +9,17 @@ def set_usr_dir(config_path: str, usr_dir_name='USR_DIR') -> PurePath:\n     Make a serialization user dir.\n     \"\"\"\n     config = read_json(config_path)\n-    try:\n+    if 'usr_dir' in config:\n         usr_dir = Path(config['usr_dir'])\n-    except KeyError:\n-        parent = Path(config_path).resolve().parent\n-        usr_dir = parent.joinpath(usr_dir_name)\n+    else:\n+        usr_dir = Path(config_path).expanduser().absolute().parent / usr_dir_name\n \n-    if not usr_dir.exists():\n-        usr_dir.mkdir()\n+    usr_dir.mkdir(mode=0o755, exist_ok=True)",
        "path": "deeppavlov/core/commands/utils.py",
        "position": 10,
        "original_position": 15,
        "commit_id": "2eb6384a27500ab40bbce728b918ac5fff199b77",
        "original_commit_id": "0a8c536f70ae5b58a983e130b46d0daddb25a0bb",
        "user": {
            "login": "my-master",
            "id": 9787475,
            "node_id": "MDQ6VXNlcjk3ODc0NzU=",
            "avatar_url": "https://avatars1.githubusercontent.com/u/9787475?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/my-master",
            "html_url": "https://github.com/my-master",
            "followers_url": "https://api.github.com/users/my-master/followers",
            "following_url": "https://api.github.com/users/my-master/following{/other_user}",
            "gists_url": "https://api.github.com/users/my-master/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/my-master/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/my-master/subscriptions",
            "organizations_url": "https://api.github.com/users/my-master/orgs",
            "repos_url": "https://api.github.com/users/my-master/repos",
            "events_url": "https://api.github.com/users/my-master/events{/privacy}",
            "received_events_url": "https://api.github.com/users/my-master/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "System umask applies to mkdir() default value, so if the parent dir has 0o755 permission mode, the created dir won't have 0o777 permissions even if default mkdir() mode is 0o777. Here is more about the subject:\r\nhttps://bugs.python.org/issue5220",
        "created_at": "2018-01-09T12:00:19Z",
        "updated_at": "2018-01-09T12:00:19Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/1#discussion_r160388021",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/1",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/160388021"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/1#discussion_r160388021"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/1"
            }
        },
        "in_reply_to_id": 159052754
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/163518731",
        "pull_request_review_id": 91141266,
        "id": 163518731,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MzUxODczMQ==",
        "diff_hunk": "@@ -34,24 +51,35 @@ def __init__(self, data: Dict[str, List[Tuple[Any, Any]]], seed: int = None, *ar\n             'all': self.train + self.test + self.valid\n         }\n \n-    def batch_generator(self, batch_size: int, data_type: str = 'train') -> Generator:\n-        r\"\"\"This function returns a generator, which serves for generation of raw (no preprocessing such as tokenization)\n+    def batch_generator(self, batch_size: int, data_type: str = 'train',\n+                        shuffle: bool = None, seed: int = None) -> Generator:\n+        r\"\"\"This function returns a generator, which serves for generation of raw\n+        (no preprocessing such as tokenization)\n          batches\n         Args:\n             batch_size (int): number of samples in batch\n             data_type (str): can be either 'train', 'test', or 'valid'\n+            shuffle (bool): whether to shuffle dataset before batching\n+            seed (int): random seed for batching\n         Returns:\n             batch_gen (Generator): a generator, that iterates through the part (defined by data_type) of the dataset\n         \"\"\"\n+        if shuffle is not None:\n+            self.shuffle = shuffle",
        "path": "deeppavlov/core/data/dataset.py",
        "position": 65,
        "original_position": 65,
        "commit_id": "47ac86f50bde6f3fd4eb317026975c43321dbb14",
        "original_commit_id": "47ac86f50bde6f3fd4eb317026975c43321dbb14",
        "user": {
            "login": "yoptar",
            "id": 5615053,
            "node_id": "MDQ6VXNlcjU2MTUwNTM=",
            "avatar_url": "https://avatars2.githubusercontent.com/u/5615053?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yoptar",
            "html_url": "https://github.com/yoptar",
            "followers_url": "https://api.github.com/users/yoptar/followers",
            "following_url": "https://api.github.com/users/yoptar/following{/other_user}",
            "gists_url": "https://api.github.com/users/yoptar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yoptar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yoptar/subscriptions",
            "organizations_url": "https://api.github.com/users/yoptar/orgs",
            "repos_url": "https://api.github.com/users/yoptar/repos",
            "events_url": "https://api.github.com/users/yoptar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yoptar/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "I don't think that batch generator should be able to switch the shuffle flag for the dataset forever",
        "created_at": "2018-01-24T11:16:57Z",
        "updated_at": "2018-01-24T11:16:57Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/7#discussion_r163518731",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/7",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/163518731"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/7#discussion_r163518731"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/7"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/163519622",
        "pull_request_review_id": 91142295,
        "id": 163519622,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MzUxOTYyMg==",
        "diff_hunk": "@@ -34,24 +51,35 @@ def __init__(self, data: Dict[str, List[Tuple[Any, Any]]], seed: int = None, *ar\n             'all': self.train + self.test + self.valid\n         }\n \n-    def batch_generator(self, batch_size: int, data_type: str = 'train') -> Generator:\n-        r\"\"\"This function returns a generator, which serves for generation of raw (no preprocessing such as tokenization)\n+    def batch_generator(self, batch_size: int, data_type: str = 'train',\n+                        shuffle: bool = None, seed: int = None) -> Generator:\n+        r\"\"\"This function returns a generator, which serves for generation of raw\n+        (no preprocessing such as tokenization)\n          batches\n         Args:\n             batch_size (int): number of samples in batch\n             data_type (str): can be either 'train', 'test', or 'valid'\n+            shuffle (bool): whether to shuffle dataset before batching\n+            seed (int): random seed for batching\n         Returns:\n             batch_gen (Generator): a generator, that iterates through the part (defined by data_type) of the dataset\n         \"\"\"\n+        if shuffle is not None:\n+            self.shuffle = shuffle\n+        if seed is not None:\n+            self.seed = seed\n+\n         data = self.data[data_type]\n         data_len = len(data)\n         order = list(range(data_len))\n-\n-        rs = random.getstate()\n-        random.setstate(self.random_state)\n-        random.shuffle(order)\n-        self.random_state = random.getstate()\n-        random.setstate(rs)\n+        if self.shuffle:\n+            rs = random.getstate()\n+            random.seed(self.seed)",
        "path": "deeppavlov/core/data/dataset.py",
        "position": 80,
        "original_position": 80,
        "commit_id": "47ac86f50bde6f3fd4eb317026975c43321dbb14",
        "original_commit_id": "47ac86f50bde6f3fd4eb317026975c43321dbb14",
        "user": {
            "login": "yoptar",
            "id": 5615053,
            "node_id": "MDQ6VXNlcjU2MTUwNTM=",
            "avatar_url": "https://avatars2.githubusercontent.com/u/5615053?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yoptar",
            "html_url": "https://github.com/yoptar",
            "followers_url": "https://api.github.com/users/yoptar/followers",
            "following_url": "https://api.github.com/users/yoptar/following{/other_user}",
            "gists_url": "https://api.github.com/users/yoptar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yoptar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yoptar/subscriptions",
            "organizations_url": "https://api.github.com/users/yoptar/orgs",
            "repos_url": "https://api.github.com/users/yoptar/repos",
            "events_url": "https://api.github.com/users/yoptar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yoptar/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "Every epoch will most likely have the same seed, so the shuffling is always the same so there is basically no shuffling",
        "created_at": "2018-01-24T11:20:56Z",
        "updated_at": "2018-01-24T11:20:56Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/7#discussion_r163519622",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/7",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/163519622"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/7#discussion_r163519622"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/7"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/164995737",
        "pull_request_review_id": 92854813,
        "id": 164995737,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NDk5NTczNw==",
        "diff_hunk": "@@ -0,0 +1,22 @@\n+{\n+  \"@default\": {\n+    \"start_message\": \"Welcome to DeepPavlov inference bot!\",\n+    \"help_message\": \"Welcomr to DeepPavlov inference bot!\"",
        "path": "telegram_utils/models_info.json",
        "position": null,
        "original_position": 4,
        "commit_id": "165f796114cf6a0cae269e4e8831427de7fc1c0b",
        "original_commit_id": "fd8a599f15d4530bb1ce057f7d9b3267f1be2924",
        "user": {
            "login": "yoptar",
            "id": 5615053,
            "node_id": "MDQ6VXNlcjU2MTUwNTM=",
            "avatar_url": "https://avatars2.githubusercontent.com/u/5615053?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yoptar",
            "html_url": "https://github.com/yoptar",
            "followers_url": "https://api.github.com/users/yoptar/followers",
            "following_url": "https://api.github.com/users/yoptar/following{/other_user}",
            "gists_url": "https://api.github.com/users/yoptar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yoptar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yoptar/subscriptions",
            "organizations_url": "https://api.github.com/users/yoptar/orgs",
            "repos_url": "https://api.github.com/users/yoptar/repos",
            "events_url": "https://api.github.com/users/yoptar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yoptar/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "`Welcomr` \u2192\u00a0`Welcome`",
        "created_at": "2018-01-31T09:30:34Z",
        "updated_at": "2018-01-31T13:54:56Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/17#discussion_r164995737",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/17",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/164995737"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/17#discussion_r164995737"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/17"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/166656804",
        "pull_request_review_id": 94754950,
        "id": 166656804,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NjY1NjgwNA==",
        "diff_hunk": "@@ -0,0 +1,56 @@\n+\"\"\"\n+Copyright 2017 Neural Networks and Deep Learning lab, MIPT\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\"\"\"\n+\n+import pathlib\n+import json\n+import logging.config\n+import sys\n+\n+\n+LOG_CONFIG_FILENAME = 'log_config.json'\n+TRACEBACK_LOGGER_ERRORS = True\n+\n+\n+def get_logger(logger_name):\n+    try:\n+        config_dir = pathlib.PurePath(__file__).parent\n+        log_config_path = pathlib.Path(config_dir, '..', '..', LOG_CONFIG_FILENAME).resolve()",
        "path": "deeppavlov/core/common/log.py",
        "position": null,
        "original_position": 30,
        "commit_id": "18600f8fcb458427f492f66898b002f56c94fe55",
        "original_commit_id": "d22991450b52a8c5898a964bff643a86232519c0",
        "user": {
            "login": "yoptar",
            "id": 5615053,
            "node_id": "MDQ6VXNlcjU2MTUwNTM=",
            "avatar_url": "https://avatars2.githubusercontent.com/u/5615053?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yoptar",
            "html_url": "https://github.com/yoptar",
            "followers_url": "https://api.github.com/users/yoptar/followers",
            "following_url": "https://api.github.com/users/yoptar/following{/other_user}",
            "gists_url": "https://api.github.com/users/yoptar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yoptar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yoptar/subscriptions",
            "organizations_url": "https://api.github.com/users/yoptar/orgs",
            "repos_url": "https://api.github.com/users/yoptar/repos",
            "events_url": "https://api.github.com/users/yoptar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yoptar/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "\u041e\u0447\u0435\u043d\u044c \u0445\u043e\u0447\u0435\u0442\u0441\u044f\r\n```\r\nconfig_dir = Path(__file__).resolve().parent\r\nlog_config_path = config_dir.parent.parent / LOG_CONFIG_FILENAME\r\nwith log_config_path.open() as log_config_json:\r\n```",
        "created_at": "2018-02-07T15:40:32Z",
        "updated_at": "2018-02-08T12:25:47Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/43#discussion_r166656804",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/43",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/166656804"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/43#discussion_r166656804"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/43"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/166857755",
        "pull_request_review_id": 94985387,
        "id": 166857755,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2Njg1Nzc1NQ==",
        "diff_hunk": "@@ -0,0 +1,56 @@\n+\"\"\"\n+Copyright 2017 Neural Networks and Deep Learning lab, MIPT\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\"\"\"\n+\n+import pathlib\n+import json\n+import logging.config\n+import sys\n+\n+\n+LOG_CONFIG_FILENAME = 'log_config.json'\n+TRACEBACK_LOGGER_ERRORS = True\n+\n+\n+def get_logger(logger_name):\n+    try:\n+        config_dir = pathlib.PurePath(__file__).parent\n+        log_config_path = pathlib.Path(config_dir, '..', '..', LOG_CONFIG_FILENAME).resolve()",
        "path": "deeppavlov/core/common/log.py",
        "position": null,
        "original_position": 30,
        "commit_id": "18600f8fcb458427f492f66898b002f56c94fe55",
        "original_commit_id": "d22991450b52a8c5898a964bff643a86232519c0",
        "user": {
            "login": "litinsky",
            "id": 22733410,
            "node_id": "MDQ6VXNlcjIyNzMzNDEw",
            "avatar_url": "https://avatars3.githubusercontent.com/u/22733410?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/litinsky",
            "html_url": "https://github.com/litinsky",
            "followers_url": "https://api.github.com/users/litinsky/followers",
            "following_url": "https://api.github.com/users/litinsky/following{/other_user}",
            "gists_url": "https://api.github.com/users/litinsky/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/litinsky/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/litinsky/subscriptions",
            "organizations_url": "https://api.github.com/users/litinsky/orgs",
            "repos_url": "https://api.github.com/users/litinsky/repos",
            "events_url": "https://api.github.com/users/litinsky/events{/privacy}",
            "received_events_url": "https://api.github.com/users/litinsky/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "`config_dir = Path(__file__).resolve().parent` - fixed\r\n`log_config_path = config_dir.parent.parent / LOG_CONFIG_FILENAME` - matter of personal preferences\r\n`with log_config_path.open() as log_config_json:` - will be fixed with other `with open()` constructions",
        "created_at": "2018-02-08T08:20:38Z",
        "updated_at": "2018-02-08T12:25:47Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/43#discussion_r166857755",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/43",
        "author_association": "CONTRIBUTOR",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/166857755"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/43#discussion_r166857755"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/43"
            }
        },
        "in_reply_to_id": 166656804
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/166905683",
        "pull_request_review_id": 95038651,
        "id": 166905683,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NjkwNTY4Mw==",
        "diff_hunk": "@@ -0,0 +1,40 @@\n+{\n+  \"version\": 1,\n+  \"root\":\n+  {\n+    \"level\": \"DEBUG\",\n+    \"handlers\": [\"stdout\"]",
        "path": "deeppavlov/log_config.json",
        "position": null,
        "original_position": 6,
        "commit_id": "18600f8fcb458427f492f66898b002f56c94fe55",
        "original_commit_id": "1d6ce4a9b58b5ac64fb5633dde59e2a63ff387d4",
        "user": {
            "login": "yoptar",
            "id": 5615053,
            "node_id": "MDQ6VXNlcjU2MTUwNTM=",
            "avatar_url": "https://avatars2.githubusercontent.com/u/5615053?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yoptar",
            "html_url": "https://github.com/yoptar",
            "followers_url": "https://api.github.com/users/yoptar/followers",
            "following_url": "https://api.github.com/users/yoptar/following{/other_user}",
            "gists_url": "https://api.github.com/users/yoptar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yoptar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yoptar/subscriptions",
            "organizations_url": "https://api.github.com/users/yoptar/orgs",
            "repos_url": "https://api.github.com/users/yoptar/repos",
            "events_url": "https://api.github.com/users/yoptar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yoptar/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "\u041e\u0447\u0435\u043d\u044c \u0445\u043e\u0447\u0435\u0442\u0441\u044f, \u0447\u0442\u043e\u0431\u044b \u0434\u0435\u0431\u0430\u0433 \u0432\u044b\u0445\u043e\u0434\u0438\u043b \u0432 stderr",
        "created_at": "2018-02-08T11:25:41Z",
        "updated_at": "2018-02-08T12:25:47Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/43#discussion_r166905683",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/43",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/166905683"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/43#discussion_r166905683"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/43"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/166907246",
        "pull_request_review_id": 95040531,
        "id": 166907246,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NjkwNzI0Ng==",
        "diff_hunk": "@@ -80,27 +83,28 @@ def load(self, *args, **kwargs):\n                 raise ConfigError(\"Provided `load_path` for {} doesn't exist!\".format(\n                     self.__class__.__name__))\n         else:\n-            warn(\"No `load_path` is provided for {}\".format(self.__class__.__name__))\n-            if self.embedding_url:\n-                try:\n-                    print('[trying to download a pretrained fasttext model from repository]')\n-                    local_filename, _ = urllib.request.urlretrieve(self.embedding_url)\n-                    with open(local_filename, 'rb') as fin:\n-                        model_file = fin.read()\n-\n-                    mp = self.save_path\n-                    self.load_path = self.save_path\n-                    model = self.load()\n-                    print(\"[saving downloaded fasttext model to {}]\".format(mp))\n-                    with open(str(mp), 'wb') as fout:\n-                        fout.write(model_file)\n-                except Exception as e:\n-                    raise RuntimeError(\n-                        'Looks like the provided fasttext url is incorrect', e)\n-            else:\n-                raise FileNotFoundError(\n-                    'No pretrained fasttext model provided or provided \"load_path\" is incorrect.'\n-                    ' Please include \"load_path\" to json.')\n+            try:\n+                log.warning(\"No `load_path` is provided for {}\".format(self.__class__.__name__))\n+                if self.embedding_url:\n+                    try:\n+                        log.info('[trying to download a pretrained fasttext model from repository]')\n+                        local_filename, _ = urllib.request.urlretrieve(self.embedding_url)\n+                        with open(local_filename, 'rb') as fin:\n+                            model_file = fin.read()\n+\n+                        mp = self.save_path\n+                        self.load_path = self.save_path\n+                        model = self.load()\n+                        log.info(\"[saving downloaded fasttext model to {}]\".format(mp))\n+                        with open(str(mp), 'wb') as fout:\n+                            fout.write(model_file)\n+                    except Exception as e:\n+                        log.error('Looks like the provided fasttext url is incorrect', exc_info=True)\n+                else:\n+                    raise FileNotFoundError\n+            except Exception:\n+                log.error('No pretrained fasttext model provided or provided \"load_path\" is incorrect.'\n+                          ' Please include \"load_path\" to json.', exc_info=True)",
        "path": "deeppavlov/models/embedders/fasttext_embedder.py",
        "position": 77,
        "original_position": 74,
        "commit_id": "18600f8fcb458427f492f66898b002f56c94fe55",
        "original_commit_id": "1d6ce4a9b58b5ac64fb5633dde59e2a63ff387d4",
        "user": {
            "login": "yoptar",
            "id": 5615053,
            "node_id": "MDQ6VXNlcjU2MTUwNTM=",
            "avatar_url": "https://avatars2.githubusercontent.com/u/5615053?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yoptar",
            "html_url": "https://github.com/yoptar",
            "followers_url": "https://api.github.com/users/yoptar/followers",
            "following_url": "https://api.github.com/users/yoptar/following{/other_user}",
            "gists_url": "https://api.github.com/users/yoptar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yoptar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yoptar/subscriptions",
            "organizations_url": "https://api.github.com/users/yoptar/orgs",
            "repos_url": "https://api.github.com/users/yoptar/repos",
            "events_url": "https://api.github.com/users/yoptar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yoptar/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "Do we not need to `raise` here after logging the error? ",
        "created_at": "2018-02-08T11:33:07Z",
        "updated_at": "2018-02-08T12:25:47Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/43#discussion_r166907246",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/43",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/166907246"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/43#discussion_r166907246"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/43"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/166919140",
        "pull_request_review_id": 95055077,
        "id": 166919140,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NjkxOTE0MA==",
        "diff_hunk": "@@ -80,27 +83,28 @@ def load(self, *args, **kwargs):\n                 raise ConfigError(\"Provided `load_path` for {} doesn't exist!\".format(\n                     self.__class__.__name__))\n         else:\n-            warn(\"No `load_path` is provided for {}\".format(self.__class__.__name__))\n-            if self.embedding_url:\n-                try:\n-                    print('[trying to download a pretrained fasttext model from repository]')\n-                    local_filename, _ = urllib.request.urlretrieve(self.embedding_url)\n-                    with open(local_filename, 'rb') as fin:\n-                        model_file = fin.read()\n-\n-                    mp = self.save_path\n-                    self.load_path = self.save_path\n-                    model = self.load()\n-                    print(\"[saving downloaded fasttext model to {}]\".format(mp))\n-                    with open(str(mp), 'wb') as fout:\n-                        fout.write(model_file)\n-                except Exception as e:\n-                    raise RuntimeError(\n-                        'Looks like the provided fasttext url is incorrect', e)\n-            else:\n-                raise FileNotFoundError(\n-                    'No pretrained fasttext model provided or provided \"load_path\" is incorrect.'\n-                    ' Please include \"load_path\" to json.')\n+            try:\n+                log.warning(\"No `load_path` is provided for {}\".format(self.__class__.__name__))\n+                if self.embedding_url:\n+                    try:\n+                        log.info('[trying to download a pretrained fasttext model from repository]')\n+                        local_filename, _ = urllib.request.urlretrieve(self.embedding_url)\n+                        with open(local_filename, 'rb') as fin:\n+                            model_file = fin.read()\n+\n+                        mp = self.save_path\n+                        self.load_path = self.save_path\n+                        model = self.load()\n+                        log.info(\"[saving downloaded fasttext model to {}]\".format(mp))\n+                        with open(str(mp), 'wb') as fout:\n+                            fout.write(model_file)\n+                    except Exception as e:\n+                        log.error('Looks like the provided fasttext url is incorrect', exc_info=True)\n+                else:\n+                    raise FileNotFoundError\n+            except Exception:\n+                log.error('No pretrained fasttext model provided or provided \"load_path\" is incorrect.'\n+                          ' Please include \"load_path\" to json.', exc_info=True)",
        "path": "deeppavlov/models/embedders/fasttext_embedder.py",
        "position": 77,
        "original_position": 74,
        "commit_id": "18600f8fcb458427f492f66898b002f56c94fe55",
        "original_commit_id": "1d6ce4a9b58b5ac64fb5633dde59e2a63ff387d4",
        "user": {
            "login": "litinsky",
            "id": 22733410,
            "node_id": "MDQ6VXNlcjIyNzMzNDEw",
            "avatar_url": "https://avatars3.githubusercontent.com/u/22733410?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/litinsky",
            "html_url": "https://github.com/litinsky",
            "followers_url": "https://api.github.com/users/litinsky/followers",
            "following_url": "https://api.github.com/users/litinsky/following{/other_user}",
            "gists_url": "https://api.github.com/users/litinsky/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/litinsky/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/litinsky/subscriptions",
            "organizations_url": "https://api.github.com/users/litinsky/orgs",
            "repos_url": "https://api.github.com/users/litinsky/repos",
            "events_url": "https://api.github.com/users/litinsky/events{/privacy}",
            "received_events_url": "https://api.github.com/users/litinsky/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "Fixed with `sys.exit()`",
        "created_at": "2018-02-08T12:30:27Z",
        "updated_at": "2018-02-08T12:30:28Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/43#discussion_r166919140",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/43",
        "author_association": "CONTRIBUTOR",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/166919140"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/43#discussion_r166919140"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/43"
            }
        },
        "in_reply_to_id": 166907246
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/167193495",
        "pull_request_review_id": 95377797,
        "id": 167193495,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NzE5MzQ5NQ==",
        "diff_hunk": "@@ -14,70 +14,243 @@\n limitations under the License.\n \"\"\"\n \n+import datetime\n+import json\n+import time\n import sys\n+from collections import OrderedDict\n \n+from typing import List, Callable, Tuple\n+\n+from deeppavlov.core.common.errors import ConfigError\n from deeppavlov.core.common.file import read_json\n-from deeppavlov.core.common.registry import REGISTRY\n-from deeppavlov.core.commands.infer import build_agent_from_config\n+from deeppavlov.core.common.registry import model as get_model\n+from deeppavlov.core.common.metrics_registry import get_metrics_by_names\n from deeppavlov.core.common.params import from_params\n+from deeppavlov.core.data.dataset import Dataset\n+from deeppavlov.core.models.inferable import Inferable\n from deeppavlov.core.models.trainable import Trainable\n from deeppavlov.core.common import paths\n from deeppavlov.core.common.log import get_logger\n \n \n log = get_logger(__name__)\n \n-# TODO pass paths to local model configs to agent config.\n+def _fit(model: Trainable, dataset: Dataset, train_config={}):\n+    model.fit(dataset.iter_all('train'))\n+    model.save()\n+    return model\n \n \n-def train_agent_models(config_path: str):\n-    usr_dir = paths.USR_PATH\n-    a = build_agent_from_config(config_path)\n-\n-    for skill_config in a.skill_configs:\n-        model_config = skill_config['model']\n-        model_name = model_config['name']\n-\n-        if issubclass(REGISTRY[model_name], Trainable):\n-            reader_config = skill_config['dataset_reader']\n-            reader = from_params(REGISTRY[reader_config['name']], {})\n-            data = reader.read(reader_config.get('data_path', usr_dir))\n-\n-            dataset_config = skill_config['dataset']\n-            dataset_name = dataset_config['name']\n-            dataset = from_params(REGISTRY[dataset_name], dataset_config, data=data)\n-\n-            model = from_params(REGISTRY[model_name], model_config)\n-            model.train(dataset)\n-        else:\n-            log.warning('Model {} is not an instance of Trainable, skip training.'.format(model_name))\n-\n-\n-def train_model_from_config(config_path: str, mode='train'):\n+def train_model_from_config(config_path: str):\n     usr_dir = paths.USR_PATH\n     config = read_json(config_path)\n \n     reader_config = config['dataset_reader']\n-    # NOTE: Why there are no params for dataset reader? Because doesn't have __init__()\n-    reader = from_params(REGISTRY[reader_config['name']], {})\n+    reader = from_params(get_model(reader_config['name']), {})\n     data = reader.read(reader_config.get('data_path', usr_dir))\n \n     dataset_config = config['dataset']\n     dataset_name = dataset_config['name']\n-    dataset = from_params(REGISTRY[dataset_name], dataset_config, data=data)\n+    dataset: Dataset = from_params(get_model(dataset_name), dataset_config, data=data)",
        "path": "deeppavlov/core/commands/train.py",
        "position": 72,
        "original_position": 72,
        "commit_id": "808c4e48d405c899d854ae20c5a23e1a4090e92f",
        "original_commit_id": "808c4e48d405c899d854ae20c5a23e1a4090e92f",
        "user": {
            "login": "vikmary",
            "id": 17520043,
            "node_id": "MDQ6VXNlcjE3NTIwMDQz",
            "avatar_url": "https://avatars0.githubusercontent.com/u/17520043?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vikmary",
            "html_url": "https://github.com/vikmary",
            "followers_url": "https://api.github.com/users/vikmary/followers",
            "following_url": "https://api.github.com/users/vikmary/following{/other_user}",
            "gists_url": "https://api.github.com/users/vikmary/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vikmary/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vikmary/subscriptions",
            "organizations_url": "https://api.github.com/users/vikmary/orgs",
            "repos_url": "https://api.github.com/users/vikmary/repos",
            "events_url": "https://api.github.com/users/vikmary/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vikmary/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "\u042f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043b\u0438 dataset \u043c\u043e\u0434\u0435\u043b\u044c\u044e? (\u0443\u043d\u0438\u0432\u0435\u0440\u0441\u0430\u043b\u044c\u043d\u043e \u043b\u0438 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 `get_model`)",
        "created_at": "2018-02-09T10:37:45Z",
        "updated_at": "2018-02-09T10:43:20Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/46#discussion_r167193495",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/46",
        "author_association": "CONTRIBUTOR",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/167193495"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/46#discussion_r167193495"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/46"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/167201729",
        "pull_request_review_id": 95387738,
        "id": 167201729,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NzIwMTcyOQ==",
        "diff_hunk": "@@ -14,70 +14,243 @@\n limitations under the License.\n \"\"\"\n \n+import datetime\n+import json\n+import time\n import sys\n+from collections import OrderedDict\n \n+from typing import List, Callable, Tuple\n+\n+from deeppavlov.core.common.errors import ConfigError\n from deeppavlov.core.common.file import read_json\n-from deeppavlov.core.common.registry import REGISTRY\n-from deeppavlov.core.commands.infer import build_agent_from_config\n+from deeppavlov.core.common.registry import model as get_model\n+from deeppavlov.core.common.metrics_registry import get_metrics_by_names\n from deeppavlov.core.common.params import from_params\n+from deeppavlov.core.data.dataset import Dataset\n+from deeppavlov.core.models.inferable import Inferable\n from deeppavlov.core.models.trainable import Trainable\n from deeppavlov.core.common import paths\n from deeppavlov.core.common.log import get_logger\n \n \n log = get_logger(__name__)\n \n-# TODO pass paths to local model configs to agent config.\n+def _fit(model: Trainable, dataset: Dataset, train_config={}):\n+    model.fit(dataset.iter_all('train'))\n+    model.save()\n+    return model\n \n \n-def train_agent_models(config_path: str):\n-    usr_dir = paths.USR_PATH\n-    a = build_agent_from_config(config_path)\n-\n-    for skill_config in a.skill_configs:\n-        model_config = skill_config['model']\n-        model_name = model_config['name']\n-\n-        if issubclass(REGISTRY[model_name], Trainable):\n-            reader_config = skill_config['dataset_reader']\n-            reader = from_params(REGISTRY[reader_config['name']], {})\n-            data = reader.read(reader_config.get('data_path', usr_dir))\n-\n-            dataset_config = skill_config['dataset']\n-            dataset_name = dataset_config['name']\n-            dataset = from_params(REGISTRY[dataset_name], dataset_config, data=data)\n-\n-            model = from_params(REGISTRY[model_name], model_config)\n-            model.train(dataset)\n-        else:\n-            log.warning('Model {} is not an instance of Trainable, skip training.'.format(model_name))\n-\n-\n-def train_model_from_config(config_path: str, mode='train'):\n+def train_model_from_config(config_path: str):\n     usr_dir = paths.USR_PATH\n     config = read_json(config_path)\n \n     reader_config = config['dataset_reader']\n-    # NOTE: Why there are no params for dataset reader? Because doesn't have __init__()\n-    reader = from_params(REGISTRY[reader_config['name']], {})\n+    reader = from_params(get_model(reader_config['name']), {})\n     data = reader.read(reader_config.get('data_path', usr_dir))\n \n     dataset_config = config['dataset']\n     dataset_name = dataset_config['name']\n-    dataset = from_params(REGISTRY[dataset_name], dataset_config, data=data)\n+    dataset: Dataset = from_params(get_model(dataset_name), dataset_config, data=data)\n \n     vocabs = {}\n-    if 'vocabs' in config:\n-        for vocab_param_name, vocab_config in config['vocabs'].items():\n-            vocab_name = vocab_config['name']\n-            v = from_params(REGISTRY[vocab_name], vocab_config, mode=mode)\n-            v.train(dataset.iter_all('train'))\n-            vocabs[vocab_param_name] = v\n+    for vocab_param_name, vocab_config in config.get('vocabs', {}).items():\n+        vocab_name = vocab_config['name']\n+        v: Trainable = from_params(get_model(vocab_name), vocab_config, mode='train')\n+        vocabs[vocab_param_name] = _fit(v, dataset)\n \n     model_config = config['model']\n     model_name = model_config['name']\n-    model = from_params(REGISTRY[model_name], model_config, vocabs=vocabs, mode=mode)\n+    model = from_params(get_model(model_name), model_config, vocabs=vocabs, mode='train')\n+\n+    train_config = {\n+        'metrics': ['accuracy'],\n+\n+        'validate_best': True,\n+        'test_best': True\n+    }\n+\n+    try:\n+        train_config.update(config['train'])\n+    except KeyError:\n+        log.warning('Train config is missing. Populating with default values')\n+\n+    metrics_functions = list(zip(train_config['metrics'], get_metrics_by_names(train_config['metrics'])))\n+\n+    if callable(getattr(model, 'train_on_batch', None)):\n+        _train_batches(model, dataset, train_config, metrics_functions)\n+    elif callable(getattr(model, 'fit', None)):\n+        _fit(model, dataset, train_config)\n+    else:\n+        'model is not adapted to the experimental_train yet'\n+        model.train(dataset)\n+        return\n+\n+    if train_config['validate_best'] or train_config['test_best']:\n+        try:\n+            model_config['load_path'] = model_config['save_path']\n+        except KeyError:\n+            log.warning('No \"save_path\" parameter for the model, so \"load_path\" will not be renewed')\n+        model = from_params(get_model(model_name), model_config, vocabs=vocabs, mode='infer')\n+        log.info('Testing the best saved model')\n+\n+        if train_config['validate_best']:\n+            report = {\n+                'valid': _test_model(model, metrics_functions, dataset, train_config.get('batch_size', -1), 'valid')\n+            }\n+\n+            print(json.dumps(report, ensure_ascii=False))",
        "path": "deeppavlov/core/commands/train.py",
        "position": 127,
        "original_position": 127,
        "commit_id": "808c4e48d405c899d854ae20c5a23e1a4090e92f",
        "original_commit_id": "808c4e48d405c899d854ae20c5a23e1a4090e92f",
        "user": {
            "login": "vikmary",
            "id": 17520043,
            "node_id": "MDQ6VXNlcjE3NTIwMDQz",
            "avatar_url": "https://avatars0.githubusercontent.com/u/17520043?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vikmary",
            "html_url": "https://github.com/vikmary",
            "followers_url": "https://api.github.com/users/vikmary/followers",
            "following_url": "https://api.github.com/users/vikmary/following{/other_user}",
            "gists_url": "https://api.github.com/users/vikmary/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vikmary/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vikmary/subscriptions",
            "organizations_url": "https://api.github.com/users/vikmary/orgs",
            "repos_url": "https://api.github.com/users/vikmary/repos",
            "events_url": "https://api.github.com/users/vikmary/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vikmary/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "train script \u043d\u0435 \u0432 \u043b\u043e\u0433\u0433\u0435\u0440 \u043f\u0438\u0448\u0435\u0442?",
        "created_at": "2018-02-09T11:16:07Z",
        "updated_at": "2018-02-09T11:16:07Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/46#discussion_r167201729",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/46",
        "author_association": "CONTRIBUTOR",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/167201729"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/46#discussion_r167201729"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/46"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/167202048",
        "pull_request_review_id": 95388111,
        "id": 167202048,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NzIwMjA0OA==",
        "diff_hunk": "@@ -14,70 +14,243 @@\n limitations under the License.\n \"\"\"\n \n+import datetime\n+import json\n+import time\n import sys\n+from collections import OrderedDict\n \n+from typing import List, Callable, Tuple\n+\n+from deeppavlov.core.common.errors import ConfigError\n from deeppavlov.core.common.file import read_json\n-from deeppavlov.core.common.registry import REGISTRY\n-from deeppavlov.core.commands.infer import build_agent_from_config\n+from deeppavlov.core.common.registry import model as get_model\n+from deeppavlov.core.common.metrics_registry import get_metrics_by_names\n from deeppavlov.core.common.params import from_params\n+from deeppavlov.core.data.dataset import Dataset\n+from deeppavlov.core.models.inferable import Inferable\n from deeppavlov.core.models.trainable import Trainable\n from deeppavlov.core.common import paths\n from deeppavlov.core.common.log import get_logger\n \n \n log = get_logger(__name__)\n \n-# TODO pass paths to local model configs to agent config.\n+def _fit(model: Trainable, dataset: Dataset, train_config={}):\n+    model.fit(dataset.iter_all('train'))\n+    model.save()\n+    return model\n \n \n-def train_agent_models(config_path: str):\n-    usr_dir = paths.USR_PATH\n-    a = build_agent_from_config(config_path)\n-\n-    for skill_config in a.skill_configs:\n-        model_config = skill_config['model']\n-        model_name = model_config['name']\n-\n-        if issubclass(REGISTRY[model_name], Trainable):\n-            reader_config = skill_config['dataset_reader']\n-            reader = from_params(REGISTRY[reader_config['name']], {})\n-            data = reader.read(reader_config.get('data_path', usr_dir))\n-\n-            dataset_config = skill_config['dataset']\n-            dataset_name = dataset_config['name']\n-            dataset = from_params(REGISTRY[dataset_name], dataset_config, data=data)\n-\n-            model = from_params(REGISTRY[model_name], model_config)\n-            model.train(dataset)\n-        else:\n-            log.warning('Model {} is not an instance of Trainable, skip training.'.format(model_name))\n-\n-\n-def train_model_from_config(config_path: str, mode='train'):\n+def train_model_from_config(config_path: str):\n     usr_dir = paths.USR_PATH\n     config = read_json(config_path)\n \n     reader_config = config['dataset_reader']\n-    # NOTE: Why there are no params for dataset reader? Because doesn't have __init__()\n-    reader = from_params(REGISTRY[reader_config['name']], {})\n+    reader = from_params(get_model(reader_config['name']), {})\n     data = reader.read(reader_config.get('data_path', usr_dir))\n \n     dataset_config = config['dataset']\n     dataset_name = dataset_config['name']\n-    dataset = from_params(REGISTRY[dataset_name], dataset_config, data=data)\n+    dataset: Dataset = from_params(get_model(dataset_name), dataset_config, data=data)\n \n     vocabs = {}\n-    if 'vocabs' in config:\n-        for vocab_param_name, vocab_config in config['vocabs'].items():\n-            vocab_name = vocab_config['name']\n-            v = from_params(REGISTRY[vocab_name], vocab_config, mode=mode)\n-            v.train(dataset.iter_all('train'))\n-            vocabs[vocab_param_name] = v\n+    for vocab_param_name, vocab_config in config.get('vocabs', {}).items():\n+        vocab_name = vocab_config['name']\n+        v: Trainable = from_params(get_model(vocab_name), vocab_config, mode='train')\n+        vocabs[vocab_param_name] = _fit(v, dataset)\n \n     model_config = config['model']\n     model_name = model_config['name']\n-    model = from_params(REGISTRY[model_name], model_config, vocabs=vocabs, mode=mode)\n+    model = from_params(get_model(model_name), model_config, vocabs=vocabs, mode='train')\n+\n+    train_config = {\n+        'metrics': ['accuracy'],\n+\n+        'validate_best': True,\n+        'test_best': True\n+    }\n+\n+    try:\n+        train_config.update(config['train'])\n+    except KeyError:\n+        log.warning('Train config is missing. Populating with default values')\n+\n+    metrics_functions = list(zip(train_config['metrics'], get_metrics_by_names(train_config['metrics'])))\n+\n+    if callable(getattr(model, 'train_on_batch', None)):\n+        _train_batches(model, dataset, train_config, metrics_functions)\n+    elif callable(getattr(model, 'fit', None)):\n+        _fit(model, dataset, train_config)\n+    else:\n+        'model is not adapted to the experimental_train yet'\n+        model.train(dataset)\n+        return\n+\n+    if train_config['validate_best'] or train_config['test_best']:\n+        try:\n+            model_config['load_path'] = model_config['save_path']\n+        except KeyError:\n+            log.warning('No \"save_path\" parameter for the model, so \"load_path\" will not be renewed')\n+        model = from_params(get_model(model_name), model_config, vocabs=vocabs, mode='infer')\n+        log.info('Testing the best saved model')\n+\n+        if train_config['validate_best']:\n+            report = {\n+                'valid': _test_model(model, metrics_functions, dataset, train_config.get('batch_size', -1), 'valid')\n+            }\n+\n+            print(json.dumps(report, ensure_ascii=False))\n+\n+        if train_config['test_best']:\n+            report = {\n+                'test': _test_model(model, metrics_functions, dataset, train_config.get('batch_size', -1), 'test')\n+            }\n+\n+            print(json.dumps(report, ensure_ascii=False))\n+\n+\n+def _test_model(model: Inferable, metrics_functions: List[Tuple[str, Callable]],\n+                dataset: Dataset, batch_size=-1, data_type='valid', start_time=None):\n+    if start_time is None:\n+        start_time = time.time()\n+\n+    val_y_true = []\n+    val_y_predicted = []\n+    for x, y_true in dataset.batch_generator(batch_size, data_type, shuffle=False):\n+        y_predicted = list(model.infer(list(x)))\n+        val_y_true += y_true\n+        val_y_predicted += y_predicted\n+\n+    metrics = [(s, f(val_y_true, val_y_predicted)) for s, f in metrics_functions]\n+\n+    report = {\n+        'examples_seen': len(val_y_true),\n+        'metrics': OrderedDict(metrics),\n+        'time_spent': str(datetime.timedelta(seconds=round(time.time() - start_time)))\n+    }\n+    return report\n+\n+\n+def _train_batches(model: Trainable, dataset: Dataset, train_config: dict,\n+                   metrics_functions: List[Tuple[str, Callable]]):\n+\n+    default_train_config = {\n+        'epochs': 0,\n+        'batch_size': 1,\n+\n+        'metric_optimization': 'maximize',\n+\n+        'validation_patience': 5,\n+        'val_every_n_epochs': 0,\n+\n+        'log_every_n_batches': 0,\n+        'log_every_n_epochs': 0,\n+        # 'show_examples': False,",
        "path": "deeppavlov/core/commands/train.py",
        "position": 173,
        "original_position": 173,
        "commit_id": "808c4e48d405c899d854ae20c5a23e1a4090e92f",
        "original_commit_id": "808c4e48d405c899d854ae20c5a23e1a4090e92f",
        "user": {
            "login": "vikmary",
            "id": 17520043,
            "node_id": "MDQ6VXNlcjE3NTIwMDQz",
            "avatar_url": "https://avatars0.githubusercontent.com/u/17520043?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vikmary",
            "html_url": "https://github.com/vikmary",
            "followers_url": "https://api.github.com/users/vikmary/followers",
            "following_url": "https://api.github.com/users/vikmary/following{/other_user}",
            "gists_url": "https://api.github.com/users/vikmary/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vikmary/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vikmary/subscriptions",
            "organizations_url": "https://api.github.com/users/vikmary/orgs",
            "repos_url": "https://api.github.com/users/vikmary/repos",
            "events_url": "https://api.github.com/users/vikmary/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vikmary/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "`show_examples` \u043f\u043b\u0430\u043d\u0438\u0440\u0443\u0435\u0448\u044c \u0440\u0435\u0430\u043b\u0438\u0437\u043e\u0432\u044b\u0432\u0430\u0442\u044c?",
        "created_at": "2018-02-09T11:17:46Z",
        "updated_at": "2018-02-09T11:17:47Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/46#discussion_r167202048",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/46",
        "author_association": "CONTRIBUTOR",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/167202048"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/46#discussion_r167202048"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/46"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/167202194",
        "pull_request_review_id": 95388288,
        "id": 167202194,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NzIwMjE5NA==",
        "diff_hunk": "@@ -14,70 +14,243 @@\n limitations under the License.\n \"\"\"\n \n+import datetime\n+import json\n+import time\n import sys\n+from collections import OrderedDict\n \n+from typing import List, Callable, Tuple\n+\n+from deeppavlov.core.common.errors import ConfigError\n from deeppavlov.core.common.file import read_json\n-from deeppavlov.core.common.registry import REGISTRY\n-from deeppavlov.core.commands.infer import build_agent_from_config\n+from deeppavlov.core.common.registry import model as get_model\n+from deeppavlov.core.common.metrics_registry import get_metrics_by_names\n from deeppavlov.core.common.params import from_params\n+from deeppavlov.core.data.dataset import Dataset\n+from deeppavlov.core.models.inferable import Inferable\n from deeppavlov.core.models.trainable import Trainable\n from deeppavlov.core.common import paths\n from deeppavlov.core.common.log import get_logger\n \n \n log = get_logger(__name__)\n \n-# TODO pass paths to local model configs to agent config.\n+def _fit(model: Trainable, dataset: Dataset, train_config={}):\n+    model.fit(dataset.iter_all('train'))\n+    model.save()\n+    return model\n \n \n-def train_agent_models(config_path: str):\n-    usr_dir = paths.USR_PATH\n-    a = build_agent_from_config(config_path)\n-\n-    for skill_config in a.skill_configs:\n-        model_config = skill_config['model']\n-        model_name = model_config['name']\n-\n-        if issubclass(REGISTRY[model_name], Trainable):\n-            reader_config = skill_config['dataset_reader']\n-            reader = from_params(REGISTRY[reader_config['name']], {})\n-            data = reader.read(reader_config.get('data_path', usr_dir))\n-\n-            dataset_config = skill_config['dataset']\n-            dataset_name = dataset_config['name']\n-            dataset = from_params(REGISTRY[dataset_name], dataset_config, data=data)\n-\n-            model = from_params(REGISTRY[model_name], model_config)\n-            model.train(dataset)\n-        else:\n-            log.warning('Model {} is not an instance of Trainable, skip training.'.format(model_name))\n-\n-\n-def train_model_from_config(config_path: str, mode='train'):\n+def train_model_from_config(config_path: str):\n     usr_dir = paths.USR_PATH\n     config = read_json(config_path)\n \n     reader_config = config['dataset_reader']\n-    # NOTE: Why there are no params for dataset reader? Because doesn't have __init__()\n-    reader = from_params(REGISTRY[reader_config['name']], {})\n+    reader = from_params(get_model(reader_config['name']), {})\n     data = reader.read(reader_config.get('data_path', usr_dir))\n \n     dataset_config = config['dataset']\n     dataset_name = dataset_config['name']\n-    dataset = from_params(REGISTRY[dataset_name], dataset_config, data=data)\n+    dataset: Dataset = from_params(get_model(dataset_name), dataset_config, data=data)\n \n     vocabs = {}\n-    if 'vocabs' in config:\n-        for vocab_param_name, vocab_config in config['vocabs'].items():\n-            vocab_name = vocab_config['name']\n-            v = from_params(REGISTRY[vocab_name], vocab_config, mode=mode)\n-            v.train(dataset.iter_all('train'))\n-            vocabs[vocab_param_name] = v\n+    for vocab_param_name, vocab_config in config.get('vocabs', {}).items():\n+        vocab_name = vocab_config['name']\n+        v: Trainable = from_params(get_model(vocab_name), vocab_config, mode='train')\n+        vocabs[vocab_param_name] = _fit(v, dataset)\n \n     model_config = config['model']\n     model_name = model_config['name']\n-    model = from_params(REGISTRY[model_name], model_config, vocabs=vocabs, mode=mode)\n+    model = from_params(get_model(model_name), model_config, vocabs=vocabs, mode='train')\n+\n+    train_config = {\n+        'metrics': ['accuracy'],\n+\n+        'validate_best': True,\n+        'test_best': True\n+    }\n+\n+    try:\n+        train_config.update(config['train'])\n+    except KeyError:\n+        log.warning('Train config is missing. Populating with default values')\n+\n+    metrics_functions = list(zip(train_config['metrics'], get_metrics_by_names(train_config['metrics'])))\n+\n+    if callable(getattr(model, 'train_on_batch', None)):\n+        _train_batches(model, dataset, train_config, metrics_functions)\n+    elif callable(getattr(model, 'fit', None)):\n+        _fit(model, dataset, train_config)\n+    else:\n+        'model is not adapted to the experimental_train yet'\n+        model.train(dataset)\n+        return\n+\n+    if train_config['validate_best'] or train_config['test_best']:\n+        try:\n+            model_config['load_path'] = model_config['save_path']\n+        except KeyError:\n+            log.warning('No \"save_path\" parameter for the model, so \"load_path\" will not be renewed')\n+        model = from_params(get_model(model_name), model_config, vocabs=vocabs, mode='infer')\n+        log.info('Testing the best saved model')\n+\n+        if train_config['validate_best']:\n+            report = {\n+                'valid': _test_model(model, metrics_functions, dataset, train_config.get('batch_size', -1), 'valid')\n+            }\n+\n+            print(json.dumps(report, ensure_ascii=False))",
        "path": "deeppavlov/core/commands/train.py",
        "position": 127,
        "original_position": 127,
        "commit_id": "808c4e48d405c899d854ae20c5a23e1a4090e92f",
        "original_commit_id": "808c4e48d405c899d854ae20c5a23e1a4090e92f",
        "user": {
            "login": "yoptar",
            "id": 5615053,
            "node_id": "MDQ6VXNlcjU2MTUwNTM=",
            "avatar_url": "https://avatars2.githubusercontent.com/u/5615053?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yoptar",
            "html_url": "https://github.com/yoptar",
            "followers_url": "https://api.github.com/users/yoptar/followers",
            "following_url": "https://api.github.com/users/yoptar/following{/other_user}",
            "gists_url": "https://api.github.com/users/yoptar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yoptar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yoptar/subscriptions",
            "organizations_url": "https://api.github.com/users/yoptar/orgs",
            "repos_url": "https://api.github.com/users/yoptar/repos",
            "events_url": "https://api.github.com/users/yoptar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yoptar/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "\u041a\u0430\u0436\u0435\u0442\u0441\u044f, \u0447\u0442\u043e \u0435\u0441\u043b\u0438 \u044d\u0442\u043e \u043b\u043e\u0433\u0438, \u0442\u043e \u0434\u0440\u0443\u0433\u0438\u0435, \u0432 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u044b\u0439 \u043f\u043e\u0442\u043e\u043a/\u0444\u0430\u0439\u043b. \u041c\u043d\u0435 \u043f\u043e\u043a\u0430\u0437\u0430\u043b\u043e\u0441\u044c, \u0447\u0442\u043e \u043f\u043e\u043a\u0430 \u0447\u0442\u043e \u043f\u0440\u043e\u0449\u0435 \u0432\u0441\u0435\u0433\u043e \u043e\u0441\u0442\u0430\u0432\u0438\u0442\u044c \u043f\u0440\u0438\u043d\u0442\u044b",
        "created_at": "2018-02-09T11:18:32Z",
        "updated_at": "2018-02-09T11:18:32Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/46#discussion_r167202194",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/46",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/167202194"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/46#discussion_r167202194"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/46"
            }
        },
        "in_reply_to_id": 167201729
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/167202679",
        "pull_request_review_id": 95388879,
        "id": 167202679,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NzIwMjY3OQ==",
        "diff_hunk": "@@ -14,70 +14,243 @@\n limitations under the License.\n \"\"\"\n \n+import datetime\n+import json\n+import time\n import sys\n+from collections import OrderedDict\n \n+from typing import List, Callable, Tuple\n+\n+from deeppavlov.core.common.errors import ConfigError\n from deeppavlov.core.common.file import read_json\n-from deeppavlov.core.common.registry import REGISTRY\n-from deeppavlov.core.commands.infer import build_agent_from_config\n+from deeppavlov.core.common.registry import model as get_model\n+from deeppavlov.core.common.metrics_registry import get_metrics_by_names\n from deeppavlov.core.common.params import from_params\n+from deeppavlov.core.data.dataset import Dataset\n+from deeppavlov.core.models.inferable import Inferable\n from deeppavlov.core.models.trainable import Trainable\n from deeppavlov.core.common import paths\n from deeppavlov.core.common.log import get_logger\n \n \n log = get_logger(__name__)\n \n-# TODO pass paths to local model configs to agent config.\n+def _fit(model: Trainable, dataset: Dataset, train_config={}):\n+    model.fit(dataset.iter_all('train'))\n+    model.save()\n+    return model\n \n \n-def train_agent_models(config_path: str):\n-    usr_dir = paths.USR_PATH\n-    a = build_agent_from_config(config_path)\n-\n-    for skill_config in a.skill_configs:\n-        model_config = skill_config['model']\n-        model_name = model_config['name']\n-\n-        if issubclass(REGISTRY[model_name], Trainable):\n-            reader_config = skill_config['dataset_reader']\n-            reader = from_params(REGISTRY[reader_config['name']], {})\n-            data = reader.read(reader_config.get('data_path', usr_dir))\n-\n-            dataset_config = skill_config['dataset']\n-            dataset_name = dataset_config['name']\n-            dataset = from_params(REGISTRY[dataset_name], dataset_config, data=data)\n-\n-            model = from_params(REGISTRY[model_name], model_config)\n-            model.train(dataset)\n-        else:\n-            log.warning('Model {} is not an instance of Trainable, skip training.'.format(model_name))\n-\n-\n-def train_model_from_config(config_path: str, mode='train'):\n+def train_model_from_config(config_path: str):\n     usr_dir = paths.USR_PATH\n     config = read_json(config_path)\n \n     reader_config = config['dataset_reader']\n-    # NOTE: Why there are no params for dataset reader? Because doesn't have __init__()\n-    reader = from_params(REGISTRY[reader_config['name']], {})\n+    reader = from_params(get_model(reader_config['name']), {})\n     data = reader.read(reader_config.get('data_path', usr_dir))\n \n     dataset_config = config['dataset']\n     dataset_name = dataset_config['name']\n-    dataset = from_params(REGISTRY[dataset_name], dataset_config, data=data)\n+    dataset: Dataset = from_params(get_model(dataset_name), dataset_config, data=data)\n \n     vocabs = {}\n-    if 'vocabs' in config:\n-        for vocab_param_name, vocab_config in config['vocabs'].items():\n-            vocab_name = vocab_config['name']\n-            v = from_params(REGISTRY[vocab_name], vocab_config, mode=mode)\n-            v.train(dataset.iter_all('train'))\n-            vocabs[vocab_param_name] = v\n+    for vocab_param_name, vocab_config in config.get('vocabs', {}).items():\n+        vocab_name = vocab_config['name']\n+        v: Trainable = from_params(get_model(vocab_name), vocab_config, mode='train')\n+        vocabs[vocab_param_name] = _fit(v, dataset)\n \n     model_config = config['model']\n     model_name = model_config['name']\n-    model = from_params(REGISTRY[model_name], model_config, vocabs=vocabs, mode=mode)\n+    model = from_params(get_model(model_name), model_config, vocabs=vocabs, mode='train')\n+\n+    train_config = {\n+        'metrics': ['accuracy'],\n+\n+        'validate_best': True,\n+        'test_best': True\n+    }\n+\n+    try:\n+        train_config.update(config['train'])\n+    except KeyError:\n+        log.warning('Train config is missing. Populating with default values')\n+\n+    metrics_functions = list(zip(train_config['metrics'], get_metrics_by_names(train_config['metrics'])))\n+\n+    if callable(getattr(model, 'train_on_batch', None)):\n+        _train_batches(model, dataset, train_config, metrics_functions)\n+    elif callable(getattr(model, 'fit', None)):\n+        _fit(model, dataset, train_config)\n+    else:\n+        'model is not adapted to the experimental_train yet'\n+        model.train(dataset)\n+        return\n+\n+    if train_config['validate_best'] or train_config['test_best']:\n+        try:\n+            model_config['load_path'] = model_config['save_path']\n+        except KeyError:\n+            log.warning('No \"save_path\" parameter for the model, so \"load_path\" will not be renewed')\n+        model = from_params(get_model(model_name), model_config, vocabs=vocabs, mode='infer')\n+        log.info('Testing the best saved model')\n+\n+        if train_config['validate_best']:\n+            report = {\n+                'valid': _test_model(model, metrics_functions, dataset, train_config.get('batch_size', -1), 'valid')\n+            }\n+\n+            print(json.dumps(report, ensure_ascii=False))\n+\n+        if train_config['test_best']:\n+            report = {\n+                'test': _test_model(model, metrics_functions, dataset, train_config.get('batch_size', -1), 'test')\n+            }\n+\n+            print(json.dumps(report, ensure_ascii=False))\n+\n+\n+def _test_model(model: Inferable, metrics_functions: List[Tuple[str, Callable]],\n+                dataset: Dataset, batch_size=-1, data_type='valid', start_time=None):\n+    if start_time is None:\n+        start_time = time.time()\n+\n+    val_y_true = []\n+    val_y_predicted = []\n+    for x, y_true in dataset.batch_generator(batch_size, data_type, shuffle=False):\n+        y_predicted = list(model.infer(list(x)))\n+        val_y_true += y_true\n+        val_y_predicted += y_predicted\n+\n+    metrics = [(s, f(val_y_true, val_y_predicted)) for s, f in metrics_functions]\n+\n+    report = {\n+        'examples_seen': len(val_y_true),\n+        'metrics': OrderedDict(metrics),\n+        'time_spent': str(datetime.timedelta(seconds=round(time.time() - start_time)))\n+    }\n+    return report\n+\n+\n+def _train_batches(model: Trainable, dataset: Dataset, train_config: dict,\n+                   metrics_functions: List[Tuple[str, Callable]]):\n+\n+    default_train_config = {\n+        'epochs': 0,\n+        'batch_size': 1,\n+\n+        'metric_optimization': 'maximize',\n+\n+        'validation_patience': 5,\n+        'val_every_n_epochs': 0,\n+\n+        'log_every_n_batches': 0,\n+        'log_every_n_epochs': 0,\n+        # 'show_examples': False,",
        "path": "deeppavlov/core/commands/train.py",
        "position": 173,
        "original_position": 173,
        "commit_id": "808c4e48d405c899d854ae20c5a23e1a4090e92f",
        "original_commit_id": "808c4e48d405c899d854ae20c5a23e1a4090e92f",
        "user": {
            "login": "yoptar",
            "id": 5615053,
            "node_id": "MDQ6VXNlcjU2MTUwNTM=",
            "avatar_url": "https://avatars2.githubusercontent.com/u/5615053?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yoptar",
            "html_url": "https://github.com/yoptar",
            "followers_url": "https://api.github.com/users/yoptar/followers",
            "following_url": "https://api.github.com/users/yoptar/following{/other_user}",
            "gists_url": "https://api.github.com/users/yoptar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yoptar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yoptar/subscriptions",
            "organizations_url": "https://api.github.com/users/yoptar/orgs",
            "repos_url": "https://api.github.com/users/yoptar/repos",
            "events_url": "https://api.github.com/users/yoptar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yoptar/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "\u0414\u0430, \u043d\u043e \u0432\u043e\u043f\u0440\u043e\u0441 \u0432 \u043f\u0440\u0438\u043e\u0440\u0438\u0442\u0435\u0442\u0430\u0445. \u042f \u0445\u043e\u0442\u0435\u043b \u043f\u0435\u0440\u0435\u0432\u0435\u0441\u0442\u0438 \u044d\u0442\u043e\u0442 \u0441\u043a\u0440\u0438\u043f\u0442 \u0432 \u043a\u043b\u0430\u0441\u0441, \u0442\u043e\u0433\u0434\u0430 \u043b\u043e\u0433\u0438\u043a\u0443 \u0432\u044b\u0432\u043e\u0434\u0430 \u044d\u043a\u0437\u0430\u043c\u043f\u043b\u043e\u0432 \u043f\u0440\u0438\u0434\u0451\u0442\u0441\u044f \u0446\u0435\u043b\u0438\u043a\u043e\u043c \u043f\u0435\u0440\u0435\u0434\u0435\u043b\u044b\u0432\u0430\u0442\u044c.",
        "created_at": "2018-02-09T11:21:12Z",
        "updated_at": "2018-02-09T11:21:13Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/46#discussion_r167202679",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/46",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/167202679"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/46#discussion_r167202679"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/46"
            }
        },
        "in_reply_to_id": 167202048
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/167211824",
        "pull_request_review_id": 95400028,
        "id": 167211824,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NzIxMTgyNA==",
        "diff_hunk": "@@ -14,70 +14,243 @@\n limitations under the License.\n \"\"\"\n \n+import datetime\n+import json\n+import time\n import sys\n+from collections import OrderedDict\n \n+from typing import List, Callable, Tuple\n+\n+from deeppavlov.core.common.errors import ConfigError\n from deeppavlov.core.common.file import read_json\n-from deeppavlov.core.common.registry import REGISTRY\n-from deeppavlov.core.commands.infer import build_agent_from_config\n+from deeppavlov.core.common.registry import model as get_model\n+from deeppavlov.core.common.metrics_registry import get_metrics_by_names\n from deeppavlov.core.common.params import from_params\n+from deeppavlov.core.data.dataset import Dataset\n+from deeppavlov.core.models.inferable import Inferable\n from deeppavlov.core.models.trainable import Trainable\n from deeppavlov.core.common import paths\n from deeppavlov.core.common.log import get_logger\n \n \n log = get_logger(__name__)\n \n-# TODO pass paths to local model configs to agent config.\n+def _fit(model: Trainable, dataset: Dataset, train_config={}):\n+    model.fit(dataset.iter_all('train'))\n+    model.save()\n+    return model\n \n \n-def train_agent_models(config_path: str):\n-    usr_dir = paths.USR_PATH\n-    a = build_agent_from_config(config_path)\n-\n-    for skill_config in a.skill_configs:\n-        model_config = skill_config['model']\n-        model_name = model_config['name']\n-\n-        if issubclass(REGISTRY[model_name], Trainable):\n-            reader_config = skill_config['dataset_reader']\n-            reader = from_params(REGISTRY[reader_config['name']], {})\n-            data = reader.read(reader_config.get('data_path', usr_dir))\n-\n-            dataset_config = skill_config['dataset']\n-            dataset_name = dataset_config['name']\n-            dataset = from_params(REGISTRY[dataset_name], dataset_config, data=data)\n-\n-            model = from_params(REGISTRY[model_name], model_config)\n-            model.train(dataset)\n-        else:\n-            log.warning('Model {} is not an instance of Trainable, skip training.'.format(model_name))\n-\n-\n-def train_model_from_config(config_path: str, mode='train'):\n+def train_model_from_config(config_path: str):\n     usr_dir = paths.USR_PATH\n     config = read_json(config_path)\n \n     reader_config = config['dataset_reader']\n-    # NOTE: Why there are no params for dataset reader? Because doesn't have __init__()\n-    reader = from_params(REGISTRY[reader_config['name']], {})\n+    reader = from_params(get_model(reader_config['name']), {})\n     data = reader.read(reader_config.get('data_path', usr_dir))\n \n     dataset_config = config['dataset']\n     dataset_name = dataset_config['name']\n-    dataset = from_params(REGISTRY[dataset_name], dataset_config, data=data)\n+    dataset: Dataset = from_params(get_model(dataset_name), dataset_config, data=data)",
        "path": "deeppavlov/core/commands/train.py",
        "position": 72,
        "original_position": 72,
        "commit_id": "808c4e48d405c899d854ae20c5a23e1a4090e92f",
        "original_commit_id": "808c4e48d405c899d854ae20c5a23e1a4090e92f",
        "user": {
            "login": "yoptar",
            "id": 5615053,
            "node_id": "MDQ6VXNlcjU2MTUwNTM=",
            "avatar_url": "https://avatars2.githubusercontent.com/u/5615053?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yoptar",
            "html_url": "https://github.com/yoptar",
            "followers_url": "https://api.github.com/users/yoptar/followers",
            "following_url": "https://api.github.com/users/yoptar/following{/other_user}",
            "gists_url": "https://api.github.com/users/yoptar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yoptar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yoptar/subscriptions",
            "organizations_url": "https://api.github.com/users/yoptar/orgs",
            "repos_url": "https://api.github.com/users/yoptar/repos",
            "events_url": "https://api.github.com/users/yoptar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yoptar/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "\u042d\u0442\u043e\u0442 \u043f\u0443\u043b-\u0440\u0435\u043a\u0432\u0435\u0441\u0442 \u043d\u0435 \u043c\u0435\u043d\u044f\u0435\u0442 \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u044e\u0449\u0435\u0439 \u043d\u043e\u0442\u0430\u0446\u0438\u0438 \u0440\u0435\u0433\u0438\u0441\u0442\u0440\u0430 \u043c\u043e\u0434\u0435\u043b\u0435\u0439/\u043a\u043e\u043c\u043f\u043e\u043d\u0435\u043d\u0442\u043e\u0432, \u043f\u0440\u043e\u0441\u0442\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442 \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u044f \u043f\u043e \u0438\u043c\u0435\u043d\u0438 \u0432\u043c\u0435\u0441\u0442\u043e \u043e\u0431\u0440\u0430\u0449\u0435\u043d\u0438\u044f \u043d\u0430\u043f\u0440\u044f\u043c\u0443\u044e \u043a \u0440\u0435\u0433\u0438\u0441\u0442\u0440\u0443",
        "created_at": "2018-02-09T12:10:22Z",
        "updated_at": "2018-02-09T12:10:22Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/46#discussion_r167211824",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/46",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/167211824"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/46#discussion_r167211824"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/46"
            }
        },
        "in_reply_to_id": 167193495
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168157450",
        "pull_request_review_id": 96477315,
        "id": 168157450,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2ODE1NzQ1MA==",
        "diff_hunk": "@@ -0,0 +1,197 @@\n+import codecs\n+import os\n+from glob import glob\n+\n+from nltk import sent_tokenize, word_tokenize\n+from six.moves import cPickle\n+import numpy as np\n+from tqdm import tqdm\n+from collections import Counter\n+\n+\n+class TextLoader:\n+    def __init__(self, data_dir, batch_size, seq_length, chars=None, vocab=None):\n+        self.data_dir = data_dir\n+        self.batch_size = batch_size\n+        self.seq_length = seq_length\n+\n+        self.chars = chars\n+        self.vocab = vocab\n+        self.noise_level = 0.0\n+        vocab_file = os.path.join(data_dir, \"vocab.pkl\")\n+        tensor_file = os.path.join(data_dir, \"data.npy\")\n+        letter_vocab_file = os.path.join(data_dir, \"letter_vocab.npy\")\n+\n+        if not (os.path.exists(vocab_file)",
        "path": "deeppavlov/datasets/robust_dataloader.py",
        "position": 25,
        "original_position": 25,
        "commit_id": "1aae5859eef4e9494b06d33f60d6b44b3eb54711",
        "original_commit_id": "1aae5859eef4e9494b06d33f60d6b44b3eb54711",
        "user": {
            "login": "my-master",
            "id": 9787475,
            "node_id": "MDQ6VXNlcjk3ODc0NzU=",
            "avatar_url": "https://avatars1.githubusercontent.com/u/9787475?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/my-master",
            "html_url": "https://github.com/my-master",
            "followers_url": "https://api.github.com/users/my-master/followers",
            "following_url": "https://api.github.com/users/my-master/following{/other_user}",
            "gists_url": "https://api.github.com/users/my-master/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/my-master/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/my-master/subscriptions",
            "organizations_url": "https://api.github.com/users/my-master/orgs",
            "repos_url": "https://api.github.com/users/my-master/repos",
            "events_url": "https://api.github.com/users/my-master/events{/privacy}",
            "received_events_url": "https://api.github.com/users/my-master/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "1. pathlib is used in the project",
        "created_at": "2018-02-14T12:20:26Z",
        "updated_at": "2018-02-14T12:31:34Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/56#discussion_r168157450",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/56",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168157450"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/56#discussion_r168157450"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/56"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168158016",
        "pull_request_review_id": 96477315,
        "id": 168158016,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2ODE1ODAxNg==",
        "diff_hunk": "@@ -0,0 +1,197 @@\n+import codecs\n+import os\n+from glob import glob\n+\n+from nltk import sent_tokenize, word_tokenize\n+from six.moves import cPickle\n+import numpy as np\n+from tqdm import tqdm\n+from collections import Counter\n+\n+\n+class TextLoader:\n+    def __init__(self, data_dir, batch_size, seq_length, chars=None, vocab=None):\n+        self.data_dir = data_dir\n+        self.batch_size = batch_size\n+        self.seq_length = seq_length\n+\n+        self.chars = chars\n+        self.vocab = vocab\n+        self.noise_level = 0.0\n+        vocab_file = os.path.join(data_dir, \"vocab.pkl\")\n+        tensor_file = os.path.join(data_dir, \"data.npy\")\n+        letter_vocab_file = os.path.join(data_dir, \"letter_vocab.npy\")\n+\n+        if not (os.path.exists(vocab_file)\n+                and os.path.exists(tensor_file)\n+                and os.path.exists(letter_vocab_file)):\n+            print(\"reading text file\")\n+            self.preprocess(vocab_file, tensor_file, letter_vocab_file)\n+        else:\n+            print(\"loading preprocessed files\")\n+            self.load_preprocessed(vocab_file, tensor_file, letter_vocab_file)\n+        self.create_batches()\n+        self.reset_batch_pointer()\n+\n+    def preprocess(self, vocab_file, tensor_file, letter_vocab_file, ):\n+        print(\"creating char vocab\")\n+        sents = self.create_vocab(vocab_file)\n+\n+        if self.vocab_size < 256:\n+            dtype = np.uint8\n+        else:\n+            dtype = np.uint16\n+\n+        uniq_tokens = Counter()\n+        word_sents = []\n+        import re\n+        for sent in sents:\n+            sent = re.sub(\"\\S*\\d\\S*\", \"\", sent).strip()\n+            sent.replace(\".\",\"\")\n+            sent.replace(\":\",\"\")\n+            word_s = word_tokenize(sent)\n+            uniq_tokens.update(Counter(word_s))\n+            word_sents.append(word_s)\n+        count_pairs = sorted(uniq_tokens.items(), key=lambda x: -x[1])\n+        tokens, _ = zip(*count_pairs)\n+        tokens_vocab = dict(zip(tokens, range(len(tokens))))\n+        letter_vectors = []\n+        print(\"creating vocabs for w2v & letters\")\n+        for token in tqdm(tokens):\n+            letter_vector = self._letters2vec(token, self.vocab, dtype)\n+            letter_vectors.append(letter_vector)\n+        self.letter_vocab = np.vstack(letter_vectors)\n+        self.tensor = []\n+        print(\"filling tensor\")\n+        for sent in tqdm(word_sents):\n+            s = []\n+            for t in sent:\n+                s.append(tokens_vocab[t])\n+            self.tensor.append(np.array(s, dtype=np.uint32))\n+        self.word_vocab_size = len(uniq_tokens)\n+        self.letter_size = self.letter_vocab.shape[1]\n+        with codecs.open(tensor_file, \"wb\") as f:\n+            cPickle.dump(self.tensor, f)\n+        np.save(letter_vocab_file, self.letter_vocab)\n+\n+    def load_preprocessed(self, vocab_file, tensor_file, letter_vocab_file):\n+        with codecs.open(vocab_file, 'rb') as f:\n+            self.chars = cPickle.load(f)\n+        self.vocab_size = len(self.chars) + 1\n+        self.vocab = dict(zip(self.chars, range(1, len(self.chars) + 1)))\n+        self.vocab[\"\"] = 0\n+        with codecs.open(tensor_file, \"rb\") as f:",
        "path": "deeppavlov/datasets/robust_dataloader.py",
        "position": 83,
        "original_position": 83,
        "commit_id": "1aae5859eef4e9494b06d33f60d6b44b3eb54711",
        "original_commit_id": "1aae5859eef4e9494b06d33f60d6b44b3eb54711",
        "user": {
            "login": "my-master",
            "id": 9787475,
            "node_id": "MDQ6VXNlcjk3ODc0NzU=",
            "avatar_url": "https://avatars1.githubusercontent.com/u/9787475?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/my-master",
            "html_url": "https://github.com/my-master",
            "followers_url": "https://api.github.com/users/my-master/followers",
            "following_url": "https://api.github.com/users/my-master/following{/other_user}",
            "gists_url": "https://api.github.com/users/my-master/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/my-master/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/my-master/subscriptions",
            "organizations_url": "https://api.github.com/users/my-master/orgs",
            "repos_url": "https://api.github.com/users/my-master/repos",
            "events_url": "https://api.github.com/users/my-master/events{/privacy}",
            "received_events_url": "https://api.github.com/users/my-master/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "2. The function should be imported from deeppavlov.common.file",
        "created_at": "2018-02-14T12:23:26Z",
        "updated_at": "2018-02-14T12:31:34Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/56#discussion_r168158016",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/56",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168158016"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/56#discussion_r168158016"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/56"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168158125",
        "pull_request_review_id": 96477315,
        "id": 168158125,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2ODE1ODEyNQ==",
        "diff_hunk": "@@ -0,0 +1,197 @@\n+import codecs\n+import os\n+from glob import glob\n+\n+from nltk import sent_tokenize, word_tokenize\n+from six.moves import cPickle\n+import numpy as np\n+from tqdm import tqdm\n+from collections import Counter\n+\n+\n+class TextLoader:",
        "path": "deeppavlov/datasets/robust_dataloader.py",
        "position": 12,
        "original_position": 12,
        "commit_id": "1aae5859eef4e9494b06d33f60d6b44b3eb54711",
        "original_commit_id": "1aae5859eef4e9494b06d33f60d6b44b3eb54711",
        "user": {
            "login": "my-master",
            "id": 9787475,
            "node_id": "MDQ6VXNlcjk3ODc0NzU=",
            "avatar_url": "https://avatars1.githubusercontent.com/u/9787475?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/my-master",
            "html_url": "https://github.com/my-master",
            "followers_url": "https://api.github.com/users/my-master/followers",
            "following_url": "https://api.github.com/users/my-master/following{/other_user}",
            "gists_url": "https://api.github.com/users/my-master/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/my-master/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/my-master/subscriptions",
            "organizations_url": "https://api.github.com/users/my-master/orgs",
            "repos_url": "https://api.github.com/users/my-master/repos",
            "events_url": "https://api.github.com/users/my-master/events{/privacy}",
            "received_events_url": "https://api.github.com/users/my-master/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "3. Add a docstring.",
        "created_at": "2018-02-14T12:23:59Z",
        "updated_at": "2018-02-14T12:31:34Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/56#discussion_r168158125",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/56",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168158125"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/56#discussion_r168158125"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/56"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168158875",
        "pull_request_review_id": 96477315,
        "id": 168158875,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2ODE1ODg3NQ==",
        "diff_hunk": "@@ -0,0 +1,197 @@\n+import codecs\n+import os\n+from glob import glob\n+\n+from nltk import sent_tokenize, word_tokenize\n+from six.moves import cPickle\n+import numpy as np\n+from tqdm import tqdm\n+from collections import Counter\n+\n+\n+class TextLoader:",
        "path": "deeppavlov/datasets/robust_dataloader.py",
        "position": 12,
        "original_position": 12,
        "commit_id": "1aae5859eef4e9494b06d33f60d6b44b3eb54711",
        "original_commit_id": "1aae5859eef4e9494b06d33f60d6b44b3eb54711",
        "user": {
            "login": "my-master",
            "id": 9787475,
            "node_id": "MDQ6VXNlcjk3ODc0NzU=",
            "avatar_url": "https://avatars1.githubusercontent.com/u/9787475?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/my-master",
            "html_url": "https://github.com/my-master",
            "followers_url": "https://api.github.com/users/my-master/followers",
            "following_url": "https://api.github.com/users/my-master/following{/other_user}",
            "gists_url": "https://api.github.com/users/my-master/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/my-master/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/my-master/subscriptions",
            "organizations_url": "https://api.github.com/users/my-master/orgs",
            "repos_url": "https://api.github.com/users/my-master/repos",
            "events_url": "https://api.github.com/users/my-master/events{/privacy}",
            "received_events_url": "https://api.github.com/users/my-master/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "4. The class is not wrapped into DeepPavlov abstractions. Looks like this class should be inherited from `DatasetReader` class and should have a proper name (sth like \"BlaBlaReader\").\r\nAlso there is a separate base class `DefaultVocabulary` which should be used here. If `DefaultVocabulary` is not good for this usecase, a separate Vocabulary class should be written.",
        "created_at": "2018-02-14T12:27:51Z",
        "updated_at": "2018-02-14T12:31:34Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/56#discussion_r168158875",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/56",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168158875"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/56#discussion_r168158875"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/56"
            }
        },
        "in_reply_to_id": 168158125
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168159501",
        "pull_request_review_id": 96477315,
        "id": 168159501,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2ODE1OTUwMQ==",
        "diff_hunk": "@@ -0,0 +1,262 @@\n+import numpy as np\n+import os\n+\n+import tensorflow as tf\n+from nltk import word_tokenize\n+from tensorflow.python.ops import rnn_cell_impl\n+from tqdm import tqdm\n+\n+from deeppavlov.models.lstms.sru import SRUCell\n+\n+rnn_cell = rnn_cell_impl\n+rnn = tf.contrib.rnn\n+\n+from deeppavlov.core.common.registry import register\n+from deeppavlov.core.models.tf_model import TFModel\n+from deeppavlov.core.common.attributes import check_attr_true\n+\n+config = tf.ConfigProto(gpu_options=tf.GPUOptions(\n+    per_process_gpu_memory_fraction=0.3\n+))\n+\n+\n+@register('rove')\n+class RoVeEmbedder(TFModel):\n+    def __init__(self, ser_path, ser_dir='emb', ser_file='rove.model', dim=256,\n+                 model='lstm', rnn_size=128, num_layers=2, batch_size=32, seq_length=8,\n+                 letter_size=200, w2v_size=300, dropout_keep_prob=0.8, grad_clip=5.0,\n+                 learning_rate=0.0002, decay_rate=0.95, inference=False, train_now=True, vocab=None):\n+        \"\"\"\n+\n+        :param ser_path:\n+        :param ser_dir:\n+        :param ser_file:\n+        :param dim:\n+        :param model:\n+        :param rnn_size:\n+        :param num_layers:\n+        :param batch_size:\n+        :param seq_length:\n+        :param letter_size:\n+        :param w2v_size:\n+        :param dropout_keep_prob:\n+        :param grad_clip:\n+        :param learning_rate:\n+        :param decay_rate:\n+        :param train_now: bool train or inference\n+        :param vocab: vocabulary to inference mode from TexLoader\n+        \"\"\"\n+        self.dim = dim\n+        self._ser_dir = ser_dir\n+        self._saver = None\n+        self.sess = None\n+\n+        self.rnn_size = rnn_size\n+        self.w2v_size = w2v_size\n+        self.batch_size = batch_size\n+        self.seq_length = seq_length\n+        self.letter_size = letter_size\n+        self.dropout = dropout_keep_prob\n+        self.learning_rate = learning_rate\n+        self.decay_rate = decay_rate\n+        self.train_now = train_now\n+        self.num_layers = num_layers\n+        self.grad_clip = grad_clip\n+        self.ser_file = ser_file\n+        self.vocab = vocab\n+\n+        if not train_now:\n+            self.batch_size = 1\n+            self.seq_length = 1\n+\n+        if model == 'rnn':\n+            self.cell_fn = rnn_cell.BasicRNNCell\n+        elif model == 'gru':\n+            self.cell_fn = rnn_cell.GRUCell\n+        elif model == 'lstm':\n+            self.cell_fn = rnn_cell.BasicLSTMCell\n+        elif model == 'sru':\n+            self.cell_fn = SRUCell\n+        else:\n+            raise Exception(\"model type not supported: {}\".format(model))\n+        self.load()\n+\n+    def _add_placeholders(self):\n+        self.input_data = tf.placeholder(tf.float32, [self.batch_size, self.seq_length, self.letter_size])\n+        self.change = tf.placeholder(tf.bool, [self.batch_size]) # need to remove\n+        with tf.variable_scope(\"rnn\", reuse=True):\n+            self.cell = self.cell_fn(self.rnn_size, state_is_tuple=False)\n+        self.initial_state = self.cell.zero_state(self.batch_size, tf.float32)\n+        self.cell = rnn_cell.MultiRNNCell([self.cell] * self.num_layers, state_is_tuple=False)\n+\n+    def run_sess(self, input_size, output_size):\n+        self._add_placeholders()\n+\n+        self.initial_state = self.cell.zero_state(self.batch_size, tf.float32)\n+        initial_state = self.initial_state\n+        inputs = tf.split(self.input_data, self.seq_length, 1)\n+        inputs = [tf.squeeze(input_, [1]) for input_ in inputs]\n+\n+        with tf.variable_scope(\"input_linear\"):\n+            linears = []\n+            for i, _input in enumerate(inputs):\n+                if i > 0:\n+                    tf.get_variable_scope()\n+                full_vector = tf.contrib.layers.fully_connected(_input, self.rnn_size,\n+                                                                activation_fn=None)\n+                linears.append(full_vector)\n+        fixed_input = tf.stack(linears, axis=1)\n+        fixed_input = tf.reshape(fixed_input, [self.batch_size, self.seq_length, -1])\n+\n+        outputs, last_state = tf.nn.dynamic_rnn(self.cell, fixed_input,\n+                                                initial_state=initial_state,scope=\"rnnlm\")\n+\n+        self.final_state = last_state\n+\n+        loss1 = tf.constant(0.0)\n+        loss2 = tf.constant(0.0)\n+        final_vectors = []\n+\n+        ones = tf.diag([1.] * self.batch_size)\n+        outputs = tf.unstack(outputs, axis=1)\n+        with tf.variable_scope(\"output_linear\"):\n+            for i in range(len(outputs)):\n+                if i > 0:\n+                    tf.get_variable_scope()\n+                output = tf.contrib.layers.fully_connected(outputs[i], self.w2v_size,\n+                                                           activation_fn=None)\n+\n+                output = tf.nn.l2_normalize(output, 1)\n+                output = tf.nn.dropout(output, self.dropout)\n+                # negative sampling\n+                matrix = tf.matmul(output, output, transpose_b=True) - ones\n+                loss1 += tf.maximum(0.0, matrix)\n+                final_vectors.append(output)\n+\n+        seq_slices = tf.reshape(tf.concat(final_vectors, 1), [self.batch_size, self.seq_length, self.w2v_size])\n+        seq_slices = tf.split(seq_slices, self.batch_size, 0)\n+        seq_slices = [tf.squeeze(input_, [0]) for input_ in seq_slices]\n+\n+        with tf.variable_scope(\"additional_loss\"):\n+            for i in range(len(seq_slices)):  # should be length of batch_size\n+                if i > 0:\n+                    tf.get_variable_scope().reuse_variables()\n+                seq_context = tf.nn.l2_normalize(seq_slices[i], 1)\n+                # context similarity\n+                matrix = tf.matmul(seq_context, seq_context, transpose_b=True)\n+                loss2 += 1. - matrix\n+\n+        self.target = final_vectors[-1]\n+        self.cost = tf.reduce_sum(loss1) / self.batch_size / self.seq_length\n+        self.cost += tf.reduce_sum(loss2) / self.batch_size / self.seq_length\n+        self.final_state = last_state\n+        self.lr = tf.Variable(0.0, trainable=False)\n+        tvars = tf.trainable_variables()\n+\n+        with tf.variable_scope(tf.get_variable_scope(), reuse=False):\n+            grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars),\n+                                                  self.grad_clip)\n+            self._optimizer = tf.train.AdamOptimizer(self.lr)\n+            self.train_op = self._optimizer.apply_gradients(zip(grads, tvars))\n+\n+        self.sess = tf.Session(config=config)\n+        tf.global_variables_initializer().run(session=self.sess)\n+        self._saver = tf.train.Saver(tf.global_variables())\n+\n+    def _set_state(self, state):\n+        self.initial_state = state\n+\n+    def _train_step(self, batch, change):\n+        if self.initial_state is None:\n+            state = self.initial_state\n+        else:\n+            state = self.initial_state.eval(session=self.sess)\n+\n+        feed = {self.input_data: batch,\n+                self.change: change,\n+                self.initial_state: state}\n+        train_loss, state, _ = self.sess.run([self.cost, self.final_state, self.train_op], feed)\n+        self._set_state(state)\n+        return train_loss\n+\n+    def _forward(self, batch, change):\n+        if self.initial_state is None:\n+            state = self.initial_state\n+        else:\n+            state = self.initial_state.eval(session=self.sess)\n+\n+        feed = {self.input_data: batch,\n+                self.change: change,\n+                self.initial_state: state}\n+        train_loss, state, _ = self.sess.run([self.cost, self.final_state, self.train_op], feed)\n+        self._set_state(state)\n+        return train_loss\n+\n+    def _encode(self, sentence: str):\n+        state = self.cell.zero_state(1, tf.float32).eval(session=self.sess)\n+\n+        tokens = word_tokenize(sentence)\n+        vectors = []\n+        for token in tokens:\n+            x = self._letters2vec(token, self.vocab).reshape((1, 1, -1))\n+            feed = {self.input_data: x,\n+                    self.initial_state: state,\n+                    self.change: np.zeros((1,))\n+                    }\n+            [state, target] = self.sess.run([self.final_state, self.target], feed)\n+            vectors.append(np.squeeze(target))\n+\n+        embs = np.array(vectors)\n+        return embs\n+\n+    @check_attr_true('train_now')\n+    def train(self, data_loader, **kwargs):\n+        print(':: creating new  model\\n')\n+        self._train_step(data_loader)\n+        self.save()\n+\n+    def infer(self, sentence: str, *args, **kwargs):\n+        return self._encode(sentence)\n+\n+    def load(self):",
        "path": "deeppavlov/models/embedders/rove_embedder.py",
        "position": 221,
        "original_position": 221,
        "commit_id": "1aae5859eef4e9494b06d33f60d6b44b3eb54711",
        "original_commit_id": "1aae5859eef4e9494b06d33f60d6b44b3eb54711",
        "user": {
            "login": "my-master",
            "id": 9787475,
            "node_id": "MDQ6VXNlcjk3ODc0NzU=",
            "avatar_url": "https://avatars1.githubusercontent.com/u/9787475?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/my-master",
            "html_url": "https://github.com/my-master",
            "followers_url": "https://api.github.com/users/my-master/followers",
            "following_url": "https://api.github.com/users/my-master/following{/other_user}",
            "gists_url": "https://api.github.com/users/my-master/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/my-master/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/my-master/subscriptions",
            "organizations_url": "https://api.github.com/users/my-master/orgs",
            "repos_url": "https://api.github.com/users/my-master/repos",
            "events_url": "https://api.github.com/users/my-master/events{/privacy}",
            "received_events_url": "https://api.github.com/users/my-master/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "5. Why `TFModel.save()` and `TFModel.load()` are not used here? If they are no good for this usecase, this is a serious lack of flexibility in the abstract class and the abstract class methods should be rewritten.  ",
        "created_at": "2018-02-14T12:30:36Z",
        "updated_at": "2018-02-14T12:31:34Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/56#discussion_r168159501",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/56",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168159501"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/56#discussion_r168159501"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/56"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168159638",
        "pull_request_review_id": 96477315,
        "id": 168159638,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2ODE1OTYzOA==",
        "diff_hunk": "@@ -2,7 +2,6 @@ lxml==4.1.1\n tqdm==4.19.4\n requests==2.18.4\n gensim==2.3.0\n-tensorflow_gpu==1.4.0",
        "path": "requirements.txt",
        "position": 4,
        "original_position": 4,
        "commit_id": "1aae5859eef4e9494b06d33f60d6b44b3eb54711",
        "original_commit_id": "1aae5859eef4e9494b06d33f60d6b44b3eb54711",
        "user": {
            "login": "my-master",
            "id": 9787475,
            "node_id": "MDQ6VXNlcjk3ODc0NzU=",
            "avatar_url": "https://avatars1.githubusercontent.com/u/9787475?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/my-master",
            "html_url": "https://github.com/my-master",
            "followers_url": "https://api.github.com/users/my-master/followers",
            "following_url": "https://api.github.com/users/my-master/following{/other_user}",
            "gists_url": "https://api.github.com/users/my-master/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/my-master/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/my-master/subscriptions",
            "organizations_url": "https://api.github.com/users/my-master/orgs",
            "repos_url": "https://api.github.com/users/my-master/repos",
            "events_url": "https://api.github.com/users/my-master/events{/privacy}",
            "received_events_url": "https://api.github.com/users/my-master/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "6. Why?",
        "created_at": "2018-02-14T12:31:17Z",
        "updated_at": "2018-02-14T12:31:34Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/56#discussion_r168159638",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/56",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168159638"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/56#discussion_r168159638"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/56"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168502143",
        "pull_request_review_id": 96879014,
        "id": 168502143,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2ODUwMjE0Mw==",
        "diff_hunk": "@@ -92,35 +92,34 @@ def __init__(self, template_path, vocabs,\n \n     def _encode_context(self, context, db_result=None):\n         # tokenize input\n-        tokenized = ' '.join(self.tokenizer.infer(context)).strip()\n+        tokenized = ' '.join(self.tokenizer([context])[0]).strip()\n         if self.debug:\n             log.debug(\"Text tokens = `{}`\".format(tokenized))\n \n         # Bag of words features\n-        bow_features = self.bow_encoder.infer(tokenized, self.word_vocab)\n+        bow_features = self.bow_encoder([tokenized], self.word_vocab)[0]\n         bow_features = bow_features.astype(np.float32)\n \n         # Embeddings\n         emb_features = []\n-        if hasattr(self.embedder, 'infer'):\n-            emb_features = self.embedder.infer(tokenized, mean=True)\n+        if callable(self.embedder):",
        "path": "deeppavlov/skills/go_bot/go_bot.py",
        "position": 46,
        "original_position": 46,
        "commit_id": "b9a8f835b174732cea78c0adbff1da134fbf18c1",
        "original_commit_id": "477ada8c5d16ca8a7ba77d714e6df8eb50374b5b",
        "user": {
            "login": "vikmary",
            "id": 17520043,
            "node_id": "MDQ6VXNlcjE3NTIwMDQz",
            "avatar_url": "https://avatars0.githubusercontent.com/u/17520043?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vikmary",
            "html_url": "https://github.com/vikmary",
            "followers_url": "https://api.github.com/users/vikmary/followers",
            "following_url": "https://api.github.com/users/vikmary/following{/other_user}",
            "gists_url": "https://api.github.com/users/vikmary/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vikmary/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vikmary/subscriptions",
            "organizations_url": "https://api.github.com/users/vikmary/orgs",
            "repos_url": "https://api.github.com/users/vikmary/repos",
            "events_url": "https://api.github.com/users/vikmary/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vikmary/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "\u041f\u043e \u0434\u0435\u0444\u043e\u043b\u0442\u0443, embedder=BowEncoder (\u043a\u043b\u0430\u0441\u0441, \u0430 \u043d\u0435 \u043e\u0431\u044a\u0435\u043a\u0442 \u043a\u043b\u0430\u0441\u0441\u0430)\r\n\u041f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 `hasattr(self.embedder, 'infer')` \u0434\u043e\u043b\u0436\u043d\u0430 \u0431\u044b\u043b\u0430 \u043f\u0440\u043e\u0432\u0435\u0440\u044f\u0442\u044c, \u0437\u0430\u0434\u0430\u043b\u0438 \u043b\u0438 \u043c\u044b \u0432 \u043a\u043e\u043d\u0444\u0438\u0433\u0435 \u044d\u043c\u0431\u0435\u0434\u0434\u0435\u0440. \u0421\u0435\u0439\u0447\u0430\u0441 \u044d\u0442\u043e\u0442 `if callable(self.embedder)` \u043e\u0442\u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u043f\u043e\u0447\u0442\u0438 \u0432\u0441\u0435\u0433\u0434\u0430 (\u0442\u043e\u043b\u044c\u043a\u043e \u0435\u0441\u043b\u0438 \u0432 \u043a\u043e\u043d\u0444\u0438\u0433\u0435 \u043d\u0435 \u0437\u0430\u0434\u0430\u043b\u0438 `embedder: null`)\r\n\u041b\u0438\u0431\u043e \u0432 `__init__` \u0437\u0430\u0434\u0430\u0435\u043c `embedder=None`, \u043b\u0438\u0431\u043e \u043d\u0443\u0436\u043d\u0430 \u0434\u0440\u0443\u0433\u0430\u044f \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0430.",
        "created_at": "2018-02-15T15:05:10Z",
        "updated_at": "2018-02-16T09:44:10Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/58#discussion_r168502143",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/58",
        "author_association": "CONTRIBUTOR",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168502143"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/58#discussion_r168502143"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/58"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168509695",
        "pull_request_review_id": 96888409,
        "id": 168509695,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2ODUwOTY5NQ==",
        "diff_hunk": "@@ -92,35 +92,34 @@ def __init__(self, template_path, vocabs,\n \n     def _encode_context(self, context, db_result=None):\n         # tokenize input\n-        tokenized = ' '.join(self.tokenizer.infer(context)).strip()\n+        tokenized = ' '.join(self.tokenizer([context])[0]).strip()\n         if self.debug:\n             log.debug(\"Text tokens = `{}`\".format(tokenized))\n \n         # Bag of words features\n-        bow_features = self.bow_encoder.infer(tokenized, self.word_vocab)\n+        bow_features = self.bow_encoder([tokenized], self.word_vocab)[0]\n         bow_features = bow_features.astype(np.float32)\n \n         # Embeddings\n         emb_features = []\n-        if hasattr(self.embedder, 'infer'):\n-            emb_features = self.embedder.infer(tokenized, mean=True)\n+        if callable(self.embedder):",
        "path": "deeppavlov/skills/go_bot/go_bot.py",
        "position": 46,
        "original_position": 46,
        "commit_id": "b9a8f835b174732cea78c0adbff1da134fbf18c1",
        "original_commit_id": "477ada8c5d16ca8a7ba77d714e6df8eb50374b5b",
        "user": {
            "login": "yoptar",
            "id": 5615053,
            "node_id": "MDQ6VXNlcjU2MTUwNTM=",
            "avatar_url": "https://avatars2.githubusercontent.com/u/5615053?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yoptar",
            "html_url": "https://github.com/yoptar",
            "followers_url": "https://api.github.com/users/yoptar/followers",
            "following_url": "https://api.github.com/users/yoptar/following{/other_user}",
            "gists_url": "https://api.github.com/users/yoptar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yoptar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yoptar/subscriptions",
            "organizations_url": "https://api.github.com/users/yoptar/orgs",
            "repos_url": "https://api.github.com/users/yoptar/repos",
            "events_url": "https://api.github.com/users/yoptar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yoptar/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "\u0423\u0436\u0435 \u0441\u0434\u0435\u043b\u0430\u043d\u043e",
        "created_at": "2018-02-15T15:27:46Z",
        "updated_at": "2018-02-16T09:44:10Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/58#discussion_r168509695",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/58",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168509695"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/58#discussion_r168509695"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/58"
            }
        },
        "in_reply_to_id": 168502143
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168518361",
        "pull_request_review_id": 96898849,
        "id": 168518361,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2ODUxODM2MQ==",
        "diff_hunk": "@@ -109,15 +110,15 @@ def train_model_from_config(config_path: str):\n             print(json.dumps(report, ensure_ascii=False))\n \n \n-def _test_model(model: Inferable, metrics_functions: List[Tuple[str, Callable]],\n+def _test_model(model: Component, metrics_functions: List[Tuple[str, Callable]],\n                 dataset: Dataset, batch_size=-1, data_type='valid', start_time=None):\n     if start_time is None:\n         start_time = time.time()\n \n     val_y_true = []\n     val_y_predicted = []\n     for x, y_true in dataset.batch_generator(batch_size, data_type, shuffle=False):\n-        y_predicted = list(model.infer(list(x)))\n+        y_predicted = list(model(list(x)))",
        "path": "deeppavlov/core/commands/train.py",
        "position": 46,
        "original_position": 43,
        "commit_id": "b9a8f835b174732cea78c0adbff1da134fbf18c1",
        "original_commit_id": "19bf91b711c93e32489ce04ab1ceaffcb5eb5951",
        "user": {
            "login": "mu-arkhipov",
            "id": 13665585,
            "node_id": "MDQ6VXNlcjEzNjY1NTg1",
            "avatar_url": "https://avatars1.githubusercontent.com/u/13665585?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mu-arkhipov",
            "html_url": "https://github.com/mu-arkhipov",
            "followers_url": "https://api.github.com/users/mu-arkhipov/followers",
            "following_url": "https://api.github.com/users/mu-arkhipov/following{/other_user}",
            "gists_url": "https://api.github.com/users/mu-arkhipov/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mu-arkhipov/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mu-arkhipov/subscriptions",
            "organizations_url": "https://api.github.com/users/mu-arkhipov/orgs",
            "repos_url": "https://api.github.com/users/mu-arkhipov/repos",
            "events_url": "https://api.github.com/users/mu-arkhipov/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mu-arkhipov/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "If x produced by dataset.batch_generator is a dict or np.array only keys will remain from the dict and np.array will be split",
        "created_at": "2018-02-15T15:53:43Z",
        "updated_at": "2018-02-16T09:44:10Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/58#discussion_r168518361",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/58",
        "author_association": "CONTRIBUTOR",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168518361"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/58#discussion_r168518361"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/58"
            }
        }
    },
    {
        "url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168519612",
        "pull_request_review_id": 96900332,
        "id": 168519612,
        "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2ODUxOTYxMg==",
        "diff_hunk": "@@ -109,15 +110,15 @@ def train_model_from_config(config_path: str):\n             print(json.dumps(report, ensure_ascii=False))\n \n \n-def _test_model(model: Inferable, metrics_functions: List[Tuple[str, Callable]],\n+def _test_model(model: Component, metrics_functions: List[Tuple[str, Callable]],\n                 dataset: Dataset, batch_size=-1, data_type='valid', start_time=None):\n     if start_time is None:\n         start_time = time.time()\n \n     val_y_true = []\n     val_y_predicted = []\n     for x, y_true in dataset.batch_generator(batch_size, data_type, shuffle=False):\n-        y_predicted = list(model.infer(list(x)))\n+        y_predicted = list(model(list(x)))",
        "path": "deeppavlov/core/commands/train.py",
        "position": 46,
        "original_position": 43,
        "commit_id": "b9a8f835b174732cea78c0adbff1da134fbf18c1",
        "original_commit_id": "19bf91b711c93e32489ce04ab1ceaffcb5eb5951",
        "user": {
            "login": "yoptar",
            "id": 5615053,
            "node_id": "MDQ6VXNlcjU2MTUwNTM=",
            "avatar_url": "https://avatars2.githubusercontent.com/u/5615053?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yoptar",
            "html_url": "https://github.com/yoptar",
            "followers_url": "https://api.github.com/users/yoptar/followers",
            "following_url": "https://api.github.com/users/yoptar/following{/other_user}",
            "gists_url": "https://api.github.com/users/yoptar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yoptar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yoptar/subscriptions",
            "organizations_url": "https://api.github.com/users/yoptar/orgs",
            "repos_url": "https://api.github.com/users/yoptar/repos",
            "events_url": "https://api.github.com/users/yoptar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yoptar/received_events",
            "type": "User",
            "site_admin": false
        },
        "body": "x is a batch and batch is a list or a tuple",
        "created_at": "2018-02-15T15:57:18Z",
        "updated_at": "2018-02-16T09:44:10Z",
        "html_url": "https://github.com/deepmipt/DeepPavlov/pull/58#discussion_r168519612",
        "pull_request_url": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/58",
        "author_association": "MEMBER",
        "_links": {
            "self": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/comments/168519612"
            },
            "html": {
                "href": "https://github.com/deepmipt/DeepPavlov/pull/58#discussion_r168519612"
            },
            "pull_request": {
                "href": "https://api.github.com/repos/deepmipt/DeepPavlov/pulls/58"
            }
        },
        "in_reply_to_id": 168518361
    }
]